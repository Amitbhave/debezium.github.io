<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debezium.io/" rel="alternate" type="text/html"/><updated>2022-03-25T16:32:12+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Hello Debezium Team!</title><link href="https://debezium.io/blog/2022/03/15/hello-debezium/" rel="alternate" type="text/html" title="Hello Debezium Team!"/><published>2022-03-15T09:19:59+00:00</published><updated>2022-03-15T09:19:59+00:00</updated><id>https://debezium.io/blog/2022/03/15/hello-debezium</id><content type="html" xml:base="https://debezium.io/blog/2022/03/15/hello-debezium/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Hi everyone, my name is Vojtěch Juránek and I recently joined the Debezium team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Most of my professional IT career I&amp;#8217;ve spent at Red Hat. I have a background in particle physics, but I did quite a lot programming even before joining Red Hat, when working on &lt;a href=&quot;https://herwig.hepforge.org/&quot;&gt;simulations of high-energy particle collisions&lt;/a&gt; and their &lt;a href=&quot;https://root.cern/&quot;&gt;data analysis&lt;/a&gt;. The science is by default open and all software I was using was open source as well. Here started my love for open source.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When I decided to do programming for a living, Red Had was a natural choice for me, as by that time it was one of the few companies which promoted open source heavily. I started to work at Red Hat as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hudson_(software)&quot;&gt;Hudson&lt;/a&gt; developer. I developed and maintained many plugins and also contributed to Hudson core. I focused mainly on Hudson stability and memory footprint as I also took care about internal JBoss Hudson instance, which was the world&amp;#8217;s largest Hudson deployment by that time. When Hudson was forked to &lt;a href=&quot;https://www.jenkins.io/&quot;&gt;Jenkins&lt;/a&gt;, I co-created and a maintained Jenkins LTS (long term support) branch. I was also a member of Jenkins CERT team.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After a couple of years spent with Hudson/Jenkins, I decided it&amp;#8217;s time to move on and joined &lt;a href=&quot;https://infinispan.org/&quot;&gt;Infinispan&lt;/a&gt; team as a quality engineer. Knowing only a little about things like memory data grid when I joined the team, I quickly discovered the beautiful world of distributed systems and fell in love with it. As a quality engineer on the Infinispan project I not only dug deep in distributed databases and consensus algorithms, but also became familiar with other very interesting projects like e.g. &lt;a href=&quot;https://jepsen.io/&quot;&gt;Jepsen&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Later on, I accepted the challenge to discover another interesting world - the world of virtual machines and data centers and started to work as a developer on &lt;a href=&quot;https://www.ovirt.org/&quot;&gt;oVirt project&lt;/a&gt; project in the storage team. I was mostly working on low level stuff, on projects &lt;a href=&quot;https://github.com/ovirt/vdsm&quot;&gt;vdsm&lt;/a&gt; and &lt;a href=&quot;https://github.com/oVirt/ovirt-imageio/&quot;&gt;imageio&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Working on oVirt was interesting, but I was really excited when I got an opportunity to move back to databases and distributed systems and join the Debezium project. I&amp;#8217;m looking forward to work on this wonderful project!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Onwards,&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;--Vojta&lt;/p&gt; &lt;/div&gt;</content><author><name>Vojtěch Juránek</name></author><category term="community"/><category term="news"/><summary type="html">Hi everyone, my name is Vojtěch Juránek and I recently joined the Debezium team. Most of my professional IT career I&amp;#8217;ve spent at Red Hat. I have a background in particle physics, but I did quite a lot programming even before joining Red Hat, when working on simulations of high-energy particle collisions and their data analysis. The science is by default open and all software I was using was open source as well. Here started my love for open source.</summary></entry><entry><title type="html">Debezium 1.9.0.Beta1 Released</title><link href="https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Beta1 Released"/><published>2022-03-03T00:00:00+00:00</published><updated>2022-03-03T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/03/03/debezium-1-9-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am happy to announce the release of Debezium &lt;strong&gt;1.9.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release includes many new features for Debezium Server, including Knative Eventing support and offset storage management with the Redis sink, multi-partitioned scaling for the SQL Server connector, and various of bugfixes and improvements. Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;56 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at a couple of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_server_knative_eventing&quot;&gt;Debezium Server Knative Eventing&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium Server has grown quite a lot since its introduction to the Debezium portfolio in version 1.2. In this release, we have added a new sink implementation to support &lt;a href=&quot;https://knative.dev/docs/eventing/&quot;&gt;Knative Eventing&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Knative Eventing &quot;provides tools and infrastructure to route events from a producer to consumers&quot;, in a very similar way in which Apache Kafka allows the exchange of events via message topics. With Debezium Server, you can now leverage the new &lt;a href=&quot;https://github.com/debezium/debezium/tree/main/debezium-server/debezium-server-http&quot;&gt;debezium-server-http&lt;/a&gt; sink to deliver Debezium change data events to a Knative Broker, a Kubernetes resource that defines a mesh for collecting and distributing &lt;a href=&quot;https://cloudevents.io/&quot;&gt;CloudEvents&lt;/a&gt; to consumers. In other words, Debezium Server can act as a &quot;native&quot; Knative event source.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to get started with Debezium and Knative Eventing, you simply need to configure the Debezium Server with your desired source connector and then configure the sink side with the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.type=http debezium.format.value=cloudevents&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The sink will attempt to automatically detect the endpoint based on the &lt;code&gt;K_SINK&lt;/code&gt; environment variable. If no value is defined by this variable, you can explicitly provide the end-point URL directly using:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.http.url=https://&amp;lt;hostname&amp;gt;/&amp;lt;end-point&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re super excited about this new sink connector and we look forward to all your feedback. A big thank you to &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt; for this excellent contribution!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;redis_managed_offsets_for_debezium_server&quot;&gt;Redis-managed Offsets for Debezium Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Several folks from &lt;a href=&quot;https://redis.com/&quot;&gt;Redis&lt;/a&gt; stepped up lately for improving the story around integrating Debezium and &lt;a href=&quot;https://redis.io/topics/streams-intro&quot;&gt;Redis Streams&lt;/a&gt;. After the performance improvements done in 1.9.0.Alpha1 (by means of batching), another result of that work is the ability to &lt;a href=&quot;/documentation/reference/1.9/operations/debezium-server.html#debezium-source-offset-storage&quot;&gt;store connector offsets&lt;/a&gt; in Redis. For the next 1.9 early access release you can expect a database history implementation backed by Redis, and the team also is working on implementing retry support for Debezium Server. Thanks a lot to &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt; and all the other Redis folks contributing not only to the Redis Streams sink, but also to Debezium and Debezium Server at large!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;multi_partitioned_scaling_for_sql_server_connector&quot;&gt;Multi-partitioned Scaling for SQL Server Connector&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some database platforms, such as SQL Server and Oracle, support the creation and management of multiple logical databases within a single physical database server instance. Traditionally, streaming changes from the multiple logical databases required a separate connector deployment. Now there isn&amp;#8217;t anything innately wrong with such a deployment strategy, but it can quickly start to show its shortcomings if you have many logical databases; for instance in case of multi-tenancy scenarios with one logical database per tenant, the overhead of setting up and operating one connector per database can become a bottleneck. Besides that, processing change events from multiple logical databases lends itself perfectly well to parallelization by means of Kafka Connect&amp;#8217;s concept of tasks.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Over the last several 1.x releases, a tremendous amount of work has gone into key fundamental changes to Debezium&amp;#8217;s common connector framework, setting the stage for a new horizontal scaling strategy.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the initial goals of this new strategy is to eliminate the need for multiple connector deployments when streaming changes from multiple logical databases within a single SQL Server instance. Additionally, it was critical to expose metrics in a way that enables monitoring tools to report on the state and health of the connector both from a connector-centric perspective but also from each logical database being processed. In this release, we&amp;#8217;ve achieved those goals.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/multi_partition_metrics.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;But this is just the beginning folks!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This foundation prepares the groundwork where we can move toward new horizontal scaling strategies. Debezium uses a single-task based architecture and this opens the possibilities to really harness the power of a multi-node Kafka Connect cluster and distribute chunks of work across multiple tasks. Furthermore, this can be extended to other connectors such as Oracle.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This work has been led by the team around &lt;a href=&quot;/blog/2021/08/23/debezium-community-stories-with-sergei-morozov/&quot;&gt;Sergei Morozov&lt;/a&gt; of SugarCRM, who already deploy the SQL Server connector in multi-partition mode built from an internal fork, which they internally maintain until the entire work has been upstreamed. We&amp;#8217;d like to say a huge, huge thank you to Sergei, Jacob Gminder, Mike Kamornikov, and everyone else from SugarCRM who worked tirelessly to make this possible for the Debezium community, and we&amp;#8217;re looking forward very much to continuing and further expanding this close collaboration.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_and_changes&quot;&gt;Other Fixes and Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in the 1.9.0.Beta1 release include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Various DDL parser fixes for both MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4707&quot;&gt;DBZ-4707&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4641&quot;&gt;DBZ-4641&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4662&quot;&gt;DBZ-4662&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4706&quot;&gt;DBZ-4706&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4746&quot;&gt;DBZ-4746&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4746&quot;&gt;DBZ-4752&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4763&quot;&gt;DBZ-4763&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Corrected a long-running transaction issue with the PostgreSQL connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2306&quot;&gt;DBZ-2306&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector stability improvements (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4635&quot;&gt;DBZ-4635&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4715&quot;&gt;DBZ-4715&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4723&quot;&gt;DBZ-4723&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4737&quot;&gt;DBZ-4737&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4744&quot;&gt;DBZ-4744&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.9/release-notes#release-1.9.0-beta1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/samagonas&quot;&gt;Aidas&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/jribera-sugarcrm&quot;&gt;Josh Ribera&lt;/a&gt;, &lt;a href=&quot;https://github.com/limer2&quot;&gt;Li Mo&lt;/a&gt;, &lt;a href=&quot;https://github.com/MartinMedek&quot;&gt;Martin Medek&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/sazzad16&quot;&gt;M Sazzadul Hoque&lt;/a&gt;, &lt;a href=&quot;https://github.com/zalmane&quot;&gt;Oren Elias&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/y5w&quot;&gt;Yang&lt;/a&gt;, &lt;a href=&quot;https://github.com/yingyingtang-brex&quot;&gt;Yingying Tang&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the Beta1 release done, we are approaching the final phase of the 1.9 release cycle. Depending on the incoming issue reports, you can expect a new release in the next few weeks to likely be CR1.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we turn and look ahead beyond 1.9, you can expect work on Debezium 2.0 to begin in early April 2022. The current roadmap is to devote 2 full release cycles, which means you can expect Debezium 2.0 sometime near the end of September 2022. In the meantime, you can expect regular updates to Debezium 1.9 throughout this process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you are interested in Debezium 2.0, we have collected a number of items in &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3899&quot;&gt;DBZ-3899&lt;/a&gt; thus far. This is not an exhaustive list nor has this list been prioritized and scoped to what you can expect in totality of 2.0; however, it is what we&amp;#8217;ve identified to be things that either the community or the team feel are actionable tasks for this new major release. If there is something you would like to see, please take a moment and either raise a discussion on the above Jira ticket or join the discussion on &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;this topic&lt;/a&gt; on our mailing list.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I am happy to announce the release of Debezium 1.9.0.Beta1! This release includes many new features for Debezium Server, including Knative Eventing support and offset storage management with the Redis sink, multi-partitioned scaling for the SQL Server connector, and various of bugfixes and improvements. Overall, 56 issues have been fixed for this release. Let&amp;#8217;s take a closer look at a couple of them.</summary></entry><entry><title type="html">Debezium 1.9.0.Alpha2 Released</title><link href="https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Alpha2 Released"/><published>2022-02-09T00:00:00+00:00</published><updated>2022-02-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2022/02/09/debezium-1-9-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.9 series, &lt;strong&gt;1.9.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release includes support for Oracle 21c, improvements around Redis for Debezium Server, configuring the &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt; option, and a number of bug fixes around DDL parsers, build infrastructure, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;51 issues&lt;/a&gt; for this release. Let’s take a closer look at some of the highlights.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_oracle_21c&quot;&gt;Support for Oracle 21c&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium Oracle connector has been tested with the latest release of Oracle 21c, 21.3.0.0, and is compatible. If you use either the LogMiner or the Xstreams adapter, you should now be able to use Oracle&amp;#8217;s latest flagship version and stream change events without any changes. If you are on Oracle 12 or Oracle 19 and perform a database upgrade, your connector configuration should require no changes and remain compatible.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configuring_kafka_query_timeout_ms&quot;&gt;Configuring &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt;&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When using the Kafka Admin Client and issuing API calls, the default timeout is 3 seconds. The new &lt;code&gt;kafka.query.timeout.ms&lt;/code&gt; field can be used to provide a custom timeout to the Kafka Admin Client to avoid possible timeout problems in environments that may use TLS or SSL encryption or where network latency causes an unexpected timeout.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to the great work done by community member, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improvements_in_redis_for_debezium_server&quot;&gt;Improvements in Redis for Debezium Server&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have three new fields in the Redis support for Debezium Server&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;redis.retry.initial.delay.ms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;redis.retry.max.delay.ms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;batch.size&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Redis allows specifying a maximum memory limit using the &lt;code&gt;maxmemory&lt;/code&gt; configuration; however, if this field is not configured then Redis will continue to allocate memory. If all memory is consumed, an OutOfMemory exception occurs. The Redis sink now uses &lt;code&gt;redis.retry.initial.delay.ms&lt;/code&gt; and &lt;code&gt;redis.retry.max.delay.ms&lt;/code&gt; to set an initial and max-retry delay to be more resilient to this and connection-related issues. If you have or are experiencing such exceptions, we urge you to try these new settings to improve the sink&amp;#8217;s resilience and experience.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Pipeline-based transactions can substantially increase Redis queries. In order to leverage pipeline-based transactions, the &lt;code&gt;batch.size&lt;/code&gt; configuration option can be specified which will allow Redis to write batches of change records rather than each record one by one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to &lt;a href=&quot;https://github.com/spicy-sauc&quot;&gt;Yossi Shirizli&lt;/a&gt;, for these amazing improvements.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Some notable bug fixes and upgrades are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Suspected inconsistent documentation for 'Ad-hoc read-only Incremental snapshot' &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4171&quot;&gt;DBZ-4171&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle Logminer: snapshot&amp;#8594;stream switch misses DB changes in ongoing transactions &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4367&quot;&gt;DBZ-4367&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;DDL parsing issue: ALTER TABLE &amp;#8230;&amp;#8203; MODIFY PARTITION &amp;#8230;&amp;#8203; &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4649&quot;&gt;DBZ-4649&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;OracleSchemaMigrationIT fails with Xstream adapter &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4703&quot;&gt;DBZ-4703&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Migrating UI from webpack-dev-server v3 to v4 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4642&quot;&gt;DBZ-4642&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade postgres driver to version 42.3.2 &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4658&quot;&gt;DBZ-4658&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade to Quarkus 2.7.0.Final &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4677&quot;&gt;DBZ-4677&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Update shared UG deployment file for use with downstream OCP Install Guide &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4700&quot;&gt;DBZ-4700&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Indicate ROWID is not supported by XStream &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4702&quot;&gt;DBZ-4702&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental snapshots does not honor column case sensitivity &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4584&quot;&gt;DBZ-4584&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Build trigger issues &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4672&quot;&gt;DBZ-4672&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Cannot expand JSON payload with nested arrays of objects &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4704&quot;&gt;DBZ-4704&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We will also be backporting the critical bugfixes to the 1.8 branch and will release Debezium 1.8.1.Final later this week.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/isacandrei&quot;&gt;Andrei Isac&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/daha&quot;&gt;David Haglund&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuyar&quot;&gt;Farid Uyar&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jmks&quot;&gt;Jason Schweier&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/pmalon&quot;&gt;Paweł Malon&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/snigdhasjg&quot;&gt;Snigdhajyoti Ghosh&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.9 series, 1.9.0.Alpha2! This release includes support for Oracle 21c, improvements around Redis for Debezium Server, configuring the kafka.query.timeout.ms option, and a number of bug fixes around DDL parsers, build infrastructure, etc. Overall, the community fixed 51 issues for this release. Let’s take a closer look at some of the highlights.</summary></entry><entry><title type="html">Debezium 1.9.0.Alpha1 Released</title><link href="https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.9.0.Alpha1 Released"/><published>2022-01-26T00:00:00+00:00</published><updated>2022-01-26T00:00:00+00:00</updated><id>https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2022/01/26/debezium-1-9-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.9 series, &lt;strong&gt;1.9.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the new year comes a new release! The Debezium 1.9.0.Alpha1 release comes with quite a number of fixes and improvements, most notably improved metrics and Oracle ROWID data type support.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improved_metrics&quot;&gt;Improved Metrics&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium&amp;#8217;s connectors provide a wide range of metrics. We have expanded upon the &lt;code&gt;TotalNumberOfEventsSeen&lt;/code&gt; metric to provide a breakdown of those events by type. To support this endeavor, the following new metrics have been added:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfCreateEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfUpdateEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;TotalNumberOfDeleteEventsSeen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These metrics represent the number of &lt;em&gt;insert&lt;/em&gt;, &lt;em&gt;update&lt;/em&gt;, and &lt;em&gt;delete&lt;/em&gt; events respectively that have occurred since the start of the connector&amp;#8217;s streaming phase. So not only can you continue to get the total number of events aggregate, but you can now get a breakdown of that total by event type.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;oracle_rowid_data_type_support&quot;&gt;Oracle ROWID data type support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle users may elect to use a &lt;code&gt;ROWID&lt;/code&gt; data type column as an optimization to represent a relationship between the current row and the row identified by the &lt;code&gt;ROWID&lt;/code&gt; column value. Starting with this release, columns using the &lt;code&gt;ROWID&lt;/code&gt; data type can be captured by Debezium and emitted in change events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Oracle has two flavors of row identifier column data types, &lt;code&gt;ROWID&lt;/code&gt; and &lt;code&gt;UROWID&lt;/code&gt;. While these may be used interchangeably in some contexts, they&amp;#8217;re very different in the context of change data capture events. Although we&amp;#8217;ve added support for &lt;code&gt;ROWID&lt;/code&gt;, support for &lt;code&gt;UROWID&lt;/code&gt; remains unsupported at this time.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;JSON Payload not expanding when enabling it (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4457&quot;&gt;DBZ-4457&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;R/O incremental snapshot can blocks the binlog stream on restart (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4502&quot;&gt;DBZ-4502&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan doesn&amp;#8217;t work with underscores inside cache names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4526&quot;&gt;DBZ-4526&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Can&amp;#8217;t process column definition with length exceeding Integer.MAX_VALUE (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4583&quot;&gt;DBZ-4583&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Oracle connector can&amp;#8217;t find the SCN (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4597&quot;&gt;DBZ-4597&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Update Postgres JDBC driver to 42.3.1 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4374&quot;&gt;DBZ-4374&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Upgrade SQL Server driver to 9.4 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4463&quot;&gt;DBZ-4463&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.9.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;100 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/chanetd&quot;&gt;Dominique Chanet&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/hjwalt&quot;&gt;Hady Willi&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/JapuDCret&quot;&gt;JapuDCret&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/wndemon&quot;&gt;Nansen&lt;/a&gt;, &lt;a href=&quot;https://github.com/nathan-smit-1&quot;&gt;Nathan Smit&lt;/a&gt;, &lt;a href=&quot;https://github.com/0sc&quot;&gt;Oscar Romero&lt;/a&gt;, &lt;a href=&quot;https://github.com/poonam-meghnani&quot;&gt;Poonam Meghnani&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhongqishang&quot;&gt;Qishang Zhong&lt;/a&gt;, &lt;a href=&quot;https://github.com/sarumont&quot;&gt;Richard Kolkovich&lt;/a&gt;, &lt;a href=&quot;https://github.com/Sebruck&quot;&gt;Sebastian Bruckner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, and &lt;a href=&quot;https://github.com/AChangFeng&quot;&gt;胡琴&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have started an &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. Your feedback is invaluable so let us know what you&amp;#8217;d like to see added, changed, or improved!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the meantime, we&amp;#8217;re just getting started! There will be another 1.9 pre-release in the coming weeks, sticking with our 3-week cadence. You can also expect a bugfix release sometime this quarter for 1.8 as we continue to get community feedback.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.9 series, 1.9.0.Alpha1! With the new year comes a new release! The Debezium 1.9.0.Alpha1 release comes with quite a number of fixes and improvements, most notably improved metrics and Oracle ROWID data type support.</summary></entry><entry><title type="html">Debezium 1.8.0.Final Released</title><link href="https://debezium.io/blog/2021/12/16/debezium-1.8-final-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Final Released"/><published>2021-12-16T00:00:00+00:00</published><updated>2021-12-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/16/debezium-1.8-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/12/16/debezium-1.8-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my great pleasure to announce the release of Debezium &lt;strong&gt;1.8.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides a strong focus on the Debezium connector for MongoDB (more on that below), the 1.8 release brings support for Postgres' logical decoding messages, support for configuring SMTs and topic creation settings in the Debezium UI, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, the community has fixed &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4460?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.8.0.Alpha1%2C%201.8.0.Alpha2%2C%201.8.0.Beta1%2C%201.8.0.CR1%2C%201.8.0.Final)&quot;&gt;242 issues&lt;/a&gt; for this release. A big thank you to everyone who helped to make this release happen on time, sticking to our quarterly release cadence!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;improvements_to_the_debezium_connector_for_mongodb&quot;&gt;Improvements to the Debezium Connector for MongoDB&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The team has made a strong push to bring multiple new features and improvements to the &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html&quot;&gt;connector for MongoDB&lt;/a&gt;. It has now a brand-new capturing implementation based on MongoDB &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/&quot;&gt;Change Streams&lt;/a&gt;, which allows for some very exciting new functionalities. More specifically, the connector now&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Supports and has been tested with all the latest versions up to 5.0&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Can optionally &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html#mongodb-property-capture-mode&quot;&gt;emit the complete document state&lt;/a&gt; for update events (by means of the Change Streams capability of reading back the entire document affected by change)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provides support for &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/mongodb.html#_incremental_snapshot&quot;&gt;incremental snapshots&lt;/a&gt;, as already known from the other Debezium connectors (more details on that in a separate blog post)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Helps you to implement the outbox pattern for microservices data exchange by means of an &lt;a href=&quot;https://debezium.io/documentation/reference/stable/transformations/mongodb-outbox-event-router.html&quot;&gt;event routing SMT&lt;/a&gt;, specifically tailored to the event format emitted by this connector&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements&quot;&gt;Further Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Besides the work on the MongoDB connector, many improvements and feature additions have been made to the other connectors. Amongst other things,&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The names of transaction metadata topics are configurable&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium UI has been further built out (see &lt;a href=&quot;/blog/2021/11/23/debezium-ui-transforms/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/blog/2021/12/02/debezium-ui-topic-groups/&quot;&gt;here&lt;/a&gt; for demos of this)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Postgres now &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-message-events&quot;&gt;supports logical decoding messages&lt;/a&gt;, as emitted using the &lt;code&gt;pg_logical_emit_message()&lt;/code&gt; function&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;There&amp;#8217;s a new snapshot mode &lt;code&gt;SCHEMA_ONLY_RECOVERY&lt;/code&gt; for the Debezium connector for Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Oracle supports &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-truncate-events&quot;&gt;&lt;code&gt;TRUNCATE&lt;/code&gt; events&lt;/a&gt; and the &lt;code&gt;binary.handling.mode&lt;/code&gt; option for controlling how BLOB data is exported&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;There&amp;#8217;s support for &lt;a href=&quot;https://debezium.io/documentation/reference/stable/connectors/oracle.html#oracle-event-buffering-infinispan&quot;&gt;remote Infinispan caches&lt;/a&gt; for buffering large Oracle transactions&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for MySQL now can export table comments; it also supports heartbeat action queries and schema changes while an incremental snapshot is running; in addition, it received many improvements to its DDL parser and character set handling&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Debezium connector for Vitess supports transaction metadata events, has an improved &lt;code&gt;source&lt;/code&gt; struct, and supports re-sharding operations in a more flexible way&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please take a look at the original release announcements (&lt;a href=&quot;/blog/2021/10/27/debezium-1-8-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/11/11/debezium-1.8-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2021/11/30/debezium-1.8-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, and &lt;a href=&quot;/blog/2021/12/09/debezium-1.8-cr1-released/&quot;&gt;CR1&lt;/a&gt;) as well as the &lt;a href=&quot;/releases/1.8/release-notes&quot;&gt;1.8 release notes&lt;/a&gt; in order to learn more about these and other new features of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Many thanks to all the folks from the Debezium community which contributed code changes to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/abhishekkh&quot;&gt;Abhishek Hodavdekar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Ashique Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/bgaraue&quot;&gt;Biel Garau Estarellas&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/cburch824&quot;&gt;Christopher Burch&lt;/a&gt;, &lt;a href=&quot;https://github.com/kometen&quot;&gt;Claus Guttesen&lt;/a&gt;, &lt;a href=&quot;https://github.com/danielpetisme&quot;&gt;Daniel PETISME&lt;/a&gt;, &lt;a href=&quot;https://github.com/famartinrh&quot;&gt;Fabian Martinez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/gkorland&quot;&gt;Guy Korland&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/lairen&quot;&gt;Lairen Hightower&lt;/a&gt;, &lt;a href=&quot;https://github.com/lbroudoux&quot;&gt;Laurent Broudoux&lt;/a&gt;, &lt;a href=&quot;https://github.com/lujiefsi&quot;&gt;陆杰&lt;/a&gt;, &lt;a href=&quot;https://github.com/xenji&quot;&gt;Mario Mueller&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, &lt;a href=&quot;https://github.com/unalsurmeli&quot;&gt;Ünal Sürmeli&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;, and &lt;a href=&quot;https://github.com/ashulin&quot;&gt;Zongwen Li&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With another release shipped on schedule, it&amp;#8217;s time for a break and take a rest over the upcoming holidays. We&amp;#8217;ll be back to business in early January, with the planning for the 1.9 release being the first activity.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please let us know about any requirements and feature requests you may have. One area we&amp;#8217;d like to focus on for the next release is performance benchmarking and subsequentially applying performance improvements based on that. It also looks like there will be new community-led Debezium connector for a distributed NoSQL store; stay tuned for the details around this super-exciting development!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Later in the year, you also can expect the release of Debezium 2.0, where we&amp;#8217;ll focus on cleaning up some inconsistencies and removing some deprecated features such as wal2json support in the Debezium connector for Postgres.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For now, we wish everybody a happy holiday season, and, if you&amp;#8217;re into it, Merry Christmas! Please note the core team will be on PTO mostly for the coming weeks, so replies to emails, chat messages, issue reports, and pull requests will be slower than usual. Upwards and onwards!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mongodb"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my great pleasure to announce the release of Debezium 1.8.0.Final! Besides a strong focus on the Debezium connector for MongoDB (more on that below), the 1.8 release brings support for Postgres' logical decoding messages, support for configuring SMTs and topic creation settings in the Debezium UI, and much more. Overall, the community has fixed 242 issues for this release. A big thank you to everyone who helped to make this release happen on time, sticking to our quarterly release cadence!</summary></entry><entry><title type="html">Note on log4j Security</title><link href="https://debezium.io/blog/2021/12/14/note-on-log4j-security/" rel="alternate" type="text/html" title="Note on log4j Security"/><published>2021-12-14T00:00:00+00:00</published><updated>2021-12-14T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/14/note-on-log4j-security</id><content type="html" xml:base="https://debezium.io/blog/2021/12/14/note-on-log4j-security/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;TL,DR: Debezium is NOT affected by the recently disclosed remote code execution vulnerability in log4j2 (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2021-44228&quot;&gt;CVE-2021-44228&lt;/a&gt;); The log4j-1.2.17.jar shipped in Debezium&amp;#8217;s container images contains a class &lt;code&gt;JMSAppender&lt;/code&gt;, which is subject to a MODERATE vulnerability (&lt;a href=&quot;https://access.redhat.com/security/cve/CVE-2021-4104&quot;&gt;CVE-2021-4104&lt;/a&gt;). This appender is NOT used by default, i.e. access to log4j&amp;#8217;s configuration is required in order to exploit this CVE. As a measure of caution, we have decided to remove the &lt;code&gt;JMSAppender&lt;/code&gt; class from Debezium&amp;#8217;s container images as of version 1.7.2.Final, released today.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On Dec 10th, a remote code execution vulnerability in the widely used log4j2 library was published (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2021-44228&quot;&gt;CVE-2021-44228&lt;/a&gt;). Debezium, just like Apache Kafka and Kafka Connect, does not use log4j2 and therefore is NOT affected by this CVE.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apache Kafka, Kafka Connect and Apache ZooKeeper do use log4j 1.x though, which therefore is shipped as part of &lt;a href=&quot;https://quay.io/organization/debezium&quot;&gt;Debezium&amp;#8217;s container images&lt;/a&gt; for these components. On Dec 13th, a MODERATE vulnerability in log4j 1.x was published (&lt;a href=&quot;https://access.redhat.com/security/cve/CVE-2021-4104&quot;&gt;CVE-2021-4104&lt;/a&gt;), affecting the &lt;code&gt;JMSAppender&lt;/code&gt; class coming with log4j 1.x. This vulnerability &quot;allows a remote attacker to execute code on the server if the deployed application is configured to use &lt;code&gt;JMSAppender&lt;/code&gt; and to the attacker&amp;#8217;s JMS Broker&quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This appender is NOT used by default, i.e. &quot;this flaw ONLY affects applications which are specifically configured to use &lt;code&gt;JMSAppender&lt;/code&gt;, which is not the default, or when the attacker has write access to the Log4j configuration for adding &lt;code&gt;JMSAppender&lt;/code&gt; to the attacker&amp;#8217;s JMS Broker&quot;. If you are using &lt;code&gt;JMSAppender&lt;/code&gt;, you should verify and ensure that you are using trustworthy configuration values for its &lt;code&gt;TopicBindingName&lt;/code&gt; and &lt;code&gt;TopicConnectionFactoryBindingName&lt;/code&gt; settings.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using a JMS-based appender should only very rarely occur in the context of Apache Kafka, if at all. As a measure of caution, we have therefore decided to remove the &lt;code&gt;JMSAppender&lt;/code&gt; class from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; JAR contained in Debezium&amp;#8217;s container images for Apache Kafka, Kafka Connect, and Apache ZooKeeper. At the same time, we are also removing the &lt;code&gt;SocketServer&lt;/code&gt; class from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt;, which is subject to another, unrelated CVE (&lt;a href=&quot;https://nvd.nist.gov/vuln/detail/CVE-2019-17571&quot;&gt;CVE-2019-17571&lt;/a&gt;). This is a separate main class, not used in any way by Debezium, Kafka, Kafka Connect, or ZooKeeper, but we decided to not ship it any longer, thus making the Debezium container images not subject to this CVE either.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note that if you are running the Debezium connectors via other distributions of Apache Kafka and related components, the &lt;code&gt;JMSAppender&lt;/code&gt; and &lt;code&gt;SocketServer&lt;/code&gt; classes may be present in their &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt;, and you thus should make sure to either not use them at all, or only use them in safe way. Access to log4j&amp;#8217;s configuration should be secured in an appropriate way.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other distributables of Debezium, such as the individual connector archives, or the Debezium Server distribution, do not contain &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; and thus are NOT subject to the mentioned CVEs in any way.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The removal of the &lt;code&gt;JMSAppender&lt;/code&gt; and &lt;code&gt;SocketServer&lt;/code&gt; classes from the &lt;em&gt;log4j-1.2.17.jar&lt;/em&gt; shipped with Debezium&amp;#8217;s container images is effective as of Debezium 1.7.2.Final, which was released earlier today. We recommend to update to this version to all users.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you have any questions around this topic, please join the discussion on &lt;a href=&quot;https://groups.google.com/g/debezium/c/W3jYvNc-d5M&quot;&gt;this thread&lt;/a&gt; on the Debezium mailling list. If you have any other security-related concerns around Debezium, please do NOT publicly discuss them, but file a Jira issue with limited visibility in our &lt;a href=&quot;https://issues.redhat.com/browse/DBZ&quot;&gt;bug tracker&lt;/a&gt;, and we will follow up with you on this as quickly as possible.&lt;/p&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><summary type="html">TL,DR: Debezium is NOT affected by the recently disclosed remote code execution vulnerability in log4j2 (CVE-2021-44228); The log4j-1.2.17.jar shipped in Debezium&amp;#8217;s container images contains a class JMSAppender, which is subject to a MODERATE vulnerability (CVE-2021-4104). This appender is NOT used by default, i.e. access to log4j&amp;#8217;s configuration is required in order to exploit this CVE. As a measure of caution, we have decided to remove the JMSAppender class from Debezium&amp;#8217;s container images as of version 1.7.2.Final, released today. On Dec 10th, a remote code execution vulnerability in the widely used log4j2 library was published (CVE-2021-44228). Debezium, just like Apache Kafka and Kafka Connect, does not use log4j2 and therefore is NOT affected by this CVE.</summary></entry><entry><title type="html">Debezium 1.8.0.CR1 Released</title><link href="https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.CR1 Released"/><published>2021-12-09T00:00:00+00:00</published><updated>2021-12-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/12/09/debezium-1.8-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very excited to announce the release of Debezium &lt;strong&gt;1.8.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As were near the final release due out next week, this release focused heavily on bugfixes. Yet this release includes incremental snapshot support for MongoDB! Overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.CR%20ORDER%20BY%20component%20ASC&quot;&gt;34 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at some of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_incremental_snapshots&quot;&gt;MongoDB incremental snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting is a feature that we first introduced as a part of Debezium 1.6 nearly six months ago. The goals of incremental snapshots is to primarily address to very common user pain-points:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;the necessity to execute consistent snapshots before streaming can begin upon connector restart&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;inability to trigger full or partial snapshots after connector has begun streaming&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The implementation of this feature is based on a novel approach to snapshotting originally invented by the &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;DBLog Framework&lt;/a&gt; from Netflix. Debezium&amp;#8217;s implementation is described in the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;design document&lt;/a&gt;, and we also published an in-depth &lt;a href=&quot;https://debezium.io/blog/2021/10/07/incremental-snapshots/&quot;&gt;blog post&lt;/a&gt; discussing our implementation in greater detail.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With this release, we&amp;#8217;re excited to finally debut this feature for MongoDB. All Debezium core connectors now support this feature; an amazing milestone!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;d like to thank our very own &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt; and &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Kate Galieva&lt;/a&gt; from Shopify for their amazing efforts these last few months at refining and delivering on this feature as well as the entire community for testing and offering solid feedback.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With 1.8 Final release scheduled for next week, a vast majority of the changes in this release focus on stability and bugfixes. Some resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;[Oracle] None of log files contains offset SCN (SCN offset is no longer available in the online redo logs) (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3635&quot;&gt;DBZ-3635&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] Add support for truncate in Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4385&quot;&gt;DBZ-4385&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Oracle] Support &lt;code&gt;binary_handling_mode&lt;/code&gt; for Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4400&quot;&gt;DBZ-4400&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Debezium Server] Event Hubs exporter slow/Event data was too large (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4277&quot;&gt;DBZ-4277&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] Enforce consistent vgtid representation in Vitess connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4409&quot;&gt;DBZ-4409&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;[Vitess] VStream gRPC connection closed after being idle for a few minutes (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4389&quot;&gt;DBZ-4389&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4397&quot;&gt;DBZ-4397&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4402&quot;&gt;DBZ-4402&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4388&quot;&gt;DBZ-4388&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4396&quot;&gt;DBZ-4396&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.8/release-notes#release-1.8.0-cr1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, and &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the year is coming to close, we&amp;#8217;re actively preparing some holiday treats!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can expect 1.7.2.Final to be released early next week including many bugfixes and improvements. Additionally, we intend to release 1.8.0.Final in the middle of next week barring no unforeseen bug reports with CR1.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After the holiday break, we plan to be back in full swing on Debezium 1.9. Keep at eye on our &lt;a href=&quot;https://debezium.io/roadmap&quot;&gt;road map&lt;/a&gt; as we&amp;#8217;ll be updating this to include our focus for next quarter&amp;#8217;s release cycle.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re also actively working on the planning and scope of Debezium 2.0 which we intend to release sometime in 2022. We would love your feedback on any features or changes you&amp;#8217;d like to see so join the discussion on this topic on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m very excited to announce the release of Debezium 1.8.0.CR1! As were near the final release due out next week, this release focused heavily on bugfixes. Yet this release includes incremental snapshot support for MongoDB! Overall, not less than 34 issues have been fixed for this release. Let&amp;#8217;s take a closer look at some of them.</summary></entry><entry><title type="html">Configuring Automatic Topic Creation With the Debezium UI</title><link href="https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups/" rel="alternate" type="text/html" title="Configuring Automatic Topic Creation With the Debezium UI"/><published>2021-12-02T00:00:00+00:00</published><updated>2021-12-02T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups</id><content type="html" xml:base="https://debezium.io/blog/2021/12/02/debezium-ui-topic-groups/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team continues to add support for more features, allowing users to more easily configure connectors. In this article, we&amp;#8217;ll describe and demonstrate the UI support for topic automatic creation. Read further for more information, including a video demo!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;topic_auto_creation&quot;&gt;Topic Auto-creation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When you start a Debezium connector, the topics for the captured events are created by the Kafka broker based on a default, possibly customized, broker configuration (if &lt;code&gt;auto.create.topics.enable = true&lt;/code&gt;). But often when you use Debezium and Kafka in a production environment, you might choose to disable Kafka’s topic auto creation capability (&lt;code&gt;auto.create.topics.enable = false&lt;/code&gt;), or you want the connector topics to be configured differently from the default. In this case you&amp;#8217;ll need to create topics for Debezium’s captured data sources upfront.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Beginning with Kafka 2.6.0, Kafka Connect provides means of customizing the settings of specififc topics created by source connectors such as Debezium (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics&quot;&gt;KIP-158&lt;/a&gt;). If Kafka Connect topic creation is enabled (&lt;code&gt;topic.creation.enable = true&lt;/code&gt;), the Debezium UI now allows you to configure connector topics using the UI.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_connect_topic_creation&quot;&gt;Kafka Connect Topic Creation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Kafka Connect topic creation works with groups. There is a &lt;code&gt;default&lt;/code&gt; group, which is used when there is no other group defined that matches the topic.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can also define multiple custom topic groups, each with it&amp;#8217;s own configuration. Each group can specify its configuration parameters to customize how the matched topics of the group will be created. The custom groups will fall back to the default group settings for the required &lt;code&gt;replication.factor&lt;/code&gt; and &lt;code&gt;partitions&lt;/code&gt; properties. If the configuration for a custom topic group leaves other properties undefined, the values specified in the default group are not applied.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To find more detail about topic auto-creation with Debezium, please refer to the &lt;a href=&quot;/documentation/reference/configuration/topic-auto-create-config.html&quot;&gt;reference documentation&lt;/a&gt;. You can also refer to this &lt;a href=&quot;/blog/2020/09/15/debezium-auto-create-topics/&quot;&gt;blog post&lt;/a&gt; for a full example. Watch the following video for a quick demo of topic creation in the Debezium UI:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/C7K1V833eDk&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;self_contained_example&quot;&gt;Self-contained Example&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can try out topic auto-creation (and more) with our self-contained example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;UI demo&lt;/a&gt; - which is included under &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;debezium-examples&lt;/a&gt; on GitHub. The UI demo includes a Docker Compose file which brings up several sources with data as well as the UI. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;README file&lt;/a&gt; for more details on running the Debezium UI demo.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the Debezium UI, please refer to the &lt;a href=&quot;/documentation/reference/operations/debezium-ui.html&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;more_coming_soon&quot;&gt;More coming soon!&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Stay tuned for further improvements and new features in the UI in the coming releases. Support for SQL Server and Oracle connectors are coming soon!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team who have contributed in many ways: Ashique Ansari, Indra Shukla, René Kerner and Gunnar Morling!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Mark Drilling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongo"/><category term="debezium-ui"/><summary type="html">The Debezium UI team continues to add support for more features, allowing users to more easily configure connectors. In this article, we&amp;#8217;ll describe and demonstrate the UI support for topic automatic creation. Read further for more information, including a video demo!</summary></entry><entry><title type="html">Debezium 1.8.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Beta1 Released"/><published>2021-11-30T00:00:00+00:00</published><updated>2021-11-30T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/11/30/debezium-1.8-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.8.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release is packed with exciting new features like support for MongoDB 5.0, an outbox event router for the MongoDB connector and support for Postgres logical decoding messages, as well as tons of bugfixes and other improvements. Overall, not less than &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;63 issues&lt;/a&gt; have been fixed for this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s take a closer look at some of them.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_outbox_event_router&quot;&gt;MongoDB Outbox Event Router&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The outbox pattern is becoming more and more popular for &lt;a href=&quot;/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/&quot;&gt;exchanging data between microservices in a reliable way&lt;/a&gt;, without using unsafe &lt;em&gt;dual writes&lt;/em&gt; to a service&amp;#8217;s database and Apache Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the outbox pattern, instead of capturing changes from your actual business tables, you write messages to be sent to external consumers into a dedicated outbox table. This nicely decouples your internal data model from the message contracts used for communicating with external services, allowing you to develop and evolve these independently. Updates to your business tables and inserts into the outbox table are done within one database transaction, so that either both of these things are done, or none of them. Once a message has been persisted in the outbox table, Debezium can capture it from there and propagate it to any consumers using the usual at-least-once semantics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium provides support for implementing the outbox pattern via a special single message transform (SMT), the &lt;a href=&quot;/documentation/reference/stable/transformations/outbox-event-router.html&quot;&gt;outbox event router&lt;/a&gt;. This takes care of routing events from the single outbox table to different topics, based on a configurable column representing the aggregate type (in the parlance of domain driven design) the event is for. In addition, there is an &lt;a href=&quot;/documentation/reference/1.8/integrations/outbox.html&quot;&gt;extension for emitting outbox events&lt;/a&gt; from services built using &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;, a stack for building cloud-native microservices.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These things are complemented now by a new &lt;a href=&quot;/documentation/reference/1.8/transformations/mongodb-outbox-event-router.html&quot;&gt;event routing SMT&lt;/a&gt; which works with the Debezium connector for MongoDB. As the MongoDB connector&amp;#8217;s event format differs from the format of the Debezium connectors for relational databases, creating this separate SMT became necessary. Here&amp;#8217;s an example for configuring the SMT:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;outbox-connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector.class&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.mongodb.MongoDbConnector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tasks.max&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.hosts&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0/mongodb:27017&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.user&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;debezium&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb.password&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbz&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory.outboxevent&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.history.kafka.bootstrap.servers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;kafka:9092&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;outbox&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.route.topic.replacement&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;${routedByValue}.events&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.expand.json.payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.field.event.timestamp&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transforms.outbox.collection.fields.additional.placement&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type:header:eventType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.storage.StringConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.storage.StringConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here we&amp;#8217;re using the &lt;code&gt;MongoEventRouter&lt;/code&gt; SMT for capturing changes from the &lt;code&gt;inventory.outboxevent&lt;/code&gt; collection. Events could be written like so, using the MongoDB CLI as an example:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;new_order = { &quot;_id&quot; : ObjectId(&quot;000000000000000000000002&quot;), &quot;order_date&quot; : ISODate(&quot;2021-11-22T00:00:00Z&quot;), &quot;purchaser_id&quot; : NumberLong(1004), &quot;quantity&quot; : 1, &quot;product_id&quot; : NumberLong(107) } s = db.getMongo().startSession() s.startTransaction() s.getDatabase(&quot;inventory&quot;).orders.insert(new_order) s.getDatabase(&quot;inventory&quot;).outboxevent.insert({ _id : ObjectId(&quot;000000000000000000000001&quot;), aggregateid : new_order._id, aggregatetype : &quot;Order&quot;, type : &quot;OrderCreated&quot;, timestamp: NumberLong(1556890294484), payload : new_order }) s.commitTransaction()&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note how we&amp;#8217;re doing the inserts into a business collection (&quot;orders&quot;) and into the outbox collection (&quot;outboxevent&quot;) within a transaction, as supported by MongoDB since version 4.0. While we are using the actual order object in the outbox message itself in this particular case, we also could separate these things and choose another representation of the purchase orders in the outbox events.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The id of the order &lt;em&gt;aggregate&lt;/em&gt; is used as the message key in Kafka, ensuring consistent ordering of all outbox events pertaining to a given purchase order. The &lt;em&gt;aggregate type&lt;/em&gt; is used for determining the name of the topic to route events to, &lt;code&gt;Order.events&lt;/code&gt; in this example. The unique &lt;em&gt;id of the message&lt;/em&gt; itself is propagated as a header in the Kafka message, for instance allowing consumers to identify duplicated messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can find a &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/mongodb-outbox&quot;&gt;complete example&lt;/a&gt; for using this new MongoDB outbox event routing SMT in our &lt;a href=&quot;https://github.com/debezium/debezium-examples/&quot;&gt;demos repository&lt;/a&gt;. A massive thank you to &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, who not only provided the actual feature implementation itself, but also created this example.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Potential next steps around outbox support for the Debezium MongoDB connector may be adding support for MongoDB to the Quarkus outbox extension, and having an option to capture outbox events from sub-documents attached to an entity like &lt;code&gt;Order&lt;/code&gt;. That way, your application&amp;#8217;s data and the outbox message could be written as a single document (the application would otherwise ignore the outbox sub-document itself) and not requiring cross-document transactions. This idea is tracked via &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4319&quot;&gt;DBZ-4319&lt;/a&gt;; please let us know if you think that&amp;#8217;d be a useful addition or if you&amp;#8217;d even be interested in implementing it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;support_for_postgres_pg_logical_emit_message&quot;&gt;Support for Postgres' &lt;code&gt;pg_logical_emit_message()&lt;/code&gt;&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The versatility and flexibility of Postgres is legend; one of the interesting and lesser known features is the ability to write messages into the database&amp;#8217;s transaction log (WAL), without writing to a table actually. This is done via the &lt;a href=&quot;https://www.postgresql.org/docs/14/functions-admin.html#FUNCTIONS-REPLICATION&quot;&gt;&lt;code&gt;pg_logical_emit_message()&lt;/code&gt;&lt;/a&gt; function. &lt;a href=&quot;http://amitkapila16.blogspot.com/2021/09/logical-replication-improvements-in.html&quot;&gt;As of Postgres 14&lt;/a&gt;, these logical decoding messages can be captured using the &lt;code&gt;pgoutput&lt;/code&gt; plug-in, and Debezium also supports this event type as of this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Logical decoding messages are great for propagating contextual information associated to your transactions, without having to store this data in a table. This could for instance be &lt;a href=&quot;/blog/2019/10/01/audit-logs-with-change-data-capture-and-stream-processing/&quot;&gt;auditing metadata&lt;/a&gt; such as a business user who triggered some data change. Another potential use case is the outbox pattern mentioned above, which could be implemented without a dedicated outbox table, solely by writing outbox events to the WAL. That&amp;#8217;s advantageous for instance when thinking about house-keeping: there&amp;#8217;d be no need for removing messages from an outbox table after they have been propagated to Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&quot;Sending&quot; a logical decoding message is as simple as that:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; pg_logical_emit_message(&lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some-prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some text&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This emits a message which is transactional (&lt;code&gt;true&lt;/code&gt;), with the &quot;some-prefix&quot; prefix and &quot;some text&quot; as the message contents. The prefix can be used for grouping messages into logical contexts. Debezium uses the prefix as the Kafka message key, i.e. all messages with the same prefix will go into the same partition of the corresponding Kafka topic and thus will be propagated in the same order to downstream consumers as they were created.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Logical decoding messages are emitted by the Debezium Postgres connector using a new event type (&quot;m&quot;) and look like so (the message content is binary-encoded, using Base64 in this example):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Beta1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgresql&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;PostgreSQL_server&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1559033904863&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;txId&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;556&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;lsn&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;46523128&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;xmin&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1559033904961&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;some-prefix&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;c29tZSB0ZXh0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The message contents is an arbitrary payload, besides the textual represention you also can insert binary data here. It is the responsibility of the event producer to document the format, evolve it with backwards compatibility in mind, and exchange schema information with any clients. One great way of doing so would be to take advantage of a schema registry such as &lt;a href=&quot;https://www.apicur.io/registry/&quot;&gt;Apicurio&lt;/a&gt;. You also could think of using a standard like &lt;a href=&quot;https://cloudevents.io/&quot;&gt;CloudEvents&lt;/a&gt; for your logical decoding messages, which then for instance would allow an SMT such as the aforementioned outbox event router to take action based on defined attributes in the event structure.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about support for logical decoding messages in Debezium, please refer to the &lt;a href=&quot;/documentation/reference/1.8/connectors/postgresql.html#postgresql-message-events&quot;&gt;connector documentation&lt;/a&gt;. Thanks a lot to Lairen Hightower for implementing this feature!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes_and_changes&quot;&gt;Other Fixes and Changes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Further fixes and improvements in the 1.8.0.Beta1 release include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for configuring SMTs and topic creation settings in the Debezium UI; you can see the former in a quick video in &lt;a href=&quot;/blog/2021/11/23/debezium-ui-transforms/&quot;&gt;this post&lt;/a&gt;, and we&amp;#8217;ll share another demo of the topic creation UI later this week&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Transaction metadata events in the Vitess connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4355&quot;&gt;DBZ-4355&lt;/a&gt;); we also simplified its configuration by removing the dependency to vtctld (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4324&quot;&gt;DBZ-4324&lt;/a&gt;), added support for the &lt;code&gt;stop_on_reshard&lt;/code&gt; flag (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4295&quot;&gt;DBZ-4295&lt;/a&gt;), and provided the ability to specify a VGTID as the starting point for streaming (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4297&quot;&gt;DBZ-4297&lt;/a&gt;). All these changes were contributed by Yang Wu and Shichao from the Stripe engineering team, who agreed to step up as maintainers of this connector. Thanks a lot, and welcome!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;More flexible configuration of the Infinispan-based transaction buffer of the Debezium connector for Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4169&quot;&gt;DBZ-4169&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improved type mappings for &lt;code&gt;MONEY&lt;/code&gt; columns in Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1931&quot;&gt;DBZ-1931&lt;/a&gt;) and &lt;code&gt;INTERVAL&lt;/code&gt; columns in Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1539&quot;&gt;DBZ-1539&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Support for schema changes while doing an incremental snapshot with the Debezium connector for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4196&quot;&gt;DBZ-4196&lt;/a&gt;); thanks to Kate Galieva for this very useful improvement!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.8/release-notes#release-1.8.0-beta1&quot;&gt;release notes&lt;/a&gt; to learn more about these and further fixes in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As always, a big thank you to everyone contributing to this release:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Ashique Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/bgaraue&quot;&gt;Biel Garau Estarellas&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/danielpetisme&quot;&gt;Daniel Petisme&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/sugarcrm-jgminder&quot;&gt;Jacob Gminder&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/lairen&quot;&gt;Lairen Hightower&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/shichao-an&quot;&gt;Shichao An&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/TomBillietKlarrio&quot;&gt;Tom Billiet&lt;/a&gt;, &lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;, &lt;a href=&quot;https://github.com/vjuranek&quot;&gt;Vojtech Juranek&lt;/a&gt;, and &lt;a href=&quot;https://github.com/sonne5&quot;&gt;Yang Wu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the Beta1 release out, we&amp;#8217;re approaching the final phase of the 1.8 release cycle. You can expect a CR1 sometime next week, and depending on incoming issue reports, we may decide to cut the Final release either in the week before Christmas, or in the first week of 2022. In terms of features to be added, one thing we&amp;#8217;d love to get to is incremental snapshotting support for the MongoDB connector. We&amp;#8217;ll have to see whether this will make it in the remaining time, or whether this will have to wait for the Debezium 1.9 release. While the 1.8 release line is maturing, you also can look forward to the release of Debezium 1.7.2.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, we&amp;#8217;re also continuing our planning around Debezium 2.0, which should be released sometime next year. Please join the discussion on this topic on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.8.0.Beta1! This release is packed with exciting new features like support for MongoDB 5.0, an outbox event router for the MongoDB connector and support for Postgres logical decoding messages, as well as tons of bugfixes and other improvements. Overall, not less than 63 issues have been fixed for this release. Let&amp;#8217;s take a closer look at some of them.</summary></entry><entry><title type="html">Debezium UI support for Single Message Transformations</title><link href="https://debezium.io/blog/2021/11/23/debezium-ui-transforms/" rel="alternate" type="text/html" title="Debezium UI support for Single Message Transformations"/><published>2021-11-23T00:00:00+00:00</published><updated>2021-11-23T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/23/debezium-ui-transforms</id><content type="html" xml:base="https://debezium.io/blog/2021/11/23/debezium-ui-transforms/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team is pleased to announce support for Single Message Transformations (SMTs) in the Debezium UI!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our goal with the Debezium graphical user interface is to allow users to set up and operate connectors more easily. To that end, we have added support for Kafka Connect &lt;a href=&quot;https://kafka.apache.org/documentation/#connect_transforms&quot;&gt;single message transformations&lt;/a&gt; to the UI. Read futher for more information, and for a video demo of the new feature!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;single_message_transformations_smts&quot;&gt;Single Message Transformations (SMTs)&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Connectors can be configured with transformations to make lightweight per message modifications. &lt;a href=&quot;https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/&quot;&gt;Common SMT use cases&lt;/a&gt; include format conversions (e.g. different date formats and number types), message filtering and routing, handling of &quot;tombstone&quot; events, encryption/decryption, etc.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium provides several single message transformations (SMTs) that you can use to either modify records before they are sent to Apache Kafka (by applying them to the Debezium connectors), or when they are read from Kafka by a sink connector. For instance we provide SMTs for extracting only the &quot;after&quot; part from change events and propagate that one in a flat row format and SMTs for routing the events from an outbox table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the SMTs coming with Debezium, please refer to the &lt;a href=&quot;/documentation/reference/transformations/index.html&quot;&gt;reference documentation&lt;/a&gt;. And thanks to the support for SMTs in the Debezium UI, setting them up is easier than ever; For a short demo of this feature in action, see the following video:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;responsive-video&quot;&gt; &lt;iframe width=&quot;1600&quot; height=&quot;900&quot; src=&quot;https://www.youtube.com/embed/F5o0Zyjlpeg&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Fun fact: this video is the very first entry to our brand-new &lt;a href=&quot;https://www.youtube.com/channel/UCk8VviAaxNZkakaL1hPykIg&quot;&gt;Debezium YouTube channel&lt;/a&gt;! We recommend you subscribe to the channel to never miss any new videos.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;trying_it_out_yourself&quot;&gt;Trying It Out Yourself&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We have created a self-contained example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;UI demo&lt;/a&gt;, which is included under &lt;a href=&quot;https://github.com/debezium/debezium-examples&quot;&gt;debezium-examples&lt;/a&gt; on Github. The UI demo includes a Docker Compose file which brings up several sources with data as well as the UI. Please refer to the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/ui-demo&quot;&gt;README file&lt;/a&gt; for more details on running the Debezium UI demo.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about the Debezium UI, please refer to the &lt;a href=&quot;/documentation/reference/stable/operations/debezium-ui.html&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;next_steps&quot;&gt;Next Steps&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We plan to continue with improvements and new features for the UI in the coming releases. Some items under consideration:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Incorporation of more Debezium connector types, such as the ones for SQL Server and Oracle&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Addition and improvement of connector metrics and monitoring&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add capability for viewing and editing connector properties after creation&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&amp;#8230;&amp;#8203;And more!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;d also be very happy to learn about your requirements and feedback on the Debezium UI. Please let us know in the comments below, or send a message to our &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;A big thank you to the team who have contributed in many ways: Ashique Ansari, Indra Shukla, René Kerner and Gunnar Morling!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Mark Drilling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="mongo"/><category term="debezium-ui"/><summary type="html">The Debezium UI team is pleased to announce support for Single Message Transformations (SMTs) in the Debezium UI! Our goal with the Debezium graphical user interface is to allow users to set up and operate connectors more easily. To that end, we have added support for Kafka Connect single message transformations to the UI. Read futher for more information, and for a video demo of the new feature!</summary></entry><entry><title type="html">Debezium 1.8.0.Alpha2 Released</title><link href="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha2 Released"/><published>2021-11-11T00:00:00+00:00</published><updated>2021-11-11T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/11/11/debezium-1.8-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;MySQL support for heartbeat action queries&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Configurable transaction topic name&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, the latest &lt;code&gt;1.2&lt;/code&gt; tag of the &lt;a href=&quot;https://hub.docker.com/repository/docker/debezium/tooling&quot;&gt;debezium/tooling&lt;/a&gt; image is available. The newest version includes all the latest tools, including &lt;a href=&quot;https://github.com/kcctl/kcctl&quot;&gt;kcctl&lt;/a&gt;, a super simple, cuddly CLI for Apache Kafka Connect.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release does include several breaking changes. Please see the &lt;a href=&quot;https://debezium.io/releases/1.8/release-notes#release-1.8.0-alpha2&quot;&gt;release notes&lt;/a&gt; for details on what changed and how to upgrade.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mysql_heartbeat_action_query_support&quot;&gt;MySQL heartbeat action query support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A heartbeat action query can be enabled by supplying a &lt;code&gt;heartbeat.action.query&lt;/code&gt; configuration option in the connector&amp;#8217;s configuration. This property is meant to supply a SQL statement that the connector will execute periodically.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The initial implementation of the heartbeat action query was specifically for PostgreSQL to handle dealing with WAL growth under specific conditions. But a heartbeat action query has many uses and is entirely connector or even user driven.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, you may want to notify downstream consumers that your MySQL topology has changed by supplying consumers with an event with the GTID. The following configuration shows how to capture changes from the heartbeat action query table that can then be consumed easily by your CDC pipeline.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table.include.list&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;gtid_history&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;heartbeat.action.query&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;INSERT INTO gtid_history( select * from mysql.gtid_executed )&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;configurable_transaction_topic_names&quot;&gt;Configurable transaction topic names&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium transaction metadata topic had previously used a relatively non-configurable naming convention of &lt;code&gt;&amp;lt;database.server.name&amp;gt;.transaction&lt;/code&gt;. While it was possible to manipulate the topic name using a single message transform (SMT) as a workaround, we felt that allowing this to be a bit more flexible in Debezium proper made sense.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A new configuration option, &lt;code&gt;transaction.topic.prefix&lt;/code&gt;, has been introduced that allows the connector configuration to adjust the naming of the transaction metadata topic. The configuration option value specifies what will be used as a direct replacement for the `&amp;lt;database.server.name&amp;gt;~ portion of the topic name. If this configuration option is not supplied, the prior topic naming behavior will continue to be used; requiring no changes for existing connector deployments.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Invalid default value error on captured table DDL with default value &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3710&quot;&gt;DBZ-3710&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incremental snapshot doesn&amp;#8217;t work without primary key &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4107&quot;&gt;DBZ-4107&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Signal based incremental snapshot is failing if database name contains dash &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4244&quot;&gt;DBZ-4244&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha2%20ORDER%20BY%20component%20ASC&quot;&gt;45 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/abhishekkh&quot;&gt;Abhishek Hodavdekar&lt;/a&gt;, &lt;a href=&quot;https://github.com/ahus1&quot;&gt;Alexander Schwartz&lt;/a&gt;, &lt;a href=&quot;https://github.com/dlg99&quot;&gt;Andrey Yegorov&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/josetesan&quot;&gt;Jose Luis&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, and &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_1_7&quot;&gt;Debezium 1.7&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition to this release, we also released Debezium 1.7.1.Final, a bugfix update for the 1.7 series. The 1.7.1.Final release includes many of the bugfixes in the 1.8 series that have been done since 1.7.0.Final. For more information on what changed in 1.7.1.Final, please see the &lt;a href=&quot;https://debezium.io/releases/1.7/release-notes#release-1.7.1-final&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The holiday season is upon us, but we intend to stick to our release cadence as closely as possible. If you haven&amp;#8217;t already taken an opportunity, we&amp;#8217;d love your feedback on the &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. In the meantime, you can expect the first beta release of 1.8 in a couple of weeks.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.8 series, 1.8.0.Alpha2! With the holiday season just around the corner, the team&amp;#8217;s release schedule remains steadfast. While Debezium 1.8.0.Alpha2 delivers quite a lot of bugfixes and minor changes, there are a few notable changes: MySQL support for heartbeat action queries Configurable transaction topic name In addition, the latest 1.2 tag of the debezium/tooling image is available. The newest version includes all the latest tools, including kcctl, a super simple, cuddly CLI for Apache Kafka Connect.</summary></entry><entry><title type="html">Debezium 1.8.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.8.0.Alpha1 Released"/><published>2021-10-27T00:00:00+00:00</published><updated>2021-10-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/10/27/debezium-1-8-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, &lt;strong&gt;1.8.0.Alpha1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;mongodb_change_streams_support&quot;&gt;MongoDB Change Streams Support&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;MonogoDB &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/&quot;&gt;change streams&lt;/a&gt; allow an application or client access to real-time change data capture events without the complexity of tailing the oplog. This functionality was first introduced by the MongoDB engine in version 3.6; however the functionality was limited. Starting with MongoDB 4.0, change streams now captures changes across a database, replica set, or even a sharded cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium added change streams support to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Enable compatibility with MongoDB 5 (not yet tested, see future work below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide full document output in update events (see below).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Abstract from internal (and potentially changing) specifics of the oplog format, making this new implementation a potential replacement for oplog reading in the future.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In order to use change stream support with Debezium, you must use MongoDB 4.0 or later.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;enablement&quot;&gt;Enablement&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium for MongoDB exposes a new configuration property called &lt;code&gt;capture.mode&lt;/code&gt;. The capture mode specifies how the connector should obtain change events from the MongoDB database. The valid options are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;dlist&quot;&gt; &lt;dl&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;oplog&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by tailing the oplog; this is the legacy behavior.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will not contain the full message; only changed fields are part of the event.&lt;/p&gt; &lt;/dd&gt; &lt;dt class=&quot;hdlist1&quot;&gt;&lt;code&gt;change_streams_update_full&lt;/code&gt;&lt;/dt&gt; &lt;dd&gt; &lt;p&gt;Specifies that changes should be captured by using MongoDB change streams. Updates will contain a full snapshot of the current record in the event. This is the new default for the connector.&lt;/p&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock warning&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-warning&quot; title=&quot;Warning&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The new &lt;code&gt;change_streams&lt;/code&gt; and &lt;code&gt;change_streams_update_full&lt;/code&gt; capture modes are incubating and the format and details surrounding how these work may change in future releases.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;event_changes&quot;&gt;Event changes&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Using our tutorial from our &lt;a href=&quot;https://www.github.com/debezium-examples&quot;&gt;examples repository&lt;/a&gt;, lets take a look at the differences in these capture modes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, lets add a new record to our &lt;code&gt;customers&lt;/code&gt; collection. Using the MongoDB shell, this can be done by running the following command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.insert([ { _id : NumberLong(&amp;quot;1005&amp;quot;), first_name : 'Bob', last_name : 'Hopper', email : 'thebob@example.com', unique_id : UUID() } ]);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This will generate a change event but as you&amp;#8217;ll see if you inspect the topic, the contents of the event are not all that different in this release. Since the event is an insert, all field values provided in the emitted event.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;During updates, this is where we can see the capture mode differences in action. Now modify the customer&amp;#8217;s first and last name using the MongoDB shell with this command:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;shell&quot;&gt;db.customers.update( { _id:NumberLong(&amp;quot;1005&amp;quot;) }, { $set: { first_name: &amp;quot;Bobby&amp;quot;, last_name: &amp;quot;Copper&amp;quot; } });&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This modifies the first and last name of the customer with id &lt;code&gt;1005&lt;/code&gt;. The following sections show what each event will look like for the given capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;oplog&quot;&gt;Oplog&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;oplog&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$v&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: 1, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$set&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: { &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;3510217852938498600&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635291250803&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event&amp;#8217;s after field has no value. Instead, the event provides values for patch and filter that describe limited details about what changed in the source document. Since the event only provides details about what fields have changed and not the values for unchanged fields, this may not be ideal for certain consumers that require knowledge of the full document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams&quot;&gt;Change Streams&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292448736&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The emitted event has a slightly different set of values than the legacy oplog output. As shown above, the event does not have a value in the after, patch, or filter fields. Instead, the event relies on describing the changes to the document&amp;#8217;s fields in the &lt;code&gt;updateDescription&lt;/code&gt; structure. While this provides a bit more detail about values that may have been set and even unset due to an update, this may still not be ideal for some consumers that need values for all fields of the source document.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect3&quot;&gt; &lt;h4 id=&quot;change_streams_full_document&quot;&gt;Change Streams Full Document&lt;/h4&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following shows a snippet of an update event when using the &lt;code&gt;change_streams_update_full&lt;/code&gt; capture mode.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{ &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$numberLong&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1005&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;thebob@example.com&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;unique_id&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: {&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$binary&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;KRywzYp5RneNu8DUmhQHAQ==&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;$type&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;04&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;patch&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updateDescription&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;removedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;updatedFields&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Bobby&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Copper&lt;/span&gt;&lt;span class=&quot;char&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;truncatedArrays&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: { &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1.8.0.Alpha1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;mongodb&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878000&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;snapshot&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;rs0&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;collection&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tord&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;stxnid&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; }, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ts_ms&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1635292878244&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;transaction&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt; } }&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This capture mode is nearly identical to the &lt;code&gt;change_streams&lt;/code&gt; mode except with one critical difference, the &lt;code&gt;after&lt;/code&gt; field is populated with a complete snapshot of document. This mode is great for consumers that rely on having all fields in the source document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Please see the &lt;a href=&quot;https://docs.mongodb.com/manual/changeStreams/#lookup-full-document-for-update-operations&quot;&gt;MongoDB documentation&lt;/a&gt; for more details on full document mode semantics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The full document mode is based on a re-selection of the source document when MongoDB provides the change event over the change stream to the connector. In cases where multiple changes to the same document happen within close proximity of one another, each event may have the same full document representation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;future_work&quot;&gt;Future work&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In conjunction to the work already done with MongoDB change streams, we recognize there is much work that remains which includes testing the new change streams implementations against MongoDB 5 and updating the connector documentation to reflect these new changes. You can expect this and much more as a part of the next preview release. As per the updated Debezium 1.8 &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt;, we&amp;#8217;re also planning to add support for incremental snapshots to the Debezium connector for MongoDB, as well as a variant of the outbox event router which supports the event format of this connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;other_fixes&quot;&gt;Other Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There were quite a number of bugfixes and stability changes in this release, some noteworthy are:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Row hashing in LogMiner Query not able to differentiate between rows of a statement (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3834&quot;&gt;DBZ-3834&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk select statement is incorrect for combined primary key in incremental snapshot (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3860&quot;&gt;DBZ-3860&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;column.the mask.hash.hashAlgorithm.with&amp;#8230;&amp;#8203;. data corruption occurs when using this feature (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4033&quot;&gt;DBZ-4033&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Infinispan SPI throws NPE with more than one connector configured to the same Oracle database (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4064&quot;&gt;DBZ-4064&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.8.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;82 issues&lt;/a&gt; were fixed for this release. A big thank you to all the contributors from the community who worked on this release: &lt;a href=&quot;https://github.com/cburch824&quot;&gt;Christopher Burch&lt;/a&gt;, &lt;a href=&quot;https://github.com/kometen&quot;&gt;Claus Guttesen&lt;/a&gt;, &lt;a href=&quot;https://github.com/famartinrh&quot;&gt;Fabian Martinez&lt;/a&gt;, &lt;a href=&quot;https://github.com/gkorland&quot;&gt;Guy Korland&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/juanfiallo&quot;&gt;Juan Fiallo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/lbroudoux&quot;&gt;Laurent Broudoux&lt;/a&gt;, &lt;a href=&quot;https://github.com/PlugaruT&quot;&gt;Plugaru Tudor&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/sgc109&quot;&gt;Sungho Hwang&lt;/a&gt;, &lt;a href=&quot;https://github.com/unalsurmeli&quot;&gt;Ünal Sürmeli&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/zxpzlp&quot;&gt;Willie Zhu&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashulin&quot;&gt;Zongwen Li&lt;/a&gt;, and &lt;a href=&quot;https://github.com/lujiefsi&quot;&gt;陆杰&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the end of the year is just around the corner, we intend to press forward with the same vigor. We have started an &lt;a href=&quot;https://groups.google.com/u/1/g/debezium/c/X17AUmQ88-E&quot;&gt;open discussion&lt;/a&gt; regarding Debezium 2.0 on the mailing list. Your feedback is invaluable so let us know what you&amp;#8217;d like to see added, changed, or improved! In the meantime, you can also expect a minor bugfix release to the Debezium 1.7 series next week, as well as another preview release of the Debezium 1.8 series in a couple more weeks. Happy Streaming!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.8 series, 1.8.0.Alpha1! With the colors of Autumn upon us, the team has been hard at work painting lines of code for this release. With Debezium 1.8.0.Alpha1 comes quite a number of improvements but most notably is the new native MongoDB 4.0 change streams support!</summary></entry><entry><title type="html">Using Debezium to Create a Data Lake with Apache Iceberg</title><link href="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/" rel="alternate" type="text/html" title="Using Debezium to Create a Data Lake with Apache Iceberg"/><published>2021-10-20T00:00:00+00:00</published><updated>2021-10-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg</id><content type="html" xml:base="https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Let&amp;#8217;s start with a short description of the data lake concept: A &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_lake&quot;&gt;data lake&lt;/a&gt; is &quot;usually a central store of data including raw copies of source system data, sensor data, social data etc&quot;. You can store your data as-is, without having to first process the data and then run different types of analytics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_server_iceberg&quot;&gt;Debezium Server Iceberg&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As operational data typically resides in a relational database or a NoSQL data store, the question is how the data can be propagated into the data lake. This is where the &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; project comes in: Based on Debezium and Apache Iceberg, it lets you process realtime data change events from a source database and upload them to any object storage supported by Iceberg. So let&amp;#8217;s take a closer look at these two projects.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;/&quot;&gt;Debezium&lt;/a&gt; is an open source distributed platform for change data capture. Debezium extracts change events from a database&amp;#8217;s transaction log and delivers them to consumers via event streaming platforms, using different formats such as JSON, Apache Avro, Google Protocol Buffers and others. Most of the time, Debezium is used with Apache Kafka and Kafka Connect. But via Debezium Server, also users of other messaging infrastructure like Kinesis, Google Pub/Sub, Pulsar can benefit from Debezium&amp;#8217;s change data capture capabilities. Here you can see the currently &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_sink_configuration&quot;&gt;supported destinations&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Apache Iceberg&lt;/a&gt; is an &quot;open table format for huge analytic datasets. Iceberg adds tables to compute engines including Spark, Trino, PrestoDB, Flink and Hive, using a high-performance table format which works just like a SQL table.&quot; It supports ACID inserts as well as row-level deletes and updates. It provides a Java API to manage table metadata, like schemas and partition specs, as well as data files that store table data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Apache Iceberg has a notion of &lt;a href=&quot;https://iceberg.apache.org/spec/#version-2-row-level-deletes&quot;&gt;data and delete files&lt;/a&gt;. Data files are the files Iceberg uses behind the scene to keep actual data. Delete files are the immutable files to encode rows that are deleted in existing data files. This is how Iceberg deletes/replaces individual rows in immutable data files without rewriting the files. In the case of Debezium Server Iceberg, these are immutable &lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Apache Parquet&lt;/a&gt; files, a format which is designed as an &quot;efficient as well as performant flat columnar storage format of data compared to row based files like CSV or TSV files&quot;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;the_apache_iceberg_consumer&quot;&gt;The Apache Iceberg Consumer&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium Server provides an SPI to &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_implementation_of_a_new_sink&quot;&gt;implement new sink adapters&lt;/a&gt;, and this is the extension point used for creating the Apache Iceberg consumer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/debezium-iceberg.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. Architecture Overview: Debezium Server and Apache Iceberg&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Iceberg consumer converts CDC change events to Iceberg data files and commits them to a destination table using the Iceberg Java API. It maps each Debezium source topic to a destination Iceberg table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a given Iceberg destination table is not found, the consumer creates it using the change event schema. Additionally, the event schema is used to map the change event itself to an equivalent Iceberg record. Because of this, the &lt;code&gt;debezium.format.value.schemas.enable&lt;/code&gt; configuration option must be set. Once the Debezium change event has been recorded into an Iceberg record, the schema is removed from the data.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;On a high level, change events processed as follows. For each received batch of events:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The events are grouped per destination Iceberg table; each group contains list of a change events coming from a single source table, sharing the same data schema&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;For each destination, events are converted to Iceberg records&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Iceberg records are saved as Iceberg data and delete files (delete files are created only if the consumer is running with upsert mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The files are committed to the destination Iceberg table (i.e. uploaded to the destination storage)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The processed change events marked as processed with Debezium&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here is a complete example configuration for using Debezium Server with the Iceberg adaptor:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.type=iceberg # run with append mode debezium.sink.iceberg.upsert=false debezium.sink.iceberg.upsert-keep-deletes=true debezium.sink.iceberg.table-prefix=debeziumcdc_ debezium.sink.iceberg.table-namespace=debeziumevents debezium.sink.iceberg.fs.defaultFS=s3a://S3_BUCKET); debezium.sink.iceberg.warehouse=s3a://S3_BUCKET/iceberg_warehouse debezium.sink.iceberg.type=hadoop debezium.sink.iceberg.catalog-name=mycatalog debezium.sink.iceberg.catalog-impl=org.apache.iceberg.hadoop.HadoopCatalog # enable event schemas debezium.format.value.schemas.enable=true debezium.format.value=json # complex nested data types are not supported, do event flattening. unwrap message! debezium.transforms=unwrap debezium.transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState debezium.transforms.unwrap.add.fields=op,table,source.ts_ms,db debezium.transforms.unwrap.delete.handling.mode=rewrite debezium.transforms.unwrap.drop.tombstones=true&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;upsert_and_append_modes&quot;&gt;Upsert and Append Modes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, the Iceberg consumer is running in upsert mode (&lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;). This means that when a row is updated in the source table, the destination is row replaced with the new updated version. And when a row is deleted from the source, it also is deleted from the destination. When using upsert mode, data at the destination is kept identical to the source data. The upsert mode uses the Iceberg equality delete feature and creates delete files using the key of the Debezium change data events (derived from the primary key of the source table). To avoid duplicate data, deduplication is done on each batch and only the last version of the record kept. For example in a single batch of events, the same record could appear twice: once when it is inserted, and another time when it gets updated. With upsert mode, always the last extracted version of the record is stored in Iceberg.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Note that when a source table doesn&amp;#8217;t define a primary key and there is also no key information available by other means (e.g. a unique key or a custom message key defined in Debezium), the consumer uses the &lt;code&gt;append&lt;/code&gt; mode for this table (see below).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;keeping_deleted_records_with_upsert_mode&quot;&gt;Keeping Deleted Records With Upsert Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For some use cases it is useful to keep deleted records as a soft delete. This is possible by setting the &lt;code&gt;debezium.sink.iceberg.upsert-keep-deletes&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt;. This setting will keep the latest version of deleted records in the destination Iceberg table. Setting it to false will remove deleted records from the destination table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;append_mode&quot;&gt;Append Mode&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This is the most straightforward operation mode, enabled by setting &lt;code&gt;debezium.sink.iceberg.upsert&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. When using Debezium Server Iceberg with append mode, all received records are appended to the destination table. No data deduplication or deletion of records is done. With append mode it is possible to analyze entire change history of a record.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It also is possible to consume realtime events and do &lt;a href=&quot;https://iceberg.apache.org/maintenance/&quot;&gt;data compaction&lt;/a&gt; afterwards with a separate compaction job. Iceberg supports compacting data and metadata files to increase performance.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;optimizing_batch_sizes&quot;&gt;Optimizing Batch Sizes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium extracts and delivers database events in real time, and this could cause too frequent commits to the tables in Iceberg, generating too many small files. This is not optimal for batch processing, especially when a near-realtime data feed is sufficient. To avoid this problem, it is possible to increase the batch size per commit.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When enabling the &lt;code&gt;MaxBatchSizeWait&lt;/code&gt; mode, the Iceberg consumer uses Debezium metrics to optimize the batch size. It periodically retrieves the current size of Debezium&amp;#8217;s internal event queue and waits until it has reached &lt;code&gt;max.batch.size&lt;/code&gt;. During the wait time, Debezium events are collected in memory (in Debezium&amp;#8217;s internal queue). That way, each commit (set of events processed) processes more records and consistent batch size. The maximum wait and check interval are controlled via the &lt;code&gt;debezium.sink.batch.batch-size-wait.max-wait-ms&lt;/code&gt; and &lt;code&gt;debezium.sink.batch.batch-size-wait.wait-interval-ms&lt;/code&gt; properties. These settings should be configured together with Debezium&amp;#8217;s &lt;code&gt;debezium.source.max.queue.size&lt;/code&gt; and &lt;code&gt;debezium.source.max.batch.size&lt;/code&gt; properties.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here&amp;#8217;s an example for all the related settings:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;debezium.sink.batch.batch-size-wait=MaxBatchSizeWait debezium.sink.batch.batch-size-wait.max-wait-ms=60000 debezium.sink.batch.batch-size-wait.wait-interval-ms=10000 debezium.sink.batch.metrics.snapshot-mbean=debezium.postgres:type=connector-metrics,context=snapshot,server=testc debezium.sink.batch.metrics.streaming-mbean=debezium.postgres:type=connector-metrics,context=streaming,server=testc # increase max.batch.size to receive large number of events per batch debezium.source.max.batch.size=50000 debezium.source.max.queue.size=400000&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;creating_additional_data_lake_layers&quot;&gt;Creating Additional Data Lake Layers&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At this point, the raw layer of the data lake has been loaded, including data deduplication and near realtime pipeline features. Building curated layers on top (sometimes called analytics layer or data warehouse layer) becomes very straightforward and simple. At the analytics layer, raw data is prepared to meet the analytics requirement; usually raw data is reorganized, cleaned, versioned (see example below), aggregated, and business logic may be applied. Using SQL through scalable processing engines is the most common way of doing this kind of data transformation.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, someone could easily use &lt;a href=&quot;https://Iceberg.apache.org/spark-writes/&quot;&gt;Spark SQL&lt;/a&gt;(or PrestoDB, Trino, Flink, etc) to load a &lt;a href=&quot;https://en.wikipedia.org/wiki/Slowly_changing_dimension&quot;&gt;slowly changing dimension&lt;/a&gt;, the most commonly used data warehouse table type:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;MERGE &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;USING&lt;/span&gt; ( &lt;span class=&quot;comment&quot;&gt;-- new data to insert&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; customer_id, name, effective_date, to_date(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;9999-12-31&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;yyyy-MM-dd&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers &lt;span class=&quot;keyword&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;-- update exiting records. close end_date&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; t.customer_id, t.name, t.effective_date, s.effective_date &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; end_date &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; debezium.consumers s &lt;span class=&quot;keyword&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; dwh.consumers t &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; ) s &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; s.customer_id = t.customer_id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; s.effective_date = t.effective_date &lt;span class=&quot;comment&quot;&gt;-- close last records/versions.&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; t.current = &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;, t.end_date = s.end_date &lt;span class=&quot;comment&quot;&gt;-- insert new versions and new data&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;NOT&lt;/span&gt; MATCHED &lt;span class=&quot;keyword&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt;(customer_id, name, current, effective_date, end_date) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt;(s.customer_id, s.name, &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;, s.effective_date, s.end_date);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Additional data lake layers may need to be updated periodically with new data. The easiest way of doing this is using SQL update or delete statements. These SQL operations are also &lt;a href=&quot;https://iceberg.apache.org/spark-writes/&quot;&gt;supported by Iceberg&lt;/a&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; prod.db.table &lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; ...; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.table &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; ts &amp;gt;= &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-05-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; ts &amp;lt; &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;2020-06-01 00:00:00&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;; &lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.orders &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; t1 &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXISTS&lt;/span&gt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; order_id &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.returned_orders &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; t1.order_id = order_id; &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; prod.db.all_events &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; session_time = &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;, ignored = &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; session_time &amp;lt; (&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;predefined&quot;&gt;min&lt;/span&gt;(session_time) &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; prod.db.good_events));&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;wrap_up_and_contributions&quot;&gt;Wrap-Up and Contributions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Based on Debezium and Apache Iceberg, &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server Iceberg&lt;/a&gt; makes it very simple to set up a low-latency data ingestion pipeline for your data lake. The project completely open-source, using the Apache 2.0 license. Debezium Server Iceberg still is a young project and there are things to improve. Please feel free to test it, give feedback, open feature requests or send pull requests. You can see more examples and start experimenting with Iceberg and Spark using &lt;a href=&quot;https://github.com/ismailsimsek/iceberg-examples&quot;&gt;this project&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Ismail Simsek</name></author><category term="debezium"/><category term="iceberg"/><category term="datalake"/><category term="lakehouse"/><summary type="html">Today, it is a common practise to build data lakes for analytics, reporting or machine learning needs. In this blog post we will describe a simple way to build a data lake. The solution is using a realtime data pipeline based on Debezium, supporting ACID transactions, SQL updates and is highly scalable. And it&amp;#8217;s not required to have Apache Kafka or Apache Spark applications to build the data feed, reducing complexity of the overall solution.</summary></entry><entry><title type="html">Incremental Snapshots in Debezium</title><link href="https://debezium.io/blog/2021/10/07/incremental-snapshots/" rel="alternate" type="text/html" title="Incremental Snapshots in Debezium"/><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/07/incremental-snapshots</id><content type="html" xml:base="https://debezium.io/blog/2021/10/07/incremental-snapshots/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the major improvements in Debezium starting in version 1.6 is support for &lt;a href=&quot;/documentation/reference/connectors/mysql.html#_ad_hoc_snapshot&quot;&gt;incremental snapshots&lt;/a&gt;. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;why_incremental_snapshots&quot;&gt;Why Incremental Snapshots?&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One of the biggest pain points in Debezium since its inception was the sup-optimal support for changes to the captured tables list. As a user, you create a new connector with a list of tables to be captured (&lt;code&gt;table.include.list&lt;/code&gt; and related options); at a later point in time, it may become necessary to adjust this configuration, so to capture further tables which where not part to CDC initially. If it suffices to only &lt;em&gt;stream&lt;/em&gt; changes from these tables, then the problem is pretty simple to solve. But what if you also need to capture the existing contents of the tables?&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Capturing existing data in tables is traditionally done by Debezium in the &lt;em&gt;snapshot&lt;/em&gt; phase. This phase is executed once upon the first connector start-up, and its objective is capturing consistent data at a point of time (transforming data at rest into data in motion). This can be a fairly long operation, and by definition, it must be executed completely or not at all - a bit like transaction semantics. This means that if the snapshot is not completed due to a connector restart for instance, it must be re-executed from scratch, and everything already done is thrown away. Also, while the snapshot is taken, any data modifications that are executed in parallel in the database are not streamed until the snapshot has been completed. This could lead to problems with database resources for very large snapshots, as transaction logs must be kept available until the streaming is started.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are thus ended up with three issues to be solved:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The near-impossibility of adding of additional tables to the captured tables list, if existing data must be streamed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A long-running process for consistent snapshotting that cannot be terminated or resumed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Change data streaming being blocked till the snapshot is completed&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;legacy_solutions&quot;&gt;Legacy Solutions&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The problem was well known, and over time we developed workarounds and also ideated possible improvements and new solutions. As a workaround, the general recommendation was to use a multiple connector approach. The user was asked to:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Stop the connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Create a new one to take the snapshot of new tables (using the &lt;code&gt;initial_only&lt;/code&gt; snapshotting mode)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;When completed, stop the new connector&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Reconfigure and start the old connector with newly captured tables added to the list&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This method somewhat did the trick, but is very clumsy, and all the questions around snapshot consistency mentioned above still apply.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next step was a community contribution into the Debezium connector for MySQL via &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-175&quot;&gt;DBZ-175&lt;/a&gt;. It was based on the notion of having multiple binary log readers in place. One reader would capture the originally configured tables, while the other one will snapshot the new tables and then capture changes from the new tables. The latter reader would catch up with the original one, and then they would be reconciled and merged into a single one.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The code was working well, but it never left the incubating stage, as the process itself was quite complex and liable to errors in corner cases. Last but not least, it was an ingenious approach, but unfortunately not portable to other connectors.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;watermark_based_snapshots&quot;&gt;Watermark-based Snapshots&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In late 2019, the Netflix engineering team announced that they had developed an in-house change data capture framework. They also came up with an innovative solution of executing concurrent snapshots using &lt;em&gt;watermarking&lt;/em&gt;, described in the paper &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt; DBLog: A Watermark Based Change-Data-Capture Framework&lt;/a&gt; by Andreas Andreakis and Ioannis Papapanagiotou.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The main idea behind this approach is that change data streaming is executed continuously together with snapshotting. The framework inserts low and high watermarks into the transaction log (by writing to the source database) and between those two points, a part of the snapshotted table is read. The framework keeps a record of database changes in between the watermarks and reconciles them with the snapshotted values, if the same records are snapshotted and modified during the window.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This means that the data is snapshotted in chunks - no lengthy process at the connector start, and also in case of crashes or a controlled termination of the connector, the snapshotting can be resumed since the last completed chunk.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As per Netflix, the implementation is provided for MySQL and PostgreSQL databases.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;signalling_table&quot;&gt;Signalling Table&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Before moving to Debezium&amp;#8217;s implementation of the watermark-based snapshotting approach, a small detour is needed.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Sometimes it can be useful to control Debezium from the outside, so to force it to execute some requested action. Let&amp;#8217;s suppose it is necessary to re-snapshot an already snapshotted table - a so-called &lt;em&gt;ad-hoc&lt;/em&gt; snapshot. The user would need to send a command to Debezium to pause the current operation and do the snapshot. For that purpose, Debezium defines the concept &lt;em&gt;signals&lt;/em&gt;, issued via a &lt;a href=&quot;/documentation/reference/configuration/signalling.html&quot;&gt;signalling table&lt;/a&gt;. This is a special table, designated for communication between the user and Debezium. Debezium captures the table and when the user requires a certain operation to be executed, they simply write a record to the signalling table (sending a signal). Debezium will receive the captured change and then execute the required action.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_in_debezium&quot;&gt;Incremental Snapshotting in Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we became aware of DBLog&amp;#8217;s snapshotting approach, we decided that the method is a universal one and that we could try to adopt it in Debezium, too. Also as we share a lot of codebase among the different connectors (using the Debezium connector framework) our objective was to implement it in the Debezium core component, so that all connectors would benefit from the feature at once. The design and implementation were driven by the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;DDD-3&lt;/a&gt; Debezium design document.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting in Debezium is available in form of ad-hoc snapshots. The user does not configure the connector to execute the snapshot, but instead they use the signalling mechanism to send a snapshot signal and thus trigger a snapshot of a set of tables. The signal in question is called &lt;code&gt;execute-snapshot&lt;/code&gt; and the signal message follows the format of:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data-collections&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-1&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-2&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;&amp;lt;table-id-3&amp;gt;&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;]}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a table snapshot is requested, then Debezium will do the following:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Obtain the largest primary key in the table; this is the snapshot endpoint, and its value is stored in the connector offsets&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Split the table into chunks based on the primary key&amp;#8217;s total order and of a size as prescribed by the &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; configuration option&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When a chunk is queried, a dynamic SQL statement is built, selecting the next &lt;code&gt;incremental.snapshot.chunk.size&lt;/code&gt; records, whose primary keys are larger than the last one from the previous chunk (or the first primary key for the first chunk) and which are smaller or equal to the recorded maximum primary key.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;admonitionblock note&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td class=&quot;icon&quot;&gt; &lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class=&quot;content&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The default chunk size is 1,024. You may increase the value for efficiency purposes (a smaller total number of snapshot queries will be executed), but this should be balanced with the increased memory consumption needed for the buffer. It is recommended to do some experimentation in your own environment to identify the setting working best for your situation.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The reading of a chunk is a slightly complicated procedure:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The chunk query is executed and the chunk content is read into memory&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is sent&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Why is this needed? Why it is not enough to just query the database? The answers lie in the following picture:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/transactions.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 1. The transaction isolation&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium is not the only process accessing the database. We can expect a multitude of processes accessing the database concurrently, potentially accessing the same records which currently are snapshotted. As shown in the picture, any changes to data are written to the transaction log based on the commit order. As it is not possible to precisely time the chunk read transaction to identify potential conflicts, the open and close window events are added to demarcate the time in which the conflicts can happen. Debezium&amp;#8217;s task is the deduplication of those conflicts.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For that purpose, Debezium records all events generated by the chunk into a buffer. When the &lt;code&gt;snapshot-window-open&lt;/code&gt; signal is received, then all events coming from the transaction log are checked whether they belong to the snapshotted table(s). If yes, then the buffer is checked whether it contains the primary key. If yes, then the snapshot event is dropped from the buffer, as this is a potential conflict. And as it is not possible to correctly order the snapshot and transaction log events, only the transaction log event is kept. When the &lt;code&gt;snapshot-window-close&lt;/code&gt; signal is received, the remaining snapshot events in the buffer are sent downstream.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The following image shows an example of how such a buffer works and how are the transaction log events are filtered before being sent downstream:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-10-07-incremental-snapshots/windowprocessing.png&quot; style=&quot;max-width:70%;&quot; class=&quot;responsive-image&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;strong&gt;Figure 2. The buffer in action&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Records K2, K3, and K4 exist already in the database. Before the snapshot window opens, records K1 gets inserted, K2 updated, and K3 deleted. These events are sent downstream as they are read from the log. The snapshot windows opens, and its query selects K1, K2, and K4 into the buffer. While the window is open, the deletion of K4 is retrieved from the transaction log; the snapshot event for K4 is dropped from the buffer and the deletion event is sent downstream. K5 and K6 are inserted, which is retrieved from the log, corresponding events will be emitted. Depending on the specific timing, there may be read events for them in the buffer too (in the image that&amp;#8217;s the case for K5), which would be dropped. When the snapshot window closes, the remaining snapshot events for K1 and K2 will be emitted from the buffer.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;connector_restarts&quot;&gt;Connector Restarts&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By now we have demonstrated that, using the notion of incremental snapshots, the same table(s) can be snapshotted repeatedly, if and when needed, while the connector is running. We have shown that its execution does not stop streaming from the transaction log. The last item is pausing and continuation of the process.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When an incremental snapshot is running, then incremental snapshot context is added to each of the message offsets. The context is represented by three pieces of information:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The list of tables to be snapshotted where the first one is the one currently snapshotted&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The maximum primary key of the table&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The primary key of the last event from incremental snapshot sent downstream&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;These three items are enough to resume the snapshot after a connector restart, be it intentionally or after a crash. Upon connector start, the component responsible for the snapshotting reads the data from the offsets. It initializes its internal state and resumes snapshotting after the last processed event. Note that any records which were inserted or updated while the connector wasn&amp;#8217;t running, will be processed via the regular stream reading, i.e. they are not subject to the ongoing snapshot.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This approach ensures the robustness of the process, resilience to restarts and crashes, and minimizes the number of redelivered events (at-least-once delivery semantics still apply).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;limitations&quot;&gt;Limitations&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The incremental snapshotting has few drawbacks in comparison to the initial consistent snapshot:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The snapshotted table must contain primary keys&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is deleted from the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and a &lt;code&gt;delete&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only a &lt;code&gt;delete&lt;/code&gt; event is be received&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;If an event is updated in the table during the snapshotting process, then one of these situations can happen:&lt;/p&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A &lt;code&gt;read&lt;/code&gt; event and an &lt;code&gt;update&lt;/code&gt; event are received by downstream consumers&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;An &lt;code&gt;update&lt;/code&gt; event and &lt;code&gt;read&lt;/code&gt; event are received (note the opposite order)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Only an &lt;code&gt;update&lt;/code&gt; event is received (in case the update happened within the chunk that would have emitted the &lt;code&gt;read&lt;/code&gt; event, causing that &lt;code&gt;read&lt;/code&gt; event to be discarded during de-duplication)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In general, &lt;code&gt;read&lt;/code&gt; events should not be understood as the initial state of the record in a table, but as the state of the record at an arbitrary point of time. Semantics for consumers are slightly changed in comparison to traditional initial snapshots in Debezium, while it will be guaranteed that a consumer has received the complete data set after an incremental snapshot has been completed, there won&amp;#8217;t be &lt;code&gt;read&lt;/code&gt; (snapshot) events for all records, but it could be &lt;code&gt;update&lt;/code&gt; events instead. The same goes for &lt;code&gt;delete&lt;/code&gt; events: consumers must be prepared to receive such events for records they had not seen before.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;demo&quot;&gt;Demo&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Having discussed the general concepts, let&amp;#8217;s explore things a bit more in an example. We will use our standard &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial&quot;&gt;tutorial deployment&lt;/a&gt; to demonstrate ad-hoc incremental snapshotting. We are using &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#using-postgres&quot;&gt;PostgreSQL&lt;/a&gt; as the source database. For this demo, you will need multiple terminal windows.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the beginning we will start the deployment, create the signalling table, and start the connector:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 1 - start the deployment # Start the deployment export DEBEZIUM_VERSION=1.7 docker-compose -f docker-compose-postgres.yaml up # Terminal 2 # Create a signalling table echo &amp;quot;CREATE TABLE inventory.dbz_signal (id varchar(64), type varchar(32), data varchar(2048))&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Start Postgres connector, capture only customers table and enable signalling curl -i -X POST -H &amp;quot;Accept:application/json&amp;quot; -H &amp;quot;Content-Type:application/json&amp;quot; http://localhost:8083/connectors/ -d @- &amp;lt;&amp;lt;EOF { &amp;quot;name&amp;quot;: &amp;quot;inventory-connector&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.debezium.connector.postgresql.PostgresConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;database.hostname&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.port&amp;quot;: &amp;quot;5432&amp;quot;, &amp;quot;database.user&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.password&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;database.dbname&amp;quot; : &amp;quot;postgres&amp;quot;, &amp;quot;database.server.name&amp;quot;: &amp;quot;dbserver1&amp;quot;, &amp;quot;schema.include&amp;quot;: &amp;quot;inventory&amp;quot;, &amp;quot;table.include.list&amp;quot;: &amp;quot;inventory.customers,inventory.dbz_signal&amp;quot;, &amp;quot;signal.data.collection&amp;quot;: &amp;quot;inventory.dbz_signal&amp;quot; } } EOF&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;From the log we see that as per the &lt;code&gt;table.include.list&lt;/code&gt; setting only one table is snapshotted, &lt;code&gt;customers&lt;/code&gt;:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;connect_1 | 2021-09-24 13:38:21,781 INFO Postgres|dbserver1|snapshot Snapshotting contents of 1 tables while still in transaction [io.debezium.relational.RelationalSnapshotChangeEventSource]&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In the next step we will simulate continuous activity in the database:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 3 # Continuously consume messages from Debezium topic for customers table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.customers # Terminal 4 # Modify records in the database via Postgres client docker-compose -f docker-compose-postgres.yaml exec postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;i=0; while true; do psql -U $POSTGRES_USER postgres -c \&amp;quot;INSERT INTO customers VALUES(default,'name\$i','surname\$i','email\$i')\&amp;quot;; ((i++)); done&amp;quot;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The topic &lt;code&gt;dbserver1.inventory.customers&lt;/code&gt; receives a continuous stream of messages. Now the connector will be reconfigured to also capture the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre&gt;# Terminal 5 # Add orders table among the captured curl -i -X PUT -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; http://localhost:8083/connectors/inventory-connector/config -d @- &amp;lt;&amp;lt;EOF { &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;, &quot;tasks.max&quot;: &quot;1&quot;, &quot;database.hostname&quot;: &quot;postgres&quot;, &quot;database.port&quot;: &quot;5432&quot;, &quot;database.user&quot;: &quot;postgres&quot;, &quot;database.password&quot;: &quot;postgres&quot;, &quot;database.dbname&quot; : &quot;postgres&quot;, &quot;database.server.name&quot;: &quot;dbserver1&quot;, &quot;schema.include&quot;: &quot;inventory&quot;, &quot;table.include.list&quot;: &quot;inventory.customers,inventory.dbz_signal,inventory.orders&quot;, &quot;signal.data.collection&quot;: &quot;inventory.dbz_signal&quot; } EOF&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As expected, there are no messages for the &lt;code&gt;orders&lt;/code&gt; table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now let&amp;#8217;s start an incremental ad-hoc snapshot by sending a signal. The snapshot messages for the &lt;code&gt;orders&lt;/code&gt; table are delivered to the &lt;code&gt;dbserver1.inventory.orders&lt;/code&gt; topic. Messages for the &lt;code&gt;customers&lt;/code&gt; table are delivered without interruption.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Terminal 5 # Send the signal echo &amp;quot;INSERT INTO inventory.dbz_signal VALUES ('signal-1', 'execute-snapshot', '{\&amp;quot;data-collections\&amp;quot;: [\&amp;quot;inventory.orders\&amp;quot;]}')&amp;quot; | docker-compose -f docker-compose-postgres.yaml exec -T postgres env PGOPTIONS=&amp;quot;--search_path=inventory&amp;quot; bash -c &amp;quot;psql -U $POSTGRES_USER postgres&amp;quot; # Check messages for orders table docker-compose -f docker-compose-postgres.yaml exec kafka /kafka/bin/kafka-console-consumer.sh \ --bootstrap-server kafka:9092 \ --from-beginning \ --property print.key=true \ --topic dbserver1.inventory.orders&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you were to modify any record in the &lt;code&gt;orders&lt;/code&gt; table while the snapshot is running, this would be either emitted as a &lt;code&gt;read&lt;/code&gt; event or as an &lt;code&gt;update&lt;/code&gt; event, depending on the exact timing and sequence of things.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As the last step, let&amp;#8217;s terminate the deployed systems and close all terminals:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;bash&quot;&gt;# Shut down the cluster docker-compose -f docker-compose-postgres.yaml down&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post, we have discussed the motivation for the notion of incremental snapshotting, as introduced by the DBLog paper. We have reviewed the methods used in the past to achieve the described functionality. Then we dived into the deep waters of the implementation of this novel snapshotting approach in Debezium, and in the end we tried to use it live.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We hope you will find incremental snapshotting useful and we look forward to your feedback, experiences, and use cases. In a future blog post, we&amp;#8217;ll talk about the support for incremental snaphots of read-only databases (supported by the Debezium MySQL connector as of version 1.7) and how to trigger ad-hoc snapshots using a Kafka topic as the means of signalling instead of a database table.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="db2"/><category term="snapshots"/><summary type="html">One of the major improvements in Debezium starting in version 1.6 is support for incremental snapshots. In this blog post we are going to explain the motivation for this feature, we will do a deep dive into the implementation details, and we will also show a demo of it.</summary></entry><entry><title type="html">Debezium 1.7.0.Final Released</title><link href="https://debezium.io/blog/2021/10/04/debezium-1-7-final-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.Final Released"/><published>2021-10-04T00:00:00+00:00</published><updated>2021-10-04T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/10/04/debezium-1-7-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/10/04/debezium-1-7-final-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s with great pleasure that I am announcing the release of Debezium &lt;strong&gt;1.7.0.Final&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Key features of this release include substantial improvements to the notion of incremental snapshotting (as introduced in Debezium 1.6), a web-based user Debezium user interface, NATS support in Debezium Server, and support for running Apache Kafka without ZooKeeper via the Debezium Kafka container image.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Also in the wider Debezium community some exciting things happened over the last few months; For instance, we saw a CDC connector for ScyllaDB &lt;a href=&quot;/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/&quot;&gt;based on the Debezium connector framework&lt;/a&gt;, and there&amp;#8217;s work happening towards a &lt;a href=&quot;https://github.com/memiiso/debezium-server-iceberg&quot;&gt;Debezium Server connector for Apache Iceberg&lt;/a&gt; (details about this coming soon in a guest post on this blog).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;incremental_snapshotting_improvements&quot;&gt;Incremental Snapshotting Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Introduced in Debezium 1.6 and based on a &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;paper published by Netflix Engineering&lt;/a&gt;, incremental snapshotting addresses many long-standing feature requests around initial snapshots, such as the ability to re-snapshot specific tables, support for modifications to the include/exclude filter configuration, and resumeability of snapshots after a connector restart.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For Debezium 1.7, incremental snapshotting has been further improved and stabilized. The &lt;a href=&quot;/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL connector&lt;/a&gt; now allows incremental snapshotting for databases without write access by the connector, which is very useful when pointing Debezium to read-only replicas. Ad-hoc snapshots can now not only be triggered via the signal table as before, but also by sending a message to a specific Kafka topic, again strengthening the support for read-only scenarios. A big thank you to &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Kate Galieva&lt;/a&gt; of &lt;a href=&quot;https://shopify.engineering/capturing-every-change-shopify-sharded-monolith&quot;&gt;Shopify Engineering&lt;/a&gt; for these contributions!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Incremental snapshotting is now also supported by the &lt;a href=&quot;/documentation/reference/connectors/oracle.html&quot;&gt;Debezium connector for Oracle&lt;/a&gt;. Another snapshotting improvement relates to non-incremental snapshots: filtered columns are now excluded from snapshot select statements right away, which improves performance of the connector when excluding large BLOB columns for instance.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;ll follow up with a more detailed blog post around incremental snapshotting shortly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;debezium_ui&quot;&gt;Debezium UI&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Debezium UI is part of our efforts to further simplify the experience of getting started with and operating Debezium. &lt;a href=&quot;/documentation/reference/operations/debezium-ui.html&quot;&gt;The UI&lt;/a&gt; lets you configure and start new connectors, examine the state of running connectors, and more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-08-12-debezium-ui/CreateConnectorStep2.png&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium UI team has been working tirelessly to build out this web app, with support for setting up transformations (SMTs) and topic auto creation settings coming up shortly. In the meantime please take a look at the &lt;a href=&quot;/blog/2021/08/12/introducing-debezium-ui/&quot;&gt;blog post&lt;/a&gt; initially announcing the UI to learn more about it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_improvements&quot;&gt;Further Improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other improvements in Debezium 1.7 include &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_nats_streaming&quot;&gt;support for NATS Streaming in Debezium Server&lt;/a&gt;, as well as support for Apache Kafka 2.8 in the Debezium container images. You even can use the Debezium container image for Apache Kafka to &lt;a href=&quot;https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/&quot;&gt;get your feet wet&lt;/a&gt; with running Apache Kafka without ZooKeeper!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;There&amp;#8217;s support for MySQL &lt;code&gt;INVISIBLE&lt;/code&gt; columns, an off-heap implementation of the transaction buffer of the Debezium connector for Oracle, allowing to process large long-running transactions, and much more. There also have been made several very nice performance improvements; a shout-out to Naveen Kumar for his continued help here, including the creation of several JMH benchmarks for measuring the impact of improvements to specific performance-sensitive areas of the code base.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4067?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.7.0.Alpha1%2C%201.7.0.Beta1%2C%201.7.0.CR1%2C%201.7.0.CR2%2C%201.7.0.Final&quot;&gt;206 issues&lt;/a&gt; have been fixed for the 1.7 final and preview releases. You can find out more in the original announcement posts for Debezium &lt;a href=&quot;/blog/2021/08/02/debezium-1-7-alpha1-released/&quot;&gt;1.7.0.Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/08/25/debezium-1-7-beta1-released/&quot;&gt;1.7.0.Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2021/09/16/debezium-1-7-cr1-released/&quot;&gt;1.7.0.CR1&lt;/a&gt;, and &lt;a href=&quot;/blog/2021/09/23/debezium-1-7-cr2-released/&quot;&gt;1.7.0.CR2&lt;/a&gt;. Please refer to the &lt;a href=&quot;/releases/1.7/release-notes#release-1.7.0-final&quot;&gt;release notes&lt;/a&gt; of Debezium 1.7.0.Final for the list of issues resolved since CR2 as well as procedures for upgrading from earlier versions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium project couldn&amp;#8217;t exist without its amazing community of contributors from different countries all around the world! A big thank you to everyone contributing to this release in one way or another! Kudos to the following individuals from the community which contributed to the Debezium core repository in 1.7:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;, &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashmeet13&quot;&gt;Ashmeet Lamba&lt;/a&gt;, &lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/diff-by-default&quot;&gt;Blake Peno&lt;/a&gt;, &lt;a href=&quot;https://github.com/umanwizard&quot;&gt;Brennan Vincent&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/d3vel0per&quot;&gt;Dhrubajyoti G&lt;/a&gt;, &lt;a href=&quot;https://github.com/sirscratchalot&quot;&gt;Erik Malm&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;, &lt;a href=&quot;https://github.com/indraraj&quot;&gt;Indra Shukla&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/jornargelo&quot;&gt;Jorn Argelo&lt;/a&gt;, &lt;a href=&quot;https://github.com/judahrand&quot;&gt;Judah Rand&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/kyleyj&quot;&gt;Kyley Jex&lt;/a&gt;, &lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt;, &lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;, &lt;a href=&quot;https://github.com/xaka&quot;&gt;Pavel Strashkin&lt;/a&gt;, &lt;a href=&quot;https://github.com/raphaelauv&quot;&gt;Raphael Auv&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/tavancini&quot;&gt;Thiago Avancini&lt;/a&gt;, &lt;a href=&quot;https://github.com/Thiago-Dantas&quot;&gt;Thiago Dantas&lt;/a&gt;, &lt;a href=&quot;https://github.com/tinntsea&quot;&gt;Tin Nguyen&lt;/a&gt;, &lt;a href=&quot;https://github.com/tommyk-gears&quot;&gt;Tommy Karlsson&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, &lt;a href=&quot;https://github.com/elgca&quot;&gt;WenChao Ke&lt;/a&gt;, &lt;a href=&quot;https://github.com/jjiey&quot;&gt;yangsanity&lt;/a&gt;, &lt;a href=&quot;https://github.com/spicy-sauce&quot;&gt;Yossi Shirizli&lt;/a&gt;, &lt;a href=&quot;https://github.com/zhangyuan&quot;&gt;Yuan Zhang&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;https://github.com/zregvart&quot;&gt;Zoran Regvart&lt;/a&gt;, &lt;a href=&quot;https://github.com/ili-zh&quot;&gt;李宗文&lt;/a&gt;, and &lt;a href=&quot;https://github.com/pkgonan&quot;&gt;민규 김&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The next Debezium release, 1.8, is planned for the end of the year. The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; is still in flux, but some of the features we plan to address are support for MongoDB change streams (so to support MongoDB 5.0), improved support for MariaDB, and the ability to compact large database history topics.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We&amp;#8217;re also planning to further build out the Debezium UI, continue the work on the Debezium connector for Oracle and making the SQL Server connector capable of dealing with multiple databases at once, and much more. Please let us know about your feature requests via the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><summary type="html">It&amp;#8217;s with great pleasure that I am announcing the release of Debezium 1.7.0.Final! Key features of this release include substantial improvements to the notion of incremental snapshotting (as introduced in Debezium 1.6), a web-based user Debezium user interface, NATS support in Debezium Server, and support for running Apache Kafka without ZooKeeper via the Debezium Kafka container image. Also in the wider Debezium community some exciting things happened over the last few months; For instance, we saw a CDC connector for ScyllaDB based on the Debezium connector framework, and there&amp;#8217;s work happening towards a Debezium Server connector for Apache Iceberg (details about this coming soon in a guest post on this blog).</summary></entry><entry><title type="html">Debezium 1.7.0.CR2 Released</title><link href="https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.CR2 Released"/><published>2021-09-23T00:00:00+00:00</published><updated>2021-09-23T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/09/23/debezium-1-7-cr2-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are very happy to announce the release of Debezium &lt;strong&gt;1.7.0.CR2&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we are moving ahead towards the final release we include mostly bugfixes. Yet this release contains important performance improvements and a new feature for read-only MySQL incremental snapshots.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;kafka_based_signalling&quot;&gt;Kafka based signalling&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Recent releases provided a new feature for MySQL - incremental snapshotting from a read-only database. The snapshot process is based on GTIDs and does not need writing to signalling table. The problem is that triggering the process still required the existence and write access to the signalling table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Now it is possible to send the signal via Kafka topic. This feature is available when the MySQL connector is configured with &lt;code&gt;read-only = true&lt;/code&gt;. Please refer to the documentation for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;performance_improvements&quot;&gt;Performance improvements&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt; identified multiple performance issues in the Debezium&amp;#8217;s core critical path. He benchmarked them and provided pull requests solving them. If you are interested in details, please check &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4015&quot;&gt;DBZ-4015&lt;/a&gt; and &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3887&quot;&gt;DBZ-3887&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we&amp;#8217;re approaching the 1.7 Final release, most changes have been centered around bug fixing and maturing the codebase. Some of the resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Connection failure after snapshot wasn&amp;#8217;t executed for a while (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3951&quot;&gt;DBZ-3951&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Incorrect incremental snapshot DDL triggers snapshot that generates unending inserts against signalling table (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-4013&quot;&gt;DBZ-4013&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3917&quot;&gt;DBZ-3917&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-4017&quot;&gt;DBZ-4017&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.7.0.CR2&quot;&gt;14 issues&lt;/a&gt; have been fixed for this release. A big thank you to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/vivekwassan&quot;&gt;Vivek Wassan&lt;/a&gt;, and &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are on a good path towards &lt;code&gt;1.7.0.Final&lt;/code&gt; by the end of the next week.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="outbox"/><summary type="html">We are very happy to announce the release of Debezium 1.7.0.CR2! As we are moving ahead towards the final release we include mostly bugfixes. Yet this release contains important performance improvements and a new feature for read-only MySQL incremental snapshots.</summary></entry><entry><title type="html">Deep Dive Into a Debezium Community Connector: The Scylla CDC Source Connector</title><link href="https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/" rel="alternate" type="text/html" title="Deep Dive Into a Debezium Community Connector: The Scylla CDC Source Connector"/><published>2021-09-22T17:10:00+00:00</published><updated>2021-09-22T17:10:00+00:00</updated><id>https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector</id><content type="html" xml:base="https://debezium.io/blog/2021/09/22/deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;At ScyllaDB, we develop a high-performance NoSQL database &lt;a href=&quot;https://www.scylladb.com/&quot;&gt;Scylla&lt;/a&gt;, API-compatible with Apache Cassandra, Amazon DynamoDB and Redis. Earlier this year, we introduced support for &lt;a href=&quot;https://docs.scylladb.com/using-scylla/cdc/cdc-intro/&quot;&gt;Change Data Capture&lt;/a&gt; in Scylla 4.3. This new feature seemed like a perfect match for integration with the Apache Kafka ecosystem, so we developed the &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector&quot;&gt;Scylla CDC Source Connector&lt;/a&gt; using the Debezium framework. In this blogpost we will cover the basic structure of Scylla’s CDC, reasons we chose the Debezium framework and design decisions we made.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;cdc_support_in_scylla&quot;&gt;CDC support in Scylla&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Change Data Capture (CDC) allows users to track data modifications in their Scylla database. It can be easily enabled/disabled on any Scylla table. Upon turning it on, a log of all modifications (INSERTs, UPDATEs, DELETEs) will be created and automatically updated.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we designed our implementation of CDC in Scylla, we wanted to make it easy to consume the CDC log. Therefore, the CDC log is stored as a regular Scylla table, accessible by any existing CQL driver. When a modification is made to a table with CDC enabled, information about that operation is saved to the CDC log table.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Here’s a quick demo of it: First, we will create a table with CDC enabled:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; ks.orders( user &lt;span class=&quot;predefined-type&quot;&gt;text&lt;/span&gt;, order_id &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, order_name &lt;span class=&quot;predefined-type&quot;&gt;text&lt;/span&gt;, &lt;span class=&quot;directive&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;KEY&lt;/span&gt;(user, order_id) ) WITH cdc = {&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;};&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Next, let’s perform some operations:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.orders(user, order_id, order_name) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Tim&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;apple&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.orders(user, order_id, order_name) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Alice&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;blueberries&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;); &lt;span class=&quot;class&quot;&gt;UPDATE&lt;/span&gt; ks.orders &lt;span class=&quot;class&quot;&gt;SET&lt;/span&gt; order_name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pineapple&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; user = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Tim&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; order_id = &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Finally, let’s see the contents of the modified table:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.orders; user | order_id | order_name &lt;span class=&quot;comment&quot;&gt;------+----------+-------------&lt;/span&gt; Tim | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | pineapple Alice | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | blueberries&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Looking only at this table, you cannot reconstruct all modifications that took place, e.g. Tim’s order name before the UPDATE. Let’s look at the CDC log, easily accessible as a table (some columns truncated for clarity):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.orders_scylla_cdc_log; cdc$stream_id | cdc$time | | cdc$operation | order_id | order_name | user &lt;span class=&quot;comment&quot;&gt;---------------+----------+-...-+---------------+----------+-------------+----------&lt;/span&gt; &lt;span class=&quot;hex&quot;&gt;0x2e46a&lt;/span&gt;... | &lt;span class=&quot;error&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;4&lt;/span&gt;... | ... | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | apple | Tim &lt;span class=&quot;hex&quot;&gt;0x2e46a&lt;/span&gt;... | &lt;span class=&quot;float&quot;&gt;8f&lt;/span&gt;dc... | ... | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; | pineapple | Tim &lt;span class=&quot;hex&quot;&gt;0x41400&lt;/span&gt;... | &lt;span class=&quot;error&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;8&lt;/span&gt;e... | ... | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt; | blueberries | Alice&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;All three operations are visible in the CDC log. There are two INSERTs (&lt;code&gt;cdc$operation = 2&lt;/code&gt;) and one UPDATE (&lt;code&gt;cdc$operation = 1&lt;/code&gt;). For each operation, its timestamp is also preserved in &lt;code&gt;cdc$time&lt;/code&gt; column. The timestamp is encoded as a time-based UUID value as specified by the &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc4122&quot;&gt;RFC 4122&lt;/a&gt; specification, which can be decoded using helper methods in Scylla drivers.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;choosing_debezium&quot;&gt;Choosing Debezium&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As shown in the previous section, Scylla CDC can be easily queried as a regular table. To get the latest operations in real-time, you poll the table with appropriate time ranges. To make this easier, we developed client libraries for &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-java&quot;&gt;Java&lt;/a&gt; and &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-go&quot;&gt;Go&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;When we thought about how our customers could access the CDC log, using it with Kafka seemed like the most accessible method. Therefore, we decided to develop a source connector for Scylla CDC.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For our first proof-of-concept, we implemented the source connector using the &lt;a href=&quot;https://kafka.apache.org/documentation.html#connect_development&quot;&gt;Kafka Connect API&lt;/a&gt;. This prototype was crucial for us to determine if the connector could scale horizontally (described later in this blogpost).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, we quickly realized that by using only the Kafka Connect API, we would have to reimplement a lot of functionality already present in other connectors. We also wanted our connector to be a good citizen in the Kafka community, sticking to the best practices and conventions. That’s exactly why we choose Debezium!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thanks to this, when you start the Scylla CDC Source Connector, the configuration parameters will be immediately familiar, as many of them are common with other Debezium connectors. The generated data change events have the same &lt;a href=&quot;https://javadoc.io/static/io.debezium/debezium-core/1.6.2.Final/io/debezium/data/Envelope.html&quot;&gt;Envelope&lt;/a&gt; structure as generated by other Debezium connectors. This similarity allows for the use of many standard Debezium features, such as &lt;a href=&quot;/documentation/reference/1.6/transformations/event-flattening.html&quot;&gt;New Record State Extraction&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;event_representation&quot;&gt;Event representation&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;After we decided to use the Debezium framework, we looked at how Scylla CDC operations should be represented in Debezium’s Envelope format.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Envelope format consists of the following fields:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;op&lt;/code&gt; - type of operation: &lt;code&gt;c&lt;/code&gt; for create, &lt;code&gt;u&lt;/code&gt; for update, &lt;code&gt;d&lt;/code&gt; for delete and &lt;code&gt;r&lt;/code&gt; for read&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;before&lt;/code&gt; - state of row before an event occured&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;after&lt;/code&gt; - state of row after an event occurred&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;source&lt;/code&gt; - metadata of the event&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;ts_ms&lt;/code&gt; - time the connector processed the event&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Mapping Scylla operations to the &lt;code&gt;op&lt;/code&gt; field was fairly easy: &lt;code&gt;c&lt;/code&gt; for INSERT, &lt;code&gt;u&lt;/code&gt; for UPDATE, &lt;code&gt;d&lt;/code&gt; for DELETE.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We decided to skip DELETE events that span multiple rows, such as range DELETEs:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; ks.table &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; pk = &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; ck &amp;gt; &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; ck &amp;lt; &lt;span class=&quot;integer&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Representing such operations would unnecessarily complicate the format in order to accommodate additional range information. Moreover, it would break the expectation that an Envelope represents a modification to a single row.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Scylla CDC, range DELETEs are represented as two rows in the CDC table: the first row encodes the information about the start of the deleted range (in the example above: &lt;code&gt;pk = 1, ck &amp;gt; 0&lt;/code&gt;) and the second row encodes the end of the deleted range (in the example above: &lt;code&gt;pk = 1, ck &amp;lt; 5&lt;/code&gt;). An information about each of the rows present in that range is not persisted. This corresponds to a fact that DELETEs in Scylla generate a tombstone in the database.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;By default, Scylla’s CDC stores the primary key and only the modified columns of an operation. For example, suppose I created a table and inserted a row:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;TABLE&lt;/span&gt; ks.example( pk &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v1 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v2 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, v3 &lt;span class=&quot;predefined-type&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;directive&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;KEY&lt;/span&gt;(pk)) WITH cdc = {&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;}; &lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.example(pk, v1, v2, v3) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In Scylla you can issue another INSERT statement, which will override some of the columns:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; ks.example(pk, v1, v3) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;integer&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;predefined-constant&quot;&gt;null&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;code&gt;v2&lt;/code&gt; column is left unchanged after this query and we don’t have any information about its previous value.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We must be able to represent three possibilities: a column was not modified, a column was assigned a &lt;code&gt;NULL&lt;/code&gt; value or a column was assigned a non-null value. The representation we chose was inspired by &lt;a href=&quot;/documentation/reference/1.6/connectors/cassandra.html&quot;&gt;Debezium Connector for Cassandra&lt;/a&gt;, which works by wrapping the value for a column in a structure:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;}, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A &lt;code&gt;null&lt;/code&gt; structure value represents that a column was not modified (&lt;code&gt;v2&lt;/code&gt; field). If the column was assigned a &lt;code&gt;NULL&lt;/code&gt; value (&lt;code&gt;v3&lt;/code&gt; field), there will be a structure with a &lt;code&gt;NULL&lt;/code&gt; &lt;code&gt;value&lt;/code&gt; field. A non-null column assignment (&lt;code&gt;v1&lt;/code&gt; field) fills the contents of the &lt;code&gt;value&lt;/code&gt; field. Such a format allows us to correctly represent all the possibilities and differentiate between assigning &lt;code&gt;NULL&lt;/code&gt; and non-modification.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, most sink connectors won’t be able to correctly parse such a structure. Therefore, we decided to develop our own SMT, based on Debezium’s &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/transformations/event-flattening.html&quot;&gt;New Record State Extraction SMT&lt;/a&gt;. Our &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector#scyllaextractnewstate-transformer&quot;&gt;ScyllaExtractNewState&lt;/a&gt; SMT works by applying Debezium&amp;#8217;s New Record State Extraction and flattening the &lt;code&gt;{&quot;value&quot;: &amp;#8230;&amp;#8203;}&lt;/code&gt; structures (at the expense of not being able to distinguish &lt;code&gt;NULL&lt;/code&gt; value and missing column value):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Scylla’s CDC also supports recording pre-images and post-images with every operation (at an additional cost). We plan to add support for them in the future versions of the Scylla CDC Source Connector.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;horizontal_scaling&quot;&gt;Horizontal scaling&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Even at a stage of proof-of-concept, great performance was a paramount requirement. Scylla databases can scale to hundreds of nodes and PBs of data, so it became clear that a single Kafka Connect worker node (even multithreaded) could not handle the load of a big Scylla cluster.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Thankfully, we took that into consideration while implementing CDC functionality in Scylla. Generally, you can think of Change Data Capture as a time-ordered queue of changes. To allow for horizontal scaling, Scylla maintains a set of multiple time-ordered queues of changes, called streams. When there is only a single consumer of the CDC log, it has to query all streams to properly read all changes. A benefit of this design is that you can introduce additional consumers, assigning a disjunct set of streams to each one of them. As a result, you can greatly increase the parallelism of processing the CDC log.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;That’s the approach we implemented in the Scylla CDC Source Connector. When starting, the connector first reads the identifiers of all available streams. Next, it distributes them among many Kafka Connect tasks (configurable by &lt;code&gt;tasks.max&lt;/code&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Each created Kafka Connect task (that can run on a separate Kafka Connect node) reads CDC changes from its assigned set of streams. If you double the number of tasks, each task will have to read only a half of the number of streams - half of data throughput, making it possible to handle a higher load.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;solving_large_stream_count_problem&quot;&gt;Solving large stream count problem&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While designing CDC functionality in Scylla, we had to carefully pick the number of streams that would be created. If we chose too few streams, a consumer could possibly not keep up with the data throughput of a single stream. That could also slow down INSERT, UPDATE, DELETE operations, because many concurrent operations would fight for access to a single stream. However, if Scylla created too many streams, the consumers would have to issue a large number of queries to Scylla (to cover each stream), causing unnecessary load.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The current implementation of CDC in Scylla creates &lt;code&gt;number_of_nodes * number_of_vnodes_per_node * number_of_shards&lt;/code&gt; streams per cluster. The number of VNodes refers to the fact that Scylla uses a &lt;a href=&quot;https://docs.scylladb.com/architecture/ringarchitecture/&quot;&gt;Ring architecture&lt;/a&gt;, which has 256 VNodes per node by default. Each Scylla node consists of several independent shards, which contain their share of the node’s total data. Typically, there is one shard per each hyperthread or physical core.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For example, if you create a 4-node i3.metal (72 vCPU per node) Scylla cluster, which is capable of roughly 600k operations per second (half INSERTs, half SELECTs), that would be: &lt;code&gt;4 * 256 * 72 = 73728&lt;/code&gt; streams.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We quickly realised that this many streams could be a problem in bigger clusters:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;olist arabic&quot;&gt; &lt;ol class=&quot;arabic&quot;&gt; &lt;li&gt; &lt;p&gt;Too many queries to Scylla - one query per each stream&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Too many Kafka Connect offsets - one offset per each stream. Storing offsets means the connector can resume from the last saved position after a crash.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To mitigate those problems, we made a decision to group streams on the client side. We chose to group the streams by VNode. This reduced the count from &lt;code&gt;number_of_nodes * number_of_vnodes_per_node * number_of_shards&lt;/code&gt; to &lt;code&gt;number_of_nodes * number_of_vnodes_per_node&lt;/code&gt;. In the case of 4-node i3.metal that means a reduction from 73728 to 1024: only 1024 queries to Scylla and 1024 offsets stored on Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;However, we were still uneasy about the number of offsets to be stored on Kafka. When we looked into other connectors, most of them stored only a single offset or at most tens of offsets per replicated table (and as an effect having a limited scalability).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To understand why storing thousands of streams on Kafka Connect could be a problem, let’s look at how it works under the hood. Each Kafka Connect record created by a source connector contains a key/value offset, for example: key - &lt;code&gt;my_table&lt;/code&gt;; offset - &lt;code&gt;25&lt;/code&gt;, which could represent that the connector finished reading 25 rows in &lt;code&gt;my_table&lt;/code&gt;. Periodically (configured by &lt;code&gt;offset.flush.interval.ms&lt;/code&gt;), those offsets are flushed to a Kafka topic called &lt;code&gt;connect-offsets&lt;/code&gt;, as regular Kafka messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Unfortunately, Kafka is not a key/value store. When a connector starts up, it must scan all messages on the &lt;code&gt;connect-offsets&lt;/code&gt; topic to find the one it needs. When it updates a previously saved offset, it just appends the new value to this topic without deleting the previous entry. It’s not a problem with connectors that have only a single offset - when updated every minute, this topic would hold roughly 10,000 messages after a week. However, in the case of the Scylla CDC Source Connector this number could be several orders of magnitude larger!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Fortunately, this issue can be easily mitigated by setting a more aggressive compaction configuration on the &lt;code&gt;connect-offsets&lt;/code&gt; topic. With the default configuration of &lt;code&gt;retention.ms&lt;/code&gt; of 7 days and &lt;code&gt;segment.bytes&lt;/code&gt; of 1GB, this topic could grow up to several hundred megabytes after just a few hours (with a Scylla cluster with tens of nodes and very small &lt;code&gt;offset.flush.interval.ms&lt;/code&gt;). This made the connector startup time slower, as it had to scan the entire offset topic after a start/restart. By tuning the &lt;code&gt;segment.bytes&lt;/code&gt;, &lt;code&gt;segment.ms&lt;/code&gt; or &lt;code&gt;cleanup.policy&lt;/code&gt;, &lt;code&gt;retention.ms&lt;/code&gt; we were able to mitigate the problem and significantly reduce the &lt;code&gt;connect-offsets&lt;/code&gt; topic size. The first two options specify the frequency of the log compaction process. When a segment is compacted, all messages with the same key are reduced to the latest one (the latest offset). Alternatively, setting a shorter retention time (but one that is larger than Scylla’s CDC retention time) proved to be a good option to reduce the offset topic size.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect2&quot;&gt; &lt;h3 id=&quot;benchmarks_near_linear_scaling&quot;&gt;Benchmarks: near linear scaling&lt;/h3&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To verify that our connector can actually scale horizontally, we performed a benchmark to measure the maximum throughput of Scylla CDC Source Connector on increasingly larger Kafka Connect clusters.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;First, we started a single-node i3.4xlarge Scylla cluster (based on the official Scylla AMI). Next, we inserted 50 million rows (total size 5.33GB) to a CDC-enabled table. Later, we started an Apache Kafka 2.6.0 cluster and Kafka Connect cluster on either 1, 3 or 5 nodes (r5n.2xlarge). We started the Scylla CDC Source Connector to consume data from the previously populated CDC-enabled table and measured the time it took to produce all 50 million Kafka messages.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Our connector was able to scale the throughput near linearly:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;img src=&quot;/assets/images/2021-09-08-deep-dive-into-a-debezium-community-connector-scylla-cdc-source-connector/horizontal_scalability.png&quot; style=&quot;max-width:90%;&quot; class=&quot;responsive-image&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt; &lt;colgroup&gt; &lt;col style=&quot;width: 50%;&quot;&gt; &lt;col style=&quot;width: 33.3333%;&quot;&gt; &lt;col style=&quot;width: 16.6667%;&quot;&gt; &lt;/colgroup&gt; &lt;thead&gt; &lt;tr&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Kafka cluster size&lt;/th&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Throughput&lt;/th&gt; &lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Speedup&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1 node&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;46k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;1x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;3 nodes&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;129k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;2.8x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;5 nodes&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;215k/s&lt;/p&gt;&lt;/td&gt; &lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;4.7x&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In this blog post, we took a deep dive into the development of Scylla CDC Source Connector. We started with an overview of CDC implementation in Scylla. We have discussed the reasons we chose Debezium rather than just Kafka Connect API to build our connector, in turn making it familiar to users and Kafka-idiomatic. Next, we looked at two problems we encountered: how to represent Scylla changes and make the connector scalable.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;We are very excited to continue improving our connector even further with additional features and making it even more performant. We are eagerly looking forward to watching the Debezium ecosystem grow and integrating functionalities introduced in the latest versions of Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;If you want to check out the connector yourself, the GitHub repository with its source code is available here: &lt;a href=&quot;https://github.com/scylladb/scylla-cdc-source-connector&quot;&gt;github.com/scylladb/scylla-cdc-source-connector&lt;/a&gt;. You can learn more about Scylla here: &lt;a href=&quot;https://scylladb.com&quot;&gt;scylladb.com&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Piotr Grabowski</name></author><category term="community"/><category term="kafka"/><category term="scylla"/><summary type="html">At ScyllaDB, we develop a high-performance NoSQL database Scylla, API-compatible with Apache Cassandra, Amazon DynamoDB and Redis. Earlier this year, we introduced support for Change Data Capture in Scylla 4.3. This new feature seemed like a perfect match for integration with the Apache Kafka ecosystem, so we developed the Scylla CDC Source Connector using the Debezium framework. In this blogpost we will cover the basic structure of Scylla’s CDC, reasons we chose the Debezium framework and design decisions we made.</summary></entry><entry><title type="html">Debezium 1.7.0.CR1 Released</title><link href="https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.CR1 Released"/><published>2021-09-16T00:00:00+00:00</published><updated>2021-09-16T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/09/16/debezium-1-7-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;I am very happy to announce the release of Debezium &lt;strong&gt;1.7.0.CR1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;For this release, we&amp;#8217;ve reworked how column filters are handled during snapshotting, the Debezium container images have been updated to use Fedora 34 as their base, there&amp;#8217;s support for MySQL &lt;code&gt;INVISIBLE&lt;/code&gt; columns, and much more.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;column_filtering_during_snapshotting&quot;&gt;Column Filtering During Snapshotting&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;While the different Debezium connectors already had the capability to exclude specific columns of the captured tables from change events, these filters were only applied when processing the data within the connectors. For initial snapshots, a more efficient approach has been implemented now: tailored SQL SELECT statements will be executed for fetching only the actually included columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2525&quot;&gt;DBZ-2525&lt;/a&gt;). This allows for significant performance gains when for instance excluding large &lt;code&gt;BLOB&lt;/code&gt; columns from change events.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;updated_container_image_base&quot;&gt;Updated Container Image Base&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The &lt;a href=&quot;https://hub.docker.com/u/debezium&quot;&gt;Debezium container images&lt;/a&gt; for Apache Kafka, Kafka Connect, and Apache ZooKeeper are based on the Fedora 34 minimal container base image (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3939&quot;&gt;DBZ-3939&lt;/a&gt;). This change became necessary as the previously used base image (derived from CentOS 7) was not maintained any longer. While this change will be transparent for most users of Debezium, some adjustments may be required for those users who derive their own custom images from the Debezium ones, e.g. when installing further packages using the operating system&amp;#8217;s package manager. Please refer to the &lt;a href=&quot;https://debezium.io/releases/1.7/release-notes#breaking_changes&quot;&gt;release notes&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;further_fixes&quot;&gt;Further Fixes&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As we&amp;#8217;re approaching the 1.7 Final release, most changes have been centered around bug fixing and maturing the code base. Some of the resolved issues include:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Support for &lt;code&gt;INVISIBLE&lt;/code&gt; columns as available since MySQL 8.0.23 (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3623&quot;&gt;DBZ-3623&lt;/a&gt;); we&amp;#8217;ve used that occassion to also update the Debezium example image for MySQL to version 8.0 (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3936&quot;&gt;DBZ-3936&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The SQL Server allows for the usage of custom connection factories (&lt;a href=&quot;https://issues.jboss.org/browse/DBZ-4001&quot;&gt;DBZ-4001&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Several fixes to DML and DDL parsing for MySQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3969&quot;&gt;DBZ-3969&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3984&quot;&gt;DBZ-3984&lt;/a&gt;) and Oracle (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3892&quot;&gt;DBZ-3892&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3962&quot;&gt;DBZ-3962&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.7.0.CR1&quot;&gt;47 issues&lt;/a&gt; have been fixed for this release. A big thank you to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/ashmeet13&quot;&gt;Ashmeet Lamba&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/camilesing&quot;&gt;Camile Sing&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/d3vel0per&quot;&gt;Dhrubajyoti G&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/indraraj&quot;&gt;Indra Shukla&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/Jiabao-Sun&quot;&gt;Jiabao Sun&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/kgalieva&quot;&gt;Katerina Galieva&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, and &lt;a href=&quot;https://github.com/zhangyuan&quot;&gt;Yuan Zhang&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Going forward, we&amp;#8217;re planning to do another CR (candidate release) in a few days, followed by Debezium 1.7.0.Final at the end of the month. We&amp;#8217;ll primarily focus on bug fixing and some asorted performance optimizations. There&amp;#8217;ll also be some exciting improvements to the &lt;a href=&quot;/documentation/reference/1.7/operations/debezium-ui.html&quot;&gt;Debezium UI&lt;/a&gt;, which should be wrapped up for the 1.7 Final release: support for the configuration of single message transforms (SMTs), as well as the ability to configure topic creation settings.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In parallel, we&amp;#8217;re working on the roadmap for Debezium 1.8, planned to be released by the end of the year. Please reach out in the comments below or on the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt; if you&amp;#8217;d like to raise specific feature requests for this release.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="oracle"/><category term="outbox"/><summary type="html">I am very happy to announce the release of Debezium 1.7.0.CR1! For this release, we&amp;#8217;ve reworked how column filters are handled during snapshotting, the Debezium container images have been updated to use Fedora 34 as their base, there&amp;#8217;s support for MySQL INVISIBLE columns, and much more.</summary></entry><entry><title type="html">Going ZooKeeper-less With the Debezium Container Image for Apache Kafka</title><link href="https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/" rel="alternate" type="text/html" title="Going ZooKeeper-less With the Debezium Container Image for Apache Kafka"/><published>2021-08-31T00:00:00+00:00</published><updated>2021-08-31T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka</id><content type="html" xml:base="https://debezium.io/blog/2021/08/31/going-zookeeperless-with-debezium-container-image-for-apache-kafka/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://blogs.apache.org/kafka/entry/what-s-new-in-apache5&quot;&gt;Apache Kafka 2.8&lt;/a&gt; allows for a first glimpse into the ZooKeeper-less future of the widely used event streaming platform: shipping with a preview of &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt; (&quot;Replace ZooKeeper with a Self-Managed Metadata Quorum&quot;), you can now run Kafka clusters without the need for setting up and operating Apache ZooKeeper. This does not only simplify running Kafka from an operational perspective, the new metadata quorum implementation (named &quot;KRaft&quot;, Kafka Raft metadata mode) also should provide much better scaling characteristics, for instance when it comes to large numbers of topics and partitions.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;I have blogged&lt;/a&gt; about my first experiences with KRaft and ZooKeeper-less Kafka a while ago over on my personal blog. Since then, the Debezium community has upgraded its &lt;a href=&quot;https://hub.docker.com/r/debezium/kafka&quot;&gt;container image&lt;/a&gt; for Apache Kafka to version 2.8, which makes it really simple to start your own explorations around running Kafka without ZooKeeper. Note that KRaft mode is an early access feature of Apache Kafka at this point in time and should not be used for production purposes.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;enabling_kraft_mode&quot;&gt;Enabling KRaft Mode&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As of Debezium version 1.7, the container image for Kafka supports three new environment variables, to be specified when running the image:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;ulist&quot;&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;CLUSTER_ID&lt;/code&gt;: A unique id, such as &quot;5Yr1SIgYQz-b-dgRabWx4g&quot;; if this variable is present, KRaft mode is enabled. Otherwise, the image behaves as before, and must be configured with a reference to ZooKeeper. When using KRaft mode, all nodes of the Kafka cluster must use the same cluster id. Values can be generated using the &lt;em&gt;kafka-storage.sh&lt;/em&gt; script coming with Apache Kafka.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;NODE_ROLE&lt;/code&gt;: Specifies the role of the Kafka node; must be one of &quot;controller&quot;, &quot;broker&quot;, or &quot;combined&quot;. In KRaft mode, Kafka nodes can either be part of the metadata quorum (controller nodes), they can be exclusively used for propagating messages (broker nodes), or they can do both (combined nodes). Depending on your use case and requirements, you might for instance go for a smaller Kafka cluster of three combined nodes, or for a larger one with three controllers and seven brokers. If no value is given, the image will start the broker in combined mode.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;NODE_ID&lt;/code&gt;; Specifies a unique id (1, 2, 3, &amp;#8230;&amp;#8203;) for each node in the cluster; the previously used variable &lt;code&gt;BROKER_ID&lt;/code&gt; has been deprecated in favour of &lt;code&gt;NODE_ID&lt;/code&gt;; for the time being, it still is supported as an alias for the new name, but using it will trigger a warning in the logs, and it is planned to be phased out eventually.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;In addition, one more environment variable must be given when starting a Kafka cluster in KRaft mode using the Debezium container image: &lt;code&gt;KAFKA_CONTROLLER_QUORUM_VOTERS&lt;/code&gt;. This one is used to pass the &lt;code&gt;controller.quorum.voters&lt;/code&gt; configuration option to Kafka, referencing all controller nodes in the cluster in the format &quot;id-1@controller-node-1:controller-port-1,&amp;#8230;&amp;#8203;&quot;, for instance &lt;code&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/code&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;sect1&quot;&gt; &lt;h2 id=&quot;giving_it_a_try&quot;&gt;Giving it a Try&lt;/h2&gt; &lt;div class=&quot;sectionbody&quot;&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;And really that&amp;#8217;s all there is to it. So let&amp;#8217;s take a look at a Docker Compose file for starting up a three node Kafka cluster, formed of combined nodes solely:&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;'2'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;services&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;kafka-1&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=1&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-2&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=2&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-3&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=3&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;One quick &lt;code&gt;docker compose up&lt;/code&gt; later, and you&amp;#8217;ll have your ZooKeeper-less Kafka cluster running, ready to be used with Debezium, Kafka Connect, or any other Kafka workload you may have. Just remember: don&amp;#8217;t roll it out to production just yet ;) Note that whether ZooKeeper is or isn&amp;#8217;t used by a given cluster, solely is an implementation detail of Kafka, i.e. it&amp;#8217;s fully transparent to Debezium, its history producers/consumers, and any other Kafka clients.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Setting up a cluster with dedicated controller and broker nodes isn&amp;#8217;t much more complex either. Here&amp;#8217;s the configuration for a cluster with one controller and three brokers (of course you&amp;#8217;d want to run with at least three controllers in reality, so to avoid the single point of failure of only one controller node):&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;listingblock&quot;&gt; &lt;div class=&quot;content&quot;&gt; &lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;key&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;'2'&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;services&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;kafka-1&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;19093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=1&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=controller&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-2&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;29093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=2&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-3&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;39093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=3&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;kafka-4&lt;/span&gt;: &lt;span class=&quot;key&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;debezium/kafka:1.7&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;ports&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;49092:9092&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;49093:9093&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;key&quot;&gt;environment&lt;/span&gt;: - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;CLUSTER_ID=5Yr1SIgYQz-b-dgRabWx4g&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;BROKER_ID=4&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093&lt;/span&gt;&lt;/span&gt; - &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;content&quot;&gt;NODE_ROLE=broker&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;You can find extended versions of the two Compose files (&lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/main/tutorial/docker-compose-zookeeperless-kafka-combined.yaml&quot;&gt;combined&lt;/a&gt;, &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/main/tutorial/docker-compose-zookeeperless-kafka.yaml&quot;&gt;controller/broker&lt;/a&gt;) in the Debezium examples repository, also containing services for Kafka Connect and a Postgres database, and accompanied by &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/main/tutorial#running-without-zookeeper&quot;&gt;instructions&lt;/a&gt; for running the &lt;a href=&quot;https://debezium.io/documentation/reference/tutorial.html&quot;&gt;Debezium tutorial&lt;/a&gt; with ZooKeeper-less Kafka.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;As KRaft mode matures in Kafka 3.0 and later versions, we may do some adjustments to the container image, so to support the new mode of running Kafka in the best way possible. Eventually, the option to run with ZooKeeper will be removed, but it&amp;#8217;ll be quite some more time until then.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;To learn more about KRaft, refer to &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt; and related KIPs, which describe the feature and its design in great detail, the &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/config/kraft/README.md&quot;&gt;KRaft README file&lt;/a&gt;, &lt;a href=&quot;https://github.com/debezium/docker-images/tree/main/kafka/1.7&quot;&gt;the README&lt;/a&gt; of the Debezium 1.7 container image for Apache Kafka, and aforementioned blog post &lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;&quot;Exploring ZooKeeper-less Kafka&quot;&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;em&gt;Many thanks to &lt;a href=&quot;https://twitter.com/rk3rn3r/&quot;&gt;René Kerner&lt;/a&gt; for providing feedback while writing this post.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="docker"/><category term="apache kafka"/><category term="examples"/><summary type="html">Apache Kafka 2.8 allows for a first glimpse into the ZooKeeper-less future of the widely used event streaming platform: shipping with a preview of KIP-500 (&quot;Replace ZooKeeper with a Self-Managed Metadata Quorum&quot;), you can now run Kafka clusters without the need for setting up and operating Apache ZooKeeper. This does not only simplify running Kafka from an operational perspective, the new metadata quorum implementation (named &quot;KRaft&quot;, Kafka Raft metadata mode) also should provide much better scaling characteristics, for instance when it comes to large numbers of topics and partitions.</summary></entry><entry><title type="html">Debezium 1.7.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.7.0.Beta1 Released"/><published>2021-08-25T00:00:00+00:00</published><updated>2021-08-25T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/08/25/debezium-1-7-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.7 series, &lt;strong&gt;1.7.0.Beta1&lt;/strong&gt;!&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;This release brings &lt;a href=&quot;https://docs.nats.io/developing-with-nats-streaming/streaming#nats-streaming-overview&quot;&gt;NATS Streaming&lt;/a&gt; support for Debezium Server along with many other fixes and enhancements. Also this release is the first one tested with Apache Kafka 2.8.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;The Debezium container images for &lt;a href=&quot;https://hub.docker.com/r/debezium/kafka&quot;&gt;Apache Kafka&lt;/a&gt; and &lt;a href=&quot;https://hub.docker.com/r/debezium/connect&quot;&gt;Kafka Connect&lt;/a&gt; have been updated to version 2.8, too. This means that you can test Debezium with the new ZooKeeper-less mode for running Kafka (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&quot;&gt;KIP-500&lt;/a&gt;). We&amp;#8217;ll share more details on that in a separate post shortly.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;A large number of bug fixes and quality improvements have been made for this release; one focus area was the Debezium connector for Oracle, which received several fixes including the ability to configure multiple Oracle RAC nodes with different ports (DBZ-3813), multiple DDL parser corrections (DBZ-3877, DBZ-3893), and improved updating of SCN offsets (DBZ-3876).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Other changes include performance improvement for the Debezium connectors for Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3870&quot;&gt;DBZ-3870&lt;/a&gt;) and MongoDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3788&quot;&gt;DBZ-3788&lt;/a&gt;), proper timezone conversions for change event timestamps in the connector for SQL Server (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3479&quot;&gt;DBZ-3479&lt;/a&gt;), and more resilient handling of errors during connector start-up (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3823&quot;&gt;DBZ-3823&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Furthermore, this release has a breaking change for the MySQL Connector. The MySQL driver was updated to the latest version 8.0.26 with &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3833&quot;&gt;DBZ-3833&lt;/a&gt;. This update comes with a new timezone handling and configuration options. Detailed information can be found in the &lt;a href=&quot;https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-connp-props-datetime-types-processing.html&quot;&gt;MySQL docs&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Earlier this month, we added the &lt;a href=&quot;https://debezium.io/documentation/reference/operations/debezium-ui.html&quot;&gt;Debezium UI&lt;/a&gt; to our regular release process. If you want to learn more about the Debezium UI have a look at our recent &lt;a href=&quot;/blog/2021/08/12/introducing-debezium-ui/&quot;&gt;release announcement&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;paragraph&quot;&gt; &lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/secure/ReleaseNote.jspa?projectId=12317320&amp;amp;version=12359667&quot;&gt;81 issues&lt;/a&gt; were fixed for this release. Thanks a lot to all contributors: &lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/umanwizard&quot;&gt;Brennan Vincent&lt;/a&gt;, &lt;a href=&quot;https://github.com/cab105&quot;&gt;Chris Baumbauer&lt;/a&gt;, &lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;, &lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;, &lt;a href=&quot;https://github.com/sirscratchalot&quot;&gt;Erik Malm&lt;/a&gt;, &lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;, &lt;a href=&quot;https://github.com/uidoyen&quot;&gt;Hussain Ansari&lt;/a&gt;, &lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;, &lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;, &lt;a href=&quot;https://github.com/mdrillin&quot;&gt;Mark Drilling&lt;/a&gt;, &lt;a href=&quot;https://github.com/mikekamornikov&quot;&gt;Mike Kamornikov&lt;/a&gt;, &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar KR&lt;/a&gt;, &lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;, &lt;a href=&quot;https://github.com/rk3rn3r&quot;&gt;René Kerner&lt;/a&gt;, &lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;, &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, &lt;a href=&quot;https://github.com/tavancini&quot;&gt;Thiago Avancini&lt;/a&gt;, &lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;https://github.com/zregvart&quot;&gt;Zoran Regvart&lt;/a&gt;, &lt;a href=&quot;https://github.com/ili-zh&quot;&gt;李宗文&lt;/a&gt;, &lt;a href=&quot;https://github.com/pkgonan&quot;&gt;민규 김&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;</content><author><name>René Kerner</name></author><category term="releases"/><category term="mysql"/><category term="postgres"/><category term="sqlserver"/><category term="cassandra"/><category term="oracle"/><category term="db2"/><category term="vitess"/><category term="outbox"/><category term="kafka"/><summary type="html">It&amp;#8217;s my pleasure to announce the second release of the Debezium 1.7 series, 1.7.0.Beta1! This release brings NATS Streaming support for Debezium Server along with many other fixes and enhancements. Also this release is the first one tested with Apache Kafka 2.8.</summary></entry></feed>