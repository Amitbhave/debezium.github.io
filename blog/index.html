<!DOCTYPE html> <html lang="en"> <head> <title>Debezium Blog</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="https://static.jboss.org/theme/css/bootstrap-community/3.2.0.2/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="https://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="https://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="https://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="https://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="https://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="https://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
      @media (min-width: 980px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
      }
      @media (max-width: 979px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
      }
      @media (max-width: 650px) {
        .banner { width: 100%; margin: 0px auto; }
      }
      @media (max-width: 450px) {
        .banner { height: 90px; }
      }
    </style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
      hljs.initHighlightingOnLoad();
    </script> <script src="https://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
      /* adjusting the vertical spacing for when a stickynav is engaged */
      .breadcrumb-fixed > .active {
        color: #8c8f91;
      }
      .breadcrumb-fixed {
        margin: 70px 0 10px;
        padding: 8px 15px;
        margin-bottom: 20px;
        list-style: none;
        background-color: #f5f5f5;
        border-radius: 4px;
      }
      
      .breadcrumb-fixed > li {
        display: inline-block;
      }
    </style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="https://www.jboss.org/projects/about"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> Debezium </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/docs/faq/">FAQ</a></li> <li class=""><a href="/docs/">DOCS</a></li> <li class=""><a href="/community/">COMMUNITY</a></li> <li class="active"><a href="/blog/">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav"> <div class="panel-docnav"> <div class="panel-heading"> <h3 class="panel-title"> Latest posts </h3> </div> <div class="panel-body"> <ul class="list-group"> <li class="list-group-item"> <a href="/blog/2018/12/19/debezium-0-9-0-beta2-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.0.Beta2 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/" rel="tooltip" title="Click to go to post">Automating Cache Invalidation With Change Data Capture</a> </li> <li class="list-group-item"> <a href="/blog/2018/11/22/debezium-0-9-0-beta1-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.0.Beta1 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/10/04/debezium-0-9-0-alpha2-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.0.Alpha2 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" rel="tooltip" title="Click to go to post">Materializing Aggregate Views With Hibernate and Debezium</a> </li> <li class="list-group-item"> <a href="/blog/2018/09/19/debezium-0-8-3-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.8.3.Final Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/08/30/streaming-mysql-data-changes-into-kinesis/" rel="tooltip" title="Click to go to post">Streaming MySQL Data Changes to Amazon Kinesis</a> </li> <li class="list-group-item"> <a href="/blog/2018/08/30/debezium-0-8-2-released/" rel="tooltip" title="Click to go to post">Debezium 0.8.2 Released</a> </li> </ul> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="text-right"> <h3> Subscribe <a class="rss" href="/blog.atom"> <i class="icon-rss"></i> </a> </h3> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/12/19/debezium-0-9-0-beta2-released/">Debezium 0.9.0.Beta2 Released</a> </h1> <div class="byline"> <p> <em> December 19, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/sqlserver/">sqlserver</a> <a class="label label-info" href="/blog/tags/oracle/">oracle</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>With only a few days left for the year, it&#8217;s about time for another Debezium release; so it&#8217;s with great pleasure that I&#8217;m announcing Debezium <strong>0.9.0.Beta2</strong>!</p> </div> <div class="paragraph"> <p>This release comes with support for MySQL 8 and Oracle 11g; it includes a first cut of metrics for monitoring the SQL Server and Oracle connectors, several improvements to the MongoDB event flattening SMT as well as a wide range of bug fixes. Overall, not less than <a href="/docs/releases/#release-0-9-0-beta2">42 issues</a> were addressed; very clearly, there has to be <a href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything_%2842%29">some deeper sense</a> in that ;)</p> </div> <div class="paragraph"> <p>A big shout out goes to the following members Debezium&#8217;s amazing community, who contributed to this release: <a href="https://github.com/pimpelsang">Eero Koplimets</a>, <a href="https://github.com/grzegorz8">Grzegorz Ko≈Çakowski</a>, <a href="https://github.com/ooooorz">Hanlin Liu</a>, <a href="https://github.com/sweat123">Lao Mei</a>, <a href="https://github.com/renatomefi">Renato Mefi</a>, <a href="https://github.com/tautautau">Tautvydas Januskevicius</a>, <a href="https://github.com/wscheep">Wout Scheepers</a> and <a href="https://github.com/wangzheng422">Zheng Wang</a>!</p> </div> <div class="paragraph"> <p>In the following, let&#8217;s take a closer look at some of the changes coming with the 0.9 Beta2 release.</p> </div> </div> </div> <div class="sect1"> <h2 id="monitoring_and_metrics_for_the_sql_server_and_oracle_connectors"><a class="anchor" href="#monitoring_and_metrics_for_the_sql_server_and_oracle_connectors"></a>Monitoring and Metrics for the SQL Server and Oracle Connectors</h2> <div class="sectionbody"> <div class="paragraph"> <p>Following the example of the MySQL connector, the connectors for <a href="/docs/connectors/sqlserver/">SQL Server</a> and <a href="/docs/connectors/oracle/">Oracle</a> now expose a range of metrics for monitoring purposes via JMX (<a href="https://issues.jboss.org/browse/DBZ-978">DBZ-978</a>). This includes values like the time since the last CDC event, offset of the last event, the total number of events, remaining and already scanned tables while doing a snapshot and much more. Please see <a href="/docs/monitoring/">the monitoring documentation</a> for details on how to enable JMX. The following image shows an example of displaying the values in OpenJDK&#8217;s <a href="https://openjdk.java.net/projects/jmc/">Mission Control</a> tool:</p> </div> <div class="imageblock centered-image"> <img src="/images/monitoring_mission_control.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Monitoring the Debezium SQL Server connector"> </div> <div class="paragraph"> <p>We&#8217;re planning to expand the set of exposed metrics in future versions and also make them available for Postgres and MongoDB. Please let us know about the metrics you&#8217;d like to see by commenting on JIRA issue <a href="https://issues.jboss.org/browse/DBZ-1040">DBZ-1040</a>.</p> </div> <div class="paragraph"> <p>As a bonus, we&#8217;ve also created a Grafana dashboard for visualizing all the relevant metrics:</p> </div> <div class="imageblock centered-image"> <img src="/images/monitoring_dashboard.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Connector metrics in Grafana"> </div> <div class="paragraph"> <p>We&#8217;ll blog about monitoring and the dashboard in more detail soon; but if you are interested, you already can take a look at <a href="https://github.com/debezium/debezium-examples/tree/master/monitoring">this demo</a> in our examples repository.</p> </div> </div> </div> <div class="sect1"> <h2 id="misc_features"><a class="anchor" href="#misc_features"></a>Misc. Features</h2> <div class="sectionbody"> <div class="paragraph"> <p>The "snapshot.delay.ms" option already known from the <a href="/docs/connectors/mysql/">Debezium MySQL connector</a> is now available for all other Debezium connectors, too (<a href="https://issues.jboss.org/browse/DBZ-966">DBZ-966</a>). This comes in handy when deploying multiple connectors to a Kafka Connect cluster, which may cause rebalancing the connectors in the cluster, interrupting and restarting running snapshots of already deployed connector instances. This can be avoided by specifying a delay which allows to wait with the snapshotting until the rebalancing phase is completed.</p> </div> <div class="paragraph"> <p>The <a href="/docs/configuration/mongodb-event-flattening/">MongoDB CDC Event Flattening</a> transformation received a number of improvements:</p> </div> <div class="ulist"> <ul> <li> <p>Support for MongoDB&#8217;s <code>$unset</code> operator (<a href="https://issues.jboss.org/browse/DBZ-612">DBZ-612</a>)</p> </li> <li> <p>Support for full document updates (<a href="https://issues.jboss.org/browse/DBZ-987">DBZ-987</a>)</p> </li> <li> <p>New option for dropping delete and tombstone messages (<a href="https://issues.jboss.org/browse/DBZ-563">DBZ-563</a>)</p> </li> <li> <p>Option to convey the original type of operation as a header parameter (<a href="https://issues.jboss.org/browse/DBZ-971">DBZ-971</a>); that option is also available for the <a href="/docs/configuration/event-flattening/">Flattening SMT</a> for the relational connectors and can be useful in case sink connectors need to differentiate between inserts and updates</p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="bug_fixes"><a class="anchor" href="#bug_fixes"></a>Bug fixes</h2> <div class="sectionbody"> <div class="paragraph"> <p>As always, we&#8217;ve also fixed a good number of bugs reported by Debezium users. The set of fixed issues includes:</p> </div> <div class="ulist"> <ul> <li> <p>Several bugs related to streaming changes from MySQL in GTID mode (<a href="https://issues.jboss.org/browse/DBZ-923">DBZ-923</a>, <a href="https://issues.jboss.org/browse/DBZ-1005">DBZ-1005</a>, <a href="https://issues.jboss.org/browse/DBZ-1008">DBZ-1008</a>)</p> </li> <li> <p>Handling of tables with reserved names in the SQL Server connector (<a href="https://issues.jboss.org/browse/DBZ-1031">DBZ-1031</a>)</p> </li> <li> <p>Potential event loss after MySQL connector restart (<a href="https://issues.jboss.org/browse/DBZ-1033">DBZ-1033</a>)</p> </li> <li> <p>Unchanged values of TOASTed columns caused the Postgres connector to fail (<a href="https://issues.jboss.org/browse/DBZ-842">DBZ-842</a>)</p> </li> </ul> </div> <div class="paragraph"> <p>Please see the <a href="/docs/releases/#release-0-9-0-beta2">change log</a> for the complete list of addressed issues.</p> </div> </div> </div> <div class="sect1"> <h2 id="next_steps"><a class="anchor" href="#next_steps"></a>Next Steps</h2> <div class="sectionbody"> <div class="paragraph"> <p>We&#8217;re planning to do a candidate release of Debezium 0.9 in early January. Provided no critical issues show up, Debezium 0.9.0.Final should be out by the end of January. For the CR we&#8217;ve mostly scheduled a number of further bug fixes, improvements to the SQL Server connector and the addition of further metrics.</p> </div> <div class="paragraph"> <p>In parallel, we&#8217;ll focus our attention on the Oracle connector again, finally getting back to the long-awaited LogMiner-based capture implementation (<a href="https://issues.jboss.org/browse/DBZ-137">DBZ-137</a>). This will be a primary feature of Debezium 0.10.</p> </div> <div class="paragraph"> <p>In addition, we&#8217;ll spend some cycles on the blogging and demo side of things; namely we&#8217;re thinking about writing on and demoing the new monitoring and metrics support, HA architectures including failover with MySQL, HAProxy and Debezium, as well as enriching CDC events with contextual information such as the current user or use case identifiers. Stay tuned!</p> </div> <div class="paragraph"> <p>Also going beyond 0.10, we got some <a href="/docs/roadmap/">great plans</a> for Debezium in the coming year. If you&#8217;d like to bring in your ideas, too, please let us know on the <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> or in the comments below, we&#8217;re looking forward to hearing from you.</p> </div> <div class="paragraph"> <p>And with that, all that remains to be said, is <a href="https://en.wikipedia.org/wiki/Festivus">"Happy Festivus for the rest of us!"</a></p> </div> <div class="paragraph"> <p>Happy change data streaming and see you in 2019!</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/12/05/automating-cache-invalidation-with-change-data-capture/">Automating Cache Invalidation With Change Data Capture</a> </h1> <div class="byline"> <p> <em> December 05, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/discussion/">discussion</a> <a class="label label-info" href="/blog/tags/examples/">examples</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>The <a href="https://docs.jboss.org/hibernate/stable/orm/userguide/html_single/Hibernate_User_Guide.html#caching-config">second-level cache</a> of Hibernate ORM / JPA is a proven and efficient way to increase application performance: caching read-only or rarely modified entities avoids roundtrips to the database, resulting in improved response times of the application.</p> </div> <div class="paragraph"> <p>Unlike the first-level cache, the second-level cache is associated with the session factory (or entity manager factory in JPA terms), so its contents are shared across transactions and concurrent sessions. Naturally, if a cached entity gets modified, the corresponding cache entry must be updated (or purged from the cache), too. As long as the data changes are done through Hibernate ORM, this is nothing to worry about: the ORM will update the cache automatically.</p> </div> <div class="paragraph"> <p>Things get tricky, though, when bypassing the application, e.g. when modifying records directly in the database. Hibernate ORM then has no way of knowing that the cached data has become stale, and it&#8217;s necessary to invalidate the affected items explicitly. A common way for doing so is to foresee some admin functionality that allows to clear an application&#8217;s caches. For this to work, it&#8217;s vital to not forget about calling that invalidation functionality, or the application will keep working with outdated cached data.</p> </div> <div class="paragraph"> <p>In the following we&#8217;re going to explore an alternative approach for cache invalidation, which works in a reliable and fully automated way: by employing Debezium and its <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/">change data capture</a> (CDC) capabilities, you can track data changes in the database itself and react to any applied change. This allows to invalidate affected cache entries in near-realtime, without the risk of stale data due to missed changes. If an entry has been evicted from the cache, Hibernate ORM will load the latest version of the entity from the database the next time is requested.</p> </div> </div> </div> <div class="sect1"> <h2 id="the_example_application"><a class="anchor" href="#the_example_application"></a>The Example Application</h2> <div class="sectionbody"> <div class="paragraph"> <p>As an example, consider this simple model of two entities, <code>PurchaseOrder</code> and <code>Item</code>:</p> </div> <div class="imageblock centered-image"> <img src="/images/cache_invalidation_class_diagram.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Example domain model"> </div> <div class="paragraph"> <p>A purchase order represents the order of an item, where its total price is the ordered quantity times the item&#8217;s base price.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Source Code</div> <div class="paragraph"> <p>The <a href="https://github.com/debezium/debezium-examples/tree/master/cache-invalidation/">source code</a> of this example is provided on GitHub. If you want to follow along and try out all the steps described in the following, clone the repo and follow the instructions in <a href="https://github.com/debezium/debezium-examples/tree/master/cache-invalidation/_README.md">README.md</a> for building the project.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Modelling order and item as JPA entities is straight-forward:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Entity&#x000A;public class PurchaseOrder {&#x000A;&#x000A;    @Id&#x000A;    @GeneratedValue(generator = "sequence")&#x000A;    @SequenceGenerator(&#x000A;        name = "sequence", sequenceName = "seq_po", initialValue = 1001, allocationSize = 50&#x000A;    )&#x000A;    private long id;&#x000A;    private String customer;&#x000A;    @ManyToOne private Item item;&#x000A;    private int quantity;&#x000A;    private BigDecimal totalPrice;&#x000A;&#x000A;    // ...&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>As changes to items are rare, the <code>Item</code> entity should be cached. This can be done by simply specifying JPA&#8217;s <a href="https://docs.oracle.com/javaee/7/api/javax/persistence/Cacheable.html">@Cacheable</a> annotation:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Entity&#x000A;@Cacheable&#x000A;public class Item {&#x000A;&#x000A;    @Id&#x000A;    private long id;&#x000A;    private String description;&#x000A;    private BigDecimal price;&#x000A;&#x000A;    // ...&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>You also need to enable the second-level cache in the <em>META-INF/persistence.xml</em> file. The property <code>hibernate.cache.use_second_level_cache</code> activates the cache itself, and the <code>ENABLE_SELECTIVE</code> cache mode causes only those entities to be put into the cache which are annotated with <code>@Cacheable</code>. It&#8217;s also a good idea to enable SQL query logging and cache access statistics. That way you&#8217;ll be able to verify whether things work as expected by examining the application log:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-xml" data-lang="xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;&#x000A;&lt;persistence xmlns="http://xmlns.jcp.org/xml/ns/persistence"&#x000A;    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&#x000A;    xsi:schemaLocation="..."&#x000A;    version="2.2"&gt;&#x000A;&#x000A;    &lt;persistence-unit name="orders-PU-JTA" transaction-type="JTA"&gt;&#x000A;        &lt;jta-data-source&gt;java:jboss/datasources/OrderDS&lt;/jta-data-source&gt;&#x000A;        &lt;shared-cache-mode&gt;ENABLE_SELECTIVE&lt;/shared-cache-mode&gt;&#x000A;        &lt;properties&gt;&#x000A;            &lt;property name="hibernate.cache.use_second_level_cache" value="true" /&gt;&#x000A;&#x000A;            &lt;property name="hibernate.show_sql" value="true" /&gt;&#x000A;            &lt;property name="hibernate.format_sql" value="true" /&gt;&#x000A;            &lt;property name="hibernate.generate_statistics" value="true" /&gt;&#x000A;&#x000A;            &lt;!-- dialect etc. ... --&gt;&#x000A;        &lt;/properties&gt;&#x000A;    &lt;/persistence-unit&gt;&#x000A;&lt;/persistence&gt;</code></pre> </div> </div> <div class="paragraph"> <p>When running on a <a href="https://www.oracle.com/technetwork/java/javaee/overview/index.html">Java EE</a> application server (or <a href="https://jakarta.ee/">Jakarta EE</a> how the stack is called after it has been donated to the Eclipse Foundation), that&#8217;s all you need to enable second-level caching. In the case of <a href="http://wildfly.org/">WildFly</a> (which is what&#8217;s used in the example project), the <a href="http://infinispan.org/">Infinispan</a> key/value store is used as the cache provider by default.</p> </div> <div class="paragraph"> <p>Now try and see what happens when modifying an item&#8217;s price by running some SQL in the database, bypassing the application layer. If you&#8217;ve checked out the example source code, comment out the <code>DatabaseChangeEventListener</code> class and start the application as described in the <em>README.md</em>. You then can place purchase orders using curl like this (a couple of example items have been persisted at application start-up):</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">&gt; curl -H "Content-Type: application/json" \&#x000A;  -X POST \&#x000A;  --data '{ "customer" : "Billy-Bob", "itemId" : 10003, "quantity" : 2 }' \&#x000A;  http://localhost:8080/cache-invalidation/rest/orders</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">{&#x000A;    "id" : 1002,&#x000A;    "customer" : "Billy-Bob",&#x000A;    "item" : {&#x000A;        "id" :10003,&#x000A;        "description" : "North By Northwest",&#x000A;        "price" : 14.99&#x000A;    },&#x000A;    "quantity" : 2,&#x000A;    "totalPrice" : 29.98&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>The response is the expected one, as the item price is 14.99. Now update the item&#8217;s price directly in the database. The example uses Postgres, so you can use the <em>psql</em> CLI utility to do so:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB -c "UPDATE item SET price = 20.99 where id = 10003"'</code></pre> </div> </div> <div class="paragraph"> <p>Placing another purchase order for the same item using curl, you&#8217;ll see that the calculated total price doesn&#8217;t reflect the update. Not good! But it&#8217;s not too surprising, given that the price update was applied completely bypassing the application layer and Hibernate ORM.</p> </div> </div> </div> <div class="sect1"> <h2 id="the_change_event_handler"><a class="anchor" href="#the_change_event_handler"></a>The Change Event Handler</h2> <div class="sectionbody"> <div class="paragraph"> <p>Now let&#8217;s explore how to use Debezium and CDC to react to changes in the <code>item</code> table and invalidate corresponding cache entries.</p> </div> <div class="paragraph"> <p>While Debezium most of the times is deployed into <a href="https://kafka.apache.org/documentation/#connect">Kafka Connect</a> (thus streaming change events into Apache Kafka topics), it has another mode of operation that comes in very handy for the use case at hand. Using the <a href="/docs/embedded/">embedded engine</a>, you can run the Debezium connectors as a library directly within your application. For each change event received from the database, a configured callback method will be invoked, which in the case at hand will evict the affected item from the second-level cache.</p> </div> <div class="paragraph"> <p>The following picture shows the design of this approach:</p> </div> <div class="imageblock centered-image"> <img src="/images/cache_invalidation_architecture.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Architecture Overview"> </div> <div class="paragraph"> <p>While this doesn&#8217;t come with the scalability and fault tolerance provided by Apache Kafka, it nicely fits the given requirements. As the second-level cache is bound to the application lifecycle, there is for instance no need for the offset management and restarting capabilities provided by the Kafka Connect framework. For the given use case it is enough to receive data change events while the application is running, and using the embedded engine enables exactly that.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Clustered Applications</div> <div class="paragraph"> <p>Note that it still might make sense to use Apache Kafka and the regular deployment of Debezium into Kafka Connect when running a clustered application where each node has a local cache. Instead of registering a connector on each node, Kafka and Connect would allow you to deploy a single connector instance and have the application nodes listen to the topic(s) with the change events. This would result in less resource utilization in the database.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>Having added the dependencies of the Debezium embedded engine (<em>io.debezium:debezium-embedded:0.9.0.Beta1</em>) and the Debezium Postgres connector (<em>io.debezium:debezium-connector-postgres:0.9.0.Beta1</em>) to your project, a class <code>DatabaseChangeEventListener</code> for listening to any changes in the database can be implemented like this:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class DatabaseChangeEventListener {&#x000A;&#x000A;    @Resource&#x000A;    private ManagedExecutorService executorService;&#x000A;&#x000A;    @PersistenceUnit private EntityManagerFactory emf;&#x000A;&#x000A;    @PersistenceContext&#x000A;    private EntityManager em;&#x000A;&#x000A;    private EmbeddedEngine engine;&#x000A;&#x000A;    public void startEmbeddedEngine(@Observes @Initialized(ApplicationScoped.class) Object init) {&#x000A;        Configuration config = Configuration.empty()&#x000A;                .withSystemProperties(Function.identity()).edit()&#x000A;                .with(EmbeddedEngine.CONNECTOR_CLASS, PostgresConnector.class)&#x000A;                .with(EmbeddedEngine.ENGINE_NAME, "cache-invalidation-engine")&#x000A;                .with(EmbeddedEngine.OFFSET_STORAGE, MemoryOffsetBackingStore.class)&#x000A;                .with("name", "cache-invalidation-connector")&#x000A;                .with("database.hostname", "postgres")&#x000A;                .with("database.port", 5432)&#x000A;                .with("database.user", "postgresuser")&#x000A;                .with("database.password", "postgrespw")&#x000A;                .with("database.server.name", "dbserver1")&#x000A;                .with("database.dbname", "inventory")&#x000A;                .with("database.whitelist", "public")&#x000A;                .with("snapshot.mode", "never")&#x000A;                .build();&#x000A;&#x000A;        this.engine = EmbeddedEngine.create()&#x000A;                .using(config)&#x000A;                .notifying(this::handleDbChangeEvent)&#x000A;                .build();&#x000A;&#x000A;        executorService.execute(engine);&#x000A;    }&#x000A;&#x000A;    @PreDestroy&#x000A;    public void shutdownEngine() {&#x000A;        engine.stop();&#x000A;    }&#x000A;&#x000A;    private void handleDbChangeEvent(SourceRecord record) {&#x000A;        if (record.topic().equals("dbserver1.public.item")) {&#x000A;            Long itemId = ((Struct) record.key()).getInt64("id");&#x000A;            Struct payload = (Struct) record.value();&#x000A;            Operation op = Operation.forCode(payload.getString("op"));&#x000A;&#x000A;            if (op == Operation.UPDATE || op == Operation.DELETE) {&#x000A;                emf.getCache().evict(Item.class, itemId);&#x000A;            }&#x000A;        }&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Upon application start-up, this configures an instance of the <a href="/docs/connectors/postgresql/">Debezium Postgres connector</a> and sets up the embedded engine for running the connector. The <a href="/docs/connectors/postgresql/#connector-properties">connector options</a> (host name, credentials etc.) are mostly the same as when deploying the connector into Kafka Connect. There is no need for doing an initial snapshot of the existing data, hence the <a href="/docs/connectors/postgresql/#snapshots">snapshot mode</a> is set to "never".</p> </div> <div class="paragraph"> <p>The offset storage option is used for controlling how connector offsets should be persisted. As it&#8217;s not necessary to process any change events occurring while the connector is not running (instead you&#8217;d just begin to read the log from the current location after the restart), the in-memory implementation provided by Kafka Connect is used.</p> </div> <div class="paragraph"> <p>Once configured, the embedded engine must be run via an <code>Executor</code> instance. As the example runs in WildFly, a managed executor can simply be obtained through <code>@Resource</code> injection for that purpose (see <a href="https://www.jcp.org/en/jsr/detail?id=236">JSR 236</a>).</p> </div> <div class="paragraph"> <p>The embedded engine is configured to invoke the <code>handleDbChangeEvent()</code> method for each received data change event. In this method it first is checked whether the incoming event originates from the <code>item</code> table. If that&#8217;s the case, and if the change event represents an <code>UPDATE</code> or <code>DELETE</code> statement, the affected <code>Item</code> instance is evicted from the second-level cache. JPA 2.0 provides a <a href="https://javaee.github.io/javaee-spec/javadocs/index.html?javax/persistence/Cache.html">simple API</a> for this purpose which is accessible via the <code>EntityManagerFactory</code>.</p> </div> <div class="paragraph"> <p>With the <code>DatabaseChangeEventListener</code> class in place, the cache entry will now automatically be evicted when doing another item update via <em>psql</em>. When placing the first purchase order for that item after the update, you&#8217;ll see in the application log how Hibernate ORM executes a query <code>SELECT ... FROM item ...</code> in order to load the item referenced by the order. Also the cache statistics will report one "L2C miss". Upon subsequent orders of that same item it will be obtained from the cache again.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Eventual Consistency</div> <div class="paragraph"> <p>While the event handling happens in near-realtime, it&#8217;s important to point out that it still applies eventual consistency semantics. This means that there is a very short time window between the point in time where a transaction is committed and the point in time where the change event is streamed from the log to the event handler and the cache entry is invalidated.</p> </div> </td> </tr> </table> </div> </div> </div> <div class="sect1"> <h2 id="avoiding_cache_invalidations_after_application_triggered_data_changes"><a class="anchor" href="#avoiding_cache_invalidations_after_application_triggered_data_changes"></a>Avoiding Cache Invalidations After Application-triggered Data Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>The change event listener shown above satisfies the requirement of invalidating cached items after external data changes. But in its current form it is evicting cache items a bit too aggressively: cached items will also be purged when updating an <code>Item</code> instance through the application itself. This is not only not needed (as the cached item already is the current version), but it&#8217;s even counter-productive: the superfluous cache evictions will cause additional database roundtrips, resulting in longer response times.</p> </div> <div class="paragraph"> <p>It is therefore necessary to distinguish between data changes performed by the application itself and external data changes. Only in the latter case the affected items should be evicted from the cache. In order to do so, you can leverage the fact that each Debezium data change event contains the id of the originating transaction. Keeping track of all transactions run by the application itself allows to trigger the cache eviction only for those items altered by external transactions.</p> </div> <div class="paragraph"> <p>Accounting for this change, the overall architecture looks like so:</p> </div> <div class="imageblock centered-image"> <img src="/images/cache_invalidation_architecture_tx_registry.png" style="max-width:100%; margin-bottom:20px; margin-top:20px;" class="responsive-image" alt="Architecture Overview with Transaction Registry"> </div> <div class="paragraph"> <p>The first thing to implement is the transaction registry, i.e. a class for the transaction book keeping:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class KnownTransactions {&#x000A;&#x000A;    private final DefaultCacheManager cacheManager;&#x000A;    private final Cache&lt;Long, Boolean&gt; applicationTransactions;&#x000A;&#x000A;    public KnownTransactions() {&#x000A;        cacheManager = new DefaultCacheManager();&#x000A;        cacheManager.defineConfiguration(&#x000A;                "tx-id-cache",&#x000A;                new ConfigurationBuilder()&#x000A;                    .expiration()&#x000A;                        .lifespan(60, TimeUnit.SECONDS)&#x000A;                    .build()&#x000A;                );&#x000A;&#x000A;        applicationTransactions = cacheManager.getCache("tx-id-cache");&#x000A;    }&#x000A;&#x000A;    @PreDestroy&#x000A;    public void stopCacheManager() {&#x000A;        cacheManager.stop();&#x000A;    }&#x000A;&#x000A;    public void register(long txId) {&#x000A;        applicationTransactions.put(txId, true);&#x000A;    }&#x000A;&#x000A;    public boolean isKnown(long txId) {&#x000A;        return Boolean.TRUE.equals(applicationTransactions.get(txId));&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>This uses the Infinispan <code>DefaultCacheManager</code> for creating and maintaining an in-memory cache of transaction ids encountered by the application. As data change events arrive in near-realtime, the TTL of the cache entries can be rather short (in fact, the value of one minute shown in the example is chosen very conservatively, usually events should be received within seconds).</p> </div> <div class="paragraph"> <p>The next step is to retrieve the current transaction id whenever a request is processed by the application and register it within <code>KnownTransactions</code>. This should happen once per transaction. There are multiple ways for implementing this logic; in the following a Hibernate ORM <code>FlushEventListener</code> is used for this purpose:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">class TransactionRegistrationListener implements FlushEventListener {&#x000A;&#x000A;    private volatile KnownTransactions knownTransactions;&#x000A;&#x000A;    public TransactionRegistrationListener() {&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public void onFlush(FlushEvent event) throws HibernateException {&#x000A;        event.getSession().getActionQueue().registerProcess( session -&gt; {&#x000A;            Number txId = (Number) event.getSession().createNativeQuery("SELECT txid_current()")&#x000A;                    .setFlushMode(FlushMode.MANUAL)&#x000A;                    .getSingleResult();&#x000A;&#x000A;            getKnownTransactions().register(txId.longValue());&#x000A;        } );&#x000A;    }&#x000A;&#x000A;    private  KnownTransactions getKnownTransactions() {&#x000A;        KnownTransactions value = knownTransactions;&#x000A;&#x000A;        if (value == null) {&#x000A;            knownTransactions = value = CDI.current().select(KnownTransactions.class).get();&#x000A;        }&#x000A;&#x000A;        return value;&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>As there&#8217;s no portable way to obtain the transaction id, this is done using a native SQL query. In the case of Postgres, the <code>txid_current()</code> function can be called for that. Hibernate ORM event listeners are not subject to dependency injection via CDI. Hence the static <code>current()</code> method is used to obtain a handle to the application&#8217;s CDI container and get a reference to the <code>KnownTransactions</code> bean.</p> </div> <div class="paragraph"> <p>This listener will be invoked whenever Hibernate ORM is synchronizing its persistence context with the database ("flushing"), which usually happens exactly once when the transaction is committed.</p> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="title">Manual Flushes</div> <div class="paragraph"> <p>The session / entity manager can also be flushed manually, in which case the <code>txid_current()</code> function would be invoked multiple times. That&#8217;s neglected here for the sake of simplicity. The actual code in the example repo contains a slightly extended version of this class which makes sure that the transaction id is obtained only once.</p> </div> </td> </tr> </table> </div> <div class="paragraph"> <p>To register the flush listener with Hibernate ORM, an <code>Integrator</code> implementation must be created and declared in the <em>META-INF/services/org.hibernate.integrator.spi.Integrator</em> file:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">public class TransactionRegistrationIntegrator implements Integrator {&#x000A;&#x000A;    @Override&#x000A;    public void integrate(Metadata metadata, SessionFactoryImplementor sessionFactory,&#x000A;            SessionFactoryServiceRegistry serviceRegistry) {&#x000A;        serviceRegistry.getService(EventListenerRegistry.class)&#x000A;            .appendListeners(EventType.FLUSH, new TransactionRegistrationListener());&#x000A;    }&#x000A;&#x000A;    @Override&#x000A;    public void disintegrate(SessionFactoryImplementor sessionFactory,&#x000A;            SessionFactoryServiceRegistry serviceRegistry) {&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>io.debezium.examples.cacheinvalidation.persistence.TransactionRegistrationIntegrator</code></pre> </div> </div> <div class="paragraph"> <p>During bootstrap, Hibernate ORM will detect the integrator class (by means of the <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/ServiceLoader.html">Java service loader</a>), invoke its <code>integrate()</code> method which in turn will register the listener class for the <code>FLUSH</code> event.</p> </div> <div class="paragraph"> <p>The last step is to exclude any events stemming from transactions run by the application itself in the database change event handler:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@ApplicationScoped&#x000A;public class DatabaseChangeEventListener {&#x000A;&#x000A;    // ...&#x000A;&#x000A;    @Inject&#x000A;    private KnownTransactions knownTransactions;&#x000A;&#x000A;    private void handleDbChangeEvent(SourceRecord record) {&#x000A;        if (record.topic().equals("dbserver1.public.item")) {&#x000A;            Long itemId = ((Struct) record.key()).getInt64("id");&#x000A;            Struct payload = (Struct) record.value();&#x000A;            Operation op = Operation.forCode(payload.getString("op"));&#x000A;            Long txId = ((Struct) payload.get("source")).getInt64("txId");&#x000A;&#x000A;            if (!knownTransactions.isKnown(txId) &amp;&amp;&#x000A;                    (op == Operation.UPDATE || op == Operation.DELETE)) {&#x000A;                emf.getCache().evict(Item.class, itemId);&#x000A;            }&#x000A;        }&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>And with that, you got all the pieces in place: cached <code>Item</code>s will only be evicted after external data changes, but not after changes done by the application itself. To confirm, you can invoke the example&#8217;s <code>items</code> resource using curl:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">&gt; curl -H "Content-Type: application/json" \&#x000A;  -X PUT \&#x000A;  --data '{ "description" : "North by Northwest", "price" : 20.99}' \&#x000A;  http://localhost:8080/cache-invalidation/rest/items/10003</code></pre> </div> </div> <div class="paragraph"> <p>When placing the next order for the item after this update, you should see that the <code>Item</code> entity is obtained from the cache, i.e. the change event will not have caused the item&#8217;s cache entry to be evicted. In contrast, if you update the item&#8217;s price via <em>psql</em> another time, the item should be removed from the cache and the order request will produce a cache miss, followed by a <code>SELECT</code> against the <code>item</code> table in the database.</p> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this blog post we&#8217;ve explored how Debezium and change data capture can be employed to invalidate application-level caches after external data changes. Compared to manual cache invalidation, this approach works very reliably (by capturing changes directly from the database log, no events will be missed) and fast (cache eviction happens in near-realtime after the data changes).</p> </div> <div class="paragraph"> <p>As you have seen, not too much glue code is needed in order to implement this. While the shown implementation is somewhat specific to the entities of the example, it should be possible to implement the change event handler in a more generic fashion, so that it can handle a set of configured entity types (essentially, the database change listener would have to convert the primary key field(s) from the change events into the primary key type of the corresponding entities in a generic way). Also such generic implementation would have to provide the logic for obtaining the current transaction id for the most commonly used databases.</p> </div> <div class="paragraph"> <p>Please let us know whether you think this would be an interesting extension to have for Debezium and Hibernate ORM. For instance this could be a new module under the Debezium umbrella, and it could also be a very great project to work on, should you be interested in contributing to Debezium. If you got any thoughts on this idea, please post a comment below or come to our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a>.</p> </div> <div class="paragraph"> <p>Many thanks to Guillaume Smet, Hans-Peter Grahsl and Jiri Pechanec for their feedback while writing this post!</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/11/22/debezium-0-9-0-beta1-released/">Debezium 0.9.0.Beta1 Released</a> </h1> <div class="byline"> <p> <em> November 22, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/sqlserver/">sqlserver</a> <a class="label label-info" href="/blog/tags/oracle/">oracle</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>It&#8217;s my pleasure to announce the release of Debezium <strong>0.9.0.Beta1</strong>! Oh, and to those of you who are celebrating it&#8201;&#8212;&#8201;Happy Thanksgiving!</p> </div> <div class="paragraph"> <p>This new Debezium release comes with several great improvements to our work-in-progress SQL Server connector:</p> </div> <div class="ulist"> <ul> <li> <p>Initial snapshots can be done using the <code>snapshot</code> isolation level if enabled in the DB (<a href="https://issues.jboss.org/browse/DBZ-941">DBZ-941</a>)</p> </li> <li> <p>Changes to the structures of captured tables after the connector has been set up are supported now (<a href="https://issues.jboss.org/browse/DBZ-812">DBZ-812</a>)</p> </li> <li> <p>New connector option <code>decimal.handling.mode</code> (<a href="https://issues.jboss.org/browse/DBZ-953">DBZ-953</a>) and pass-through of any <code>database.*</code> option to the JDBC driver (<a href="https://issues.jboss.org/browse/DBZ-964">DBZ-964</a>)</p> </li> </ul> </div> <div class="paragraph"> <p>Besides that, we spent some time on supporting the latest versions of the different databases. The Debezium connectors now support Postgres 11 (<a href="https://issues.jboss.org/browse/DBZ-955">DBZ-955</a>) and MongoDB 4.0 (<a href="https://issues.jboss.org/browse/DBZ-974">DBZ-974</a>). We are also working on supporting MySQL 8.0, which should be completed in the next 0.9.x release. The Debezium container images have been updated to Kafka 2.0.1 (<a href="https://issues.jboss.org/browse/DBZ-979">DBZ-979</a>) and the Kafka Connect image now supports the <code>STATUS_STORAGE_TOPIC</code> environment variable, bringing consistency with <code>CONFIG_STORAGE_TOPIC</code> and <code>OFFSET_STORAGE_TOPIC</code> that already were supported before (<a href="https://issues.jboss.org/browse/DBZ-893">DBZ-893</a>).</p> </div> <div class="paragraph"> <p>As usual, several bugs were fixed, too. Several of them dealt with the new Antlr-based DDL parser for the MySQL connector. By now we feel confident about its implementation, so it&#8217;s the default DDL parser as of this release (<a href="https://issues.jboss.org/browse/DBZ-757">DBZ-757</a>). If you would like to continue to use the legacy parser for some reason, you can do so by setting the <code>ddl.parser.mode</code> connector option to "legacy". This implementation will remain available in the lifetime of Debezium 0.9.x and is scheduled for removal after that. So please make sure to log issues in JIRA should you run into any problems with the Antlr parser.</p> </div> <div class="paragraph"> <p>Overall, this release contains <a href="/docs/releases/#release-0-9-0-beta1">21 fixes</a>. Thanks a lot to all the community members who helped with making this happen: <a href="https://github.com/anton-martynov">Anton Martynov</a>, <a href="https://github.com/deepakbarr">Deepak Barr</a>, <a href="https://github.com/grzegorz8">Grzegorz Ko≈Çakowski</a>, <a href="https://github.com/olavim">Olavi Mustanoja</a>, <a href="https://github.com/renatomefi">Renato Mefi</a>, <a href="https://github.com/vamossagar12">Sagar Rao</a> and <a href="https://github.com/shivamsharma">Shivam Sharma</a>!</p> </div> </div> </div> <div class="sect1"> <h2 id="what_else"><a class="anchor" href="#what_else"></a>What else?</h2> <div class="sectionbody"> <div class="paragraph"> <p>While the work towards Debezium 0.9 continues, we&#8217;ve lately been quite busy with presenting Debezium at multiple conferences. You can find the slides and recordings from <a href="https://kafka-summit.org/sessions/change-data-streaming-patterns-microservices-debezium/">Kafka Summit</a> San Francisco and <a href="https://vxdms2018.confinabox.com/talk/INI-9172/Data_Streaming_for_Microservices_using_Debezium">Voxxed Days Microservices</a> on our list of <a href="/docs/online-resources/">online resources</a> around Debezium.</p> </div> <div class="paragraph"> <p>There you also can find the links to the slides of the great talk "The Why‚Äôs and How‚Äôs of Database Streaming" by Joy Gao of WePay, a Debezium user of the first hour, as well as the link to a blog post by Hans-Peter Grahsl about setting up a CDC pipeline from MySQL into Cosmos DB running on Azure. If you know about other great articles, session recordings or similar on Debezium and change data capture which should be added there, please let us know.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/10/04/debezium-0-9-0-alpha2-released/">Debezium 0.9.0.Alpha2 Released</a> </h1> <div class="byline"> <p> <em> October 04, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/sqlserver/">sqlserver</a> <a class="label label-info" href="/blog/tags/oracle/">oracle</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>It&#8217;s my pleasure to announce the release of Debezium <strong>0.9.0.Alpha2</strong>!</p> </div> <div class="paragraph"> <p>While the work on the connectors for SQL Server and Oracle continues, we decided to do another Alpha release, as lots of fixes and new features - many of them contributed by community members - have piled up, which we wanted to get into your hands as quickly as possible.</p> </div> <div class="paragraph"> <p>This release supports Apache Kafka 2.0, comes with support for Postgres' HSTORE column type, allows to rename and filter fields from change data messages for MongoDB and contains multiple bug fixes and performance improvements. Overall, this release contains <a href="/docs/releases/#release-0-9-0-alpha2">55 fixes</a> (note that a few of these have been merged back to 0.8.x and are contained in earlier 0.8 releases, too).</p> </div> <div class="paragraph"> <p>A big "Thank You" is in order to community members <a href="https://github.com/jchipmunk">Andrey Pustovetov</a>, <a href="https://github.com/artiship">Artiship Artiship</a>, <a href="https://github.com/CliffWheadon">Cliff Wheadon</a>, <a href="https://github.com/deepakbarr">Deepak Barr</a>, <a href="https://github.com/ian-axelrod">Ian Axelrod</a>, <a href="https://github.com/ooooorz">Liu Hanlin</a>, <a href="https://github.com/maver1ck">Maciej Bry≈Ñski</a>, <a href="https://github.com/oripwk">Ori Popowski</a>, <a href="https://github.com/PengLyu">Peng Lyu</a>, <a href="https://github.com/PSanetra">Philip Sanetra</a>, <a href="https://github.com/sagarrao">Sagar Rao</a> and <a href="https://github.com/SyedMuhammadSufyian">Syed Muhammad Sufyian</a> for their contributions to this release. We salute you!</p> </div> </div> </div> <div class="sect1"> <h2 id="kafka_upgrade"><a class="anchor" href="#kafka_upgrade"></a>Kafka Upgrade</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium runs with and has been tested on top of the recently released Apache Kafka 2.0 (<a href="https://issues.jboss.org/browse/DBZ-858">DBZ-858</a>). The widely used version Kafka 1.x continues to be supported as well.</p> </div> <div class="paragraph"> <p>Note that 0.10.x is not supported due to Debezium&#8217;s usage of the admin client API which is only available in later versions. It shouldn&#8217;t be too hard to work around this, so if someone is interested in helping out with this, this would be a great contribution (see <a href="https://issues.jboss.org/browse/DBZ-883">DBZ-883</a>).</p> </div> </div> </div> <div class="sect1"> <h2 id="support_for_hstore_columns_in_postgres"><a class="anchor" href="#support_for_hstore_columns_in_postgres"></a>Support for HSTORE columns in Postgres</h2> <div class="sectionbody"> <div class="paragraph"> <p>Postgres is an amazingly powerful and flexible RDBMS, not the least due to its wide range of column types which go far beyond what&#8217;s defined by the SQL standard. One of these types being <a href="https://www.postgresql.org/docs/current/static/hstore.html">HSTORE</a>, which is a string-to-string map essentially.</p> </div> <div class="paragraph"> <p>Debezium can capture changes to columns of this type now (<a href="https://issues.jboss.org/browse/DBZ-898">DBZ-898</a>). By default, the field values will be represented using Kafka Connect&#8217;s map data type. As this may not be supported by all sink connectors, you might alternatively represent them as a string-ified JSON by setting the new <code>hstore.handling.mode</code> connector option to <code>json</code>. In this case, you&#8217;d see HSTORE columns represented as values in change messages like so: <code>{ "key1" : "val1", "key2" : "val2" }</code>.</p> </div> </div> </div> <div class="sect1"> <h2 id="field_filtering_and_renaming_for_mongodb"><a class="anchor" href="#field_filtering_and_renaming_for_mongodb"></a>Field filtering and renaming for MongoDB</h2> <div class="sectionbody"> <div class="paragraph"> <p>Unlike the connectors for MySQL and Postgres, the Debezium MongoDB connector so far didn&#8217;t allow to exclude single fields of captured collections from CDC messages. Also renaming them wasn&#8217;t supported e.g. by means of Kafka&#8217;s <code>ReplaceField</code> SMT. The reason being that MongoDB doesn&#8217;t mandate a fixed schema for the documents of a given collection, and documents therefore are represented in change messages using a single string-ified JSON field.</p> </div> <div class="paragraph"> <p>Thanks to the fantastic work of community member Andrey Pustovetov, this finally has changed, i.e. you can remove given fields (<a href="https://issues.jboss.org/browse/DBZ-633">DBZ-633</a>) now from the CDC messages of given collections or have them renamed (<a href="https://issues.jboss.org/browse/DBZ-881">DBZ-881</a>). Please refer to the description of the new connector options <code>field.blacklist</code> and <code>field.renames</code> in the <a href="/docs/connectors/mongodb/">MongoDB connector documentation</a> to learn more.</p> </div> </div> </div> <div class="sect1"> <h2 id="extended_source_info"><a class="anchor" href="#extended_source_info"></a>Extended source info</h2> <div class="sectionbody"> <div class="paragraph"> <p>Another contribution by Andrey is the new optional <code>connector</code> field within the source info block of CDC messages (<a href="https://issues.jboss.org/browse/DBZ-918">DBZ-918</a>). This tells the type of source connector that produced the messages ("mysql", "postgres" etc.), which can come in handy in cases where specific semantics need to be applied on the consumer side depending on the type of source database.</p> </div> </div> </div> <div class="sect1"> <h2 id="bug_fixes_and_version_upgrades"><a class="anchor" href="#bug_fixes_and_version_upgrades"></a>Bug fixes and version upgrades</h2> <div class="sectionbody"> <div class="paragraph"> <p>The new release contains a good number of bug fixes and other smaller improvements. Amongst them are</p> </div> <div class="ulist"> <ul> <li> <p>correct handling of invalid temporal default values with MySQL (<a href="https://issues.jboss.org/browse/DBZ-927">DBZ-927</a>),</p> </li> <li> <p>support for table/collection names with special characters for MySQL (<a href="https://issues.jboss.org/browse/DBZ-878">DBZ-878</a>) and MongoDB (<a href="https://issues.jboss.org/browse/DBZ-865">DBZ-865</a>) and</p> </li> <li> <p>fixed handling of blacklisted tables with the new Antlr-based DDL parser (<a href="https://issues.jboss.org/browse/DBZ-872">DBZ-872</a>).</p> </li> </ul> </div> <div class="paragraph"> <p>Community member Ian Axelrod provided a fix for a potential performance issue, where changes to tables with TOAST columns in Postgres would cause repeated updates to the connector&#8217;s internal schema metadata, which can be a costly operation (<a href="https://issues.jboss.org/browse/DBZ-911">DBZ-911</a>). Please refer to the <a href="/docs/connectors/postgres/">Postgres connector documentation</a> for details on the new <code>schema.refresh.mode</code> option, which deals with this issue.</p> </div> <div class="paragraph"> <p>In terms of version upgrades we migrated to the latest releases of the MySQL (<a href="https://issues.jboss.org/browse/DBZ-763">DBZ-763</a>, <a href="https://issues.jboss.org/browse/DBZ-764">DBZ-764</a>) and Postgres drivers (<a href="https://issues.jboss.org/browse/DBZ-912">DBZ-912</a>). The former is part of a longer stream of work leading towards support of MySQL 8 which should be finished in one of the next Debezium releases. For Postgres we provide a Docker image with Debezium&#8217;s supported logical decoding plug-ins based on Alpine now, which might be interesting to those concerned about container size (<a href="https://issues.jboss.org/browse/DBZ-705">DBZ-705</a>).</p> </div> <div class="paragraph"> <p>Please see the change log for the complete list of fixed issues.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_s_next"><a class="anchor" href="#what_s_next"></a>What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>The work towards Debezium 0.9 continues, and we&#8217;ll focus mostly on improvements to the SQL Server and Oracle connectors. Other potential topics include support for MySQL 8 and native logical decoding as introduced with Postgres 10, which should greatly help with using the Debezium Postgres connectors in cloud environments such as Amazon RDS.</p> </div> <div class="paragraph"> <p>We&#8217;ll also be talking about Debezium at the following conferences:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://kafka-summit.org/sessions/change-data-streaming-patterns-microservices-debezium/">Kafka Summit</a>; San Francisco, Cal.; Oct. 17</p> </li> <li> <p><a href="https://vxdms2018.confinabox.com/talk/INI-9172/Data_Streaming_for_Microservices_using_Debezium">VoxxedDays Microservices</a>; Paris, France; Oct. 29 - 31</p> </li> <li> <p><a href="https://cfp.devoxx.ma/2018/talk/AEY-4477/Change_Data_Streaming_Patterns_for_Microservices_With_Debezium">Devoxx Morocco</a>; Marrakesh, Morocco; Nov. 27 - 29</p> </li> </ul> </div> <div class="paragraph"> <p>Already last week I had the opportunity to present Debezium at <a href="https://jug-saxony-day.org/programm/#!/P31">JUG Saxony Day</a>. If you are interested, you can find the (German) <a href="https://speakerdeck.com/gunnarmorling/streaming-von-datenbankanderungen-mit-debezium-jug-saxony-day">slideset of that talk</a> on Speaker Deck.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/">Materializing Aggregate Views With Hibernate and Debezium</a> </h1> <div class="byline"> <p> <em> September 20, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/discussion/">discussion</a> <a class="label label-info" href="/blog/tags/examples/">examples</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>Updating external full text search indexes (e.g. <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a>) after data changes is a very popular use case for change data capture (CDC).</p> </div> <div class="paragraph"> <p>As we&#8217;ve discussed in a <a href="/blog/2018/01/17/streaming-to-elasticsearch/">blog post</a> a while ago, the combination of Debezium&#8217;s CDC source connectors and Confluent&#8217;s <a href="https://docs.confluent.io/current/connect/connect-elasticsearch/docs/index.html">sink connector for Elasticsearch</a> makes it straight forward to capture data changes in MySQL, Postgres etc. and push them towards Elastisearch in near real-time. This results in a 1:1 relationship between tables in the source database and a corresponding search index in Elasticsearch, which is perfectly fine for many use cases.</p> </div> <div class="paragraph"> <p>It gets more challenging though if you&#8217;d like to put entire aggregates into a single index. An example could be a customer and all their addresses; those would typically be stored in two separate tables in an RDBMS, linked by a foreign key, whereas you&#8217;d like to have just one index in Elasticsearch, containing documents of customers with their addresses embedded, allowing you to efficiently search for customers based on their address.</p> </div> <div class="paragraph"> <p>Following up to the <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/">KStreams-based solution</a> to this we described recently, we&#8217;d like to present in this post an alternative for materializing such aggregate views driven by the application layer.</p> </div> </div> </div> <div class="sect1"> <h2 id="overview"><a class="anchor" href="#overview"></a>Overview</h2> <div class="sectionbody"> <div class="paragraph"> <p>The idea is to materialize views in a separate table in the source database, right in the moment the original data is altered.</p> </div> <div class="paragraph"> <p>Aggregates are serialized as JSON structures (which naturally can represent any nested object structure) and stored in a specific table. This is done within the actual transaction altering the data, which means the aggregate view is always consistent with the primary data. In particular this approach isn&#8217;t prone to exposing intermediary aggregations as the KStreams-based solution discussed in the post linked above.</p> </div> <div class="paragraph"> <p>The following picture shows the overall architecture:</p> </div> <img src="/images/jpa_aggregations.png" style="max-width:100%; margin-bottom:10px;" class="responsive-image" alt="Streaming Materialized Aggregate Views to Elastisearch"> <div class="paragraph"> <p>Here the aggregate views are materialized by means of a small extension to <a href="http://hibernate.org/orm/">Hibernate ORM</a>, which stores the JSON aggregates within the source database (note "aggregate views" can be considered conceptually the same as "materialized views" as known from different RDBMS, as in that they materialize the result of a "join" operation, but technically we&#8217;re not using the latter to store aggregate views, but a regular table). Changes to that aggregate table are then captured by Debezium and streamed to one topic per aggregate type. The Elasticsearch sink connector can subscribe to these topics and update corresponding full-text indexes.</p> </div> <div class="paragraph"> <p>You can find a proof-of-concept implementation (said Hibernate extension and related code) of this idea in our <a href="https://github.com/debezium/debezium-examples/tree/master/jpa-aggregations">examples repository</a>. Of course the general idea isn&#8217;t limited to Hibernate ORM or JPA, you could implement something similar with any other API you&#8217;re using to access your data.</p> </div> </div> </div> <div class="sect1"> <h2 id="creating_aggregate_views_via_hibernate_orm"><a class="anchor" href="#creating_aggregate_views_via_hibernate_orm"></a>Creating Aggregate Views via Hibernate ORM</h2> <div class="sectionbody"> <div class="paragraph"> <p>For the following let&#8217;s assume we&#8217;re persisting a simple domain model (comprising a <code>Customer</code> entity and a few related ones like <code>Address</code>, (customer) <code>Category</code> etc.) in a database. Using Hibernate for that allows us to make the creation of aggregates fully transparent to the actual application code using a <a href="http://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#events-events">Hibernate event listener</a>. Thanks to its extensible architecture, we can plug such listener into Hibernate just by adding it to the classpath, from where it will be picked up automatically when bootstrapping the entity manager / session factory.</p> </div> <div class="paragraph"> <p>Our example listener reacts to an annotation, <code>@MaterializeAggregate</code>, which marks those entity types that should be the roots of materialized aggregates.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Entity&#x000A;@MaterializeAggregate(aggregateName="customers-complete")&#x000A;public class Customer {&#x000A;&#x000A;    @Id&#x000A;    private long id;&#x000A;&#x000A;    private String firstName;&#x000A;&#x000A;    @OneToMany(mappedBy = "customer", fetch = FetchType.EAGER, cascade = CascadeType.ALL)&#x000A;    private Set&lt;Address&gt; addresses;&#x000A;&#x000A;    @ManyToOne&#x000A;    private Category category;&#x000A;&#x000A;    ...&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Now if any entity annotated with <code>@MaterializeAggregate</code> is inserted, updated or deleted via Hibernate, the listener will kick in and materialize a JSON view of the aggregate root (customer) and its associated entities (addresses, category).</p> </div> <div class="paragraph"> <p>Under the hood the <a href="https://github.com/FasterXML/jackson">Jackson API</a> is used for serializing the model into JSON. This means you can use any of its annotations to customize the JSON output, e.g. <code>@JsonIgnore</code> to exclude the inverse relationship from <code>Address</code> to <code>Customer</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">@Entity&#x000A;public class Address {&#x000A;&#x000A;    @Id&#x000A;    private long id;&#x000A;&#x000A;    @ManyToOne&#x000A;    @JoinColumn(name = "customer_id")&#x000A;    @JsonIgnore&#x000A;    private Customer customer;&#x000A;&#x000A;    private String street;&#x000A;&#x000A;    private String city;&#x000A;&#x000A;    ...&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Note that <code>Address</code> itself isn&#8217;t marked with <code>@MaterializeAggregate</code>, i.e. it won&#8217;t be materialized into an aggregate view by itself.</p> </div> <div class="paragraph"> <p>After using JPA&#8217;s <code>EntityManager</code> to insert or update a few customers, let&#8217;s take a look at the <code>aggregates</code> table which has been populated by the listener (value schema omitted for the sake of brevity):</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-sql" data-lang="sql">&gt; select * from aggregates;&#x000A;&#x000A;| rootType | keySchema | rootId | materialization | valueSchema |&#x000A;&#x000A;| customers-complete&#x000A;&#x000A;| {&#x000A;  "schema" : {&#x000A;    "type" : "struct",&#x000A;    "fields" : [ {&#x000A;      "type" : "int64",&#x000A;      "optional" : false,&#x000A;      "field" : "id"&#x000A;    } ],&#x000A;    "optional" : false,&#x000A;    "name" : "customers-complete.Key"&#x000A;  }&#x000A;}&#x000A;&#x000A;| { "id" : 1004 }&#x000A;&#x000A;| { "schema" : { ... } }&#x000A;&#x000A;| {&#x000A;  "id" : 1004,&#x000A;  "firstName" : "Anne",&#x000A;  "lastName" : "Kretchmar",&#x000A;  "email" : "annek@noanswer.org",&#x000A;  "tags" : [ "long-term", "vip" ],&#x000A;  "birthday" : 5098,&#x000A;  "category" : {&#x000A;    "id" : 100001,&#x000A;    "name" : "Retail"&#x000A;  },&#x000A;  "addresses" : [ {&#x000A;    "id" : 16,&#x000A;    "street" : "1289 University Hill Road",&#x000A;    "city" : "Canehill",&#x000A;    "state" : "Arkansas",&#x000A;    "zip" : "72717",&#x000A;    "type" : "SHIPPING"&#x000A;  } ]&#x000A;} |</code></pre> </div> </div> <div class="paragraph"> <p>The table contains these columns:</p> </div> <div class="ulist"> <ul> <li> <p><code>rootType</code>: The name of the aggregate as given in the <code>@MaterializeAggregate</code> annotation</p> </li> <li> <p><code>rootId</code>: The aggregate&#8217;s id as serialized JSON</p> </li> <li> <p><code>materialization</code>: The aggregate itself as serialized JSON; in this case a customer and their addresses, category etc.</p> </li> <li> <p><code>keySchema</code>: The Kafka Connect schema of the row&#8217;s key</p> </li> <li> <p><code>valueSchema</code>: The Kafka Connect schema of the materialization</p> </li> </ul> </div> <div class="paragraph"> <p>Let&#8217;s talk about the two schema columns for a bit. JSON itself is quite limited as far as its supported data types are concerned. So for instance we&#8217;d loose information about a numeric field&#8217;s value range (int vs. long etc.) without any additional information. Therefore the listener derives the corresponding schema information for key and aggregate view from the entity model and stores it within the aggregate records.</p> </div> <div class="paragraph"> <p>Now Jackson itself only supports JSON Schema, which would be a bit too limited for our purposes. Hence the example implementation provides custom serializers for Jackson&#8217;s schema system, which allow us to emit Kafka Connect&#8217;s schema representation (with more precise type information) instead of plain JSON Schema. This will come in handy in the following when we&#8217;d like to expand the string-based JSON representations of key and value into properly typed Kafka Connect records.</p> </div> </div> </div> <div class="sect1"> <h2 id="capturing_changes_to_the_aggregate_table"><a class="anchor" href="#capturing_changes_to_the_aggregate_table"></a>Capturing Changes to the Aggregate Table</h2> <div class="sectionbody"> <div class="paragraph"> <p>We now have a mechanism in place which transparently persists aggregates into a separate table within the source database, whenever the application data is changed through Hibernate. Note that this happens within the boundaries of the source transaction, so if the same would be rolled back for some reason, also the aggregate view would not be updated.</p> </div> <div class="paragraph"> <p>The Hibernate listener uses insert-or-update semantics when writing an aggregate view, i.e. for a given aggregate root there&#8217;ll always be exactly one corresponding entry in the aggregate table which reflects its current state. If an aggregate root entity is deleted, the listener will also drop the entry from the aggregate table.</p> </div> <div class="paragraph"> <p>So let&#8217;s set up Debezium now to capture any changes to the <code>aggregates</code> table:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">curl -i -X POST \&#x000A;  -H "Accept:application/json" \&#x000A;  -H "Content-Type:application/json" \&#x000A;  http://localhost:8083/connectors/ -d @- &lt;&lt;-EOF&#x000A;  {&#x000A;      "name": "inventory-connector",&#x000A;      "config": {&#x000A;          "connector.class": "io.debezium.connector.mysql.MySqlConnector",&#x000A;          "tasks.max": "1",&#x000A;          "database.hostname": "mysql",&#x000A;          "database.port": "3306",&#x000A;          "database.user": "debezium",&#x000A;          "database.password": "dbz",&#x000A;          "database.server.id": "184054",&#x000A;          "database.server.name": "dbserver1",&#x000A;          "database.whitelist": "inventory",&#x000A;          "table.whitelist": ".*aggregates",&#x000A;          "database.history.kafka.bootstrap.servers": "kafka:9092",&#x000A;          "database.history.kafka.topic": "schema-changes.inventory"&#x000A;      }&#x000A;  }&#x000A;EOF</code></pre> </div> </div> <div class="paragraph"> <p>This registers the MySQL connector with the "inventory" database (we&#8217;re using an expanded version of the schema from the <a href="/docs/tutorial/">Debezium tutorial</a>), capturing any changes to the "aggregates" table.</p> </div> </div> </div> <div class="sect1"> <h2 id="expanding_json"><a class="anchor" href="#expanding_json"></a>Expanding JSON</h2> <div class="sectionbody"> <div class="paragraph"> <p>If we now were to browse the corresponding Kafka topic, we&#8217;d see data change events in the known Debezium format for all the changes to the <code>aggregates</code> table.</p> </div> <div class="paragraph"> <p>The "materialization" field with the records' "after" state still is a single field containing a JSON string, though. What we&#8217;d rather like to have is a strongly typed Kafka Connect record, whose schema exactly describes the aggregate structure and the types of its fields. For that purpose the example project provides an SMT (single message transform) which takes the JSON materialization and the corresponding <code>valueSchema</code> and converts this into a full-blown Kafka Connect record. The same is done for keys. DELETE events are rewritten into tombstone events. Finally, the SMT re-routes every record to a topic named after the aggregate root, allowing consumers to subscribe just to changes to specific aggregate types.</p> </div> <div class="paragraph"> <p>So let&#8217;s add that SMT when registering the Debezium CDC connector:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">...&#x000A;"transforms":"expandjson",&#x000A;"transforms.expandjson.type":"io.debezium.aggregation.smt.ExpandJsonSmt",&#x000A;...</code></pre> </div> </div> <div class="paragraph"> <p>When now browsing the "customers-complete" topic, we&#8217;ll see the strongly typed Kafka Connect records we&#8217;d expect:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "schema": {&#x000A;        "type": "struct",&#x000A;        "fields": [&#x000A;            {&#x000A;                "type": "int64",&#x000A;                "optional": false,&#x000A;                "field": "id"&#x000A;            }&#x000A;        ],&#x000A;        "optional": false,&#x000A;        "name": "customers-complete.Key"&#x000A;    },&#x000A;    "payload": {&#x000A;        "id": 1004&#x000A;    }&#x000A;}&#x000A;{&#x000A;    "schema": {&#x000A;        "type": "struct",&#x000A;        "fields": [ ... ],&#x000A;        "optional": true,&#x000A;        "name": "urn:jsonschema:com:example:domain:Customer"&#x000A;    },&#x000A;    "payload": {&#x000A;        "id": 1004,&#x000A;        "firstName": "Anne",&#x000A;        "lastName": "Kretchmar",&#x000A;        "email": "annek@noanswer.org",&#x000A;        "active": true,&#x000A;        "tags" : [ "long-term", "vip" ],&#x000A;        "birthday" : 5098,&#x000A;        "category": {&#x000A;            "id": 100001,&#x000A;            "name": "Retail"&#x000A;        },&#x000A;        "addresses": [&#x000A;            {&#x000A;                "id": 16,&#x000A;                "street": "1289 University Hill Road",&#x000A;                "city": "Canehill",&#x000A;                "state": "Arkansas",&#x000A;                "zip": "72717",&#x000A;                "type": "LIVING"&#x000A;            }&#x000A;        ]&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>To confirm that these are actual typed Kafka Connect records and not just a single JSON string field, you could for instance use the <a href="/docs/configuration/avro/">Avro message converter</a> and examine the message schemas in the schema registry.</p> </div> </div> </div> <div class="sect1"> <h2 id="sinking_aggregate_messages_into_elasticsearch"><a class="anchor" href="#sinking_aggregate_messages_into_elasticsearch"></a>Sinking Aggregate Messages Into Elasticsearch</h2> <div class="sectionbody"> <div class="paragraph"> <p>The last missing step is to register the Confluent Elasticsearch sink connector, hooking it up with the "customers-complete" topic and letting it push any changes to the corresponding index:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">curl -i -X POST \&#x000A;  -H "Accept:application/json" \&#x000A;  -H "Content-Type:application/json" \&#x000A;  http://localhost:8083/connectors/ -d @- &lt;&lt;-EOF&#x000A;  {&#x000A;      "name": "es-customers",&#x000A;      "config": {&#x000A;          "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",&#x000A;          "tasks.max": "1",&#x000A;          "topics": "customers-complete",&#x000A;          "connection.url": "http://elastic:9200",&#x000A;          "key.ignore": "false",&#x000A;          "schema.ignore" : "false",&#x000A;          "behavior.on.null.values" : "delete",&#x000A;          "type.name": "customer-with-addresses",&#x000A;          "transforms" : "key",&#x000A;          "transforms.key.type": "org.apache.kafka.connect.transforms.ExtractField$Key",&#x000A;          "transforms.key.field": "id"&#x000A;      }&#x000A;  }&#x000A;EOF</code></pre> </div> </div> <div class="paragraph"> <p>This uses Connect&#8217;s <code>ExtractField</code> transformation to obtain just the actual id value from the key struct and use it as key for the corresponding Elasticsearch documents. Specifying the "behavior.on.null.values" option will let the connector delete the corresponding document from the index when encountering a tombstone message (i.e. a message with a key but without value).</p> </div> <div class="paragraph"> <p>Finally, we can use the Elasticsearch REST API to browse the index and of course use its powerful full-text query language to find customers by the address or any other property embedded into the aggregate structure:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">&gt; curl -X GET -H "Accept:application/json" \&#x000A;  http://localhost:9200/customers-complete/_search?pretty&#x000A;&#x000A;  {&#x000A;      "_shards": {&#x000A;          "failed": 0,&#x000A;          "successful": 5,&#x000A;          "total": 5&#x000A;      },&#x000A;      "hits": {&#x000A;          "hits": [&#x000A;              {&#x000A;                  "_id": "1004",&#x000A;                  "_index": "customers-complete",&#x000A;                  "_score": 1.0,&#x000A;                  "_source": {&#x000A;                      "active": true,&#x000A;                      "addresses": [&#x000A;                          {&#x000A;                              "city": "Canehill",&#x000A;                              "id": 16,&#x000A;                              "state": "Arkansas",&#x000A;                              "street": "1289 University Hill Road",&#x000A;                              "type": "LIVING",&#x000A;                              "zip": "72717"&#x000A;                          }&#x000A;                      ],&#x000A;                      "tags" : [ "long-term", "vip" ],&#x000A;                      "birthday" : 5098,&#x000A;                      "category": {&#x000A;                          "id": 100001,&#x000A;                          "name": "Retail"&#x000A;                      },&#x000A;                      "email": "annek@noanswer.org",&#x000A;                      "firstName": "Anne",&#x000A;                      "id": 1004,&#x000A;                      "lastName": "Kretchmar",&#x000A;                      "scores": [],&#x000A;                      "someBlob": null,&#x000A;                      "tags": []&#x000A;                  },&#x000A;                  "_type": "customer-with-addresses"&#x000A;              }&#x000A;          ],&#x000A;          "max_score": 1.0,&#x000A;          "total": 1&#x000A;      },&#x000A;      "timed_out": false,&#x000A;      "took": 11&#x000A;  }</code></pre> </div> </div> <div class="paragraph"> <p>And there you have it: a customer&#8217;s complete data, including their addresses, categories, tags etc., materialized into a single document within Elasticsearch. If you&#8217;re using JPA to update the customer, you&#8217;ll see the data in the index being updated accordingly in near-realtime.</p> </div> </div> </div> <div class="sect1"> <h2 id="pros_and_cons"><a class="anchor" href="#pros_and_cons"></a>Pros and Cons</h2> <div class="sectionbody"> <div class="paragraph"> <p>So what are the advantages and disadvantages of this approach for materializing aggregates from multiple source tables compared to the <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/">KStreams-based approach</a>?</p> </div> <div class="paragraph"> <p>The big advantage is consistency and awareness of transactional boundaries, whereas the KStreams-based solution in its suggested form was prone to exposing intermediary aggregates. For instance, if you&#8217;re storing a customer and three addresses, it might happen that the streaming query first creates an aggregation of the customer and the two addresses inserted first, and shortly thereafter the complete aggregate with all three addresses. This not the case for the approach discussed here, as you&#8217;ll only ever stream complete aggregates to Kafka. Also this approach feels a bit more "light-weight", i.e. a simple marker annotation (together with some Jackson annotations for fine-tuning the emitted JSON structures) is enough in order to materialize aggregates from your domain model, whereas some more effort was needed to set up the required streams, temporary tables etc. with the KStreams solution.</p> </div> <div class="paragraph"> <p>The downside of driving aggregations through the application layer is that it&#8217;s not fully agnostic to the way you access the primary data. If you bypass the application, e.g. by patching data directly in the database, naturally these updates would be missed, requiring a refresh of affected aggregates. Although this again could be done through change data capture and Debezium: change events to source tables could be captured and consumed by the application itself, allowing it to re-materialize aggregates after external data changes. You also might argue that running JSON serializations within source transactions and storing aggregates within the source database represents some overhead. This often may be acceptable, though.</p> </div> <div class="paragraph"> <p>Another question to ask is what&#8217;s the advantage of using change data capture on an intermediary aggregate table over simply posting REST requests to Elasticsearch. The answer is the highly increased robustness and fault tolerance. If the Elasticsearch cluster can&#8217;t be accessed for some reason, the machinery of Kafka and Kafka Connect will ensure that any change events will be propagated eventually, once the sink is up again. Also other consumers than Elasticsearch can subscribe to the aggregate topic, the log can be replayed from the beginning etc.</p> </div> <div class="paragraph"> <p>Note that while we&#8217;ve been talking primarily about using Elasticsearch as a data sink, there are also other datastores and connectors that support complexly structured records. One example would be MongoDB and the <a href="https://github.com/hpgrahsl/kafka-connect-mongodb">sink connector</a> maintained by Hans-Peter Grahsl, which one could use to sink customer aggregates into MongoDB, for instance enabling efficient retrieval of a customer and all their associated data with a single primary key look-up.</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook"><a class="anchor" href="#outlook"></a>Outlook</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Hibernate ORM extension as well as the SMT discussed in this post can be found in our <a href="https://github.com/debezium/debezium-examples/tree/master/jpa-aggregations">examples repository</a>. They should be considered to be at "proof-of-concept" level currently.</p> </div> <div class="paragraph"> <p>That being said, we&#8217;re considering to make this a Debezium component proper, allowing you to employ this aggregation approach within your Hibernate-based applications just by pulling in this new component. For that we&#8217;d have to improve a few things first, though. Most importantly, an API is needed which will let you (re-)create aggregates on demand, e.g. for existing data or for data updated by bulk updates via the Criteria API / JPQL (which will be missed by listeners). Also aggregates should be re-created automatically, if any of the referenced entities change (with the current PoC, only a change to the customer instance itself will trigger its aggregate view to be rebuilt, but not a change to one of its addresses).</p> </div> <div class="paragraph"> <p>If you like this idea, then let us know about it, so we can gauge the general interest in this. Also, this would be a great item to work on, if you&#8217;re interested in contributing to the Debezium project. Looking forward to hearing from you, e.g. in the comment section below or on our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a>.</p> </div> <div class="paragraph"> <p>Thanks a lot to Hans-Peter Grahsl for his feedback on an earlier version of this post!</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <ul class="pager"> <li class="previous"> <a href="/blog/page/2/">&laquo; Older</a> </li> <li class="pages">Page 1 of 11</li> <li class="disabled next"> <a href="#">Newer &raquo;</a> </li> </ul> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2019 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/docs/features/" title="Features">Features</a> </li> <li> <a href="/docs/install/" title="Install">Install</a> </li> <li> <a href="/docs/manage/" title="Manage">Manage</a> </li> <li> <a href="/docs/architecture/" title="Architecture">Architecture</a> </li> <li> <a href="/docs/faq/" title="FAQ">FAQ</a> </li> <li> <a href="/docs/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/dev" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="https://www.redhat.com/"><img src="https://static.jboss.org/theme/images/common/redhat_logo.png"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="https://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.2/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
        var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
        var urlSplit = coreUrl.toLowerCase().split(/\//);
        var urlLast = urlSplit[urlSplit.length-1];
        var pageNameString = "";
        var siteName = "";
        var minorSectionIndex = 3
        if (urlLast == "") {
            urlSplit.splice(-1,1);
        }
        if (urlLast.search(/\./) >= 0) {
            if (urlLast == "index.html") {
                urlSplit.splice(-1,1);
            }
            else {
                urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
            }
        }
        siteName = urlSplit[2].split(".")[1];
        s.prop14 = s.eVar27 = siteName || "";
        s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
        s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
        pageNameString = urlSplit.splice(3).join(" | ");
        s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
        s.server = "jboss";
        s.channel = "jboss | community";
        s.prop4 = s.eVar23 = encodeURI(document.URL);
        s.prop21 = s.eVar18 = coreUrl;
        s.prop2 = s.eVar22 = "en";
        s.prop3 = s.eVar19 = "us";
        //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
        if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
        //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
      document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script> <script type="text/javascript">
      try {
      var pageTracker = _gat._getTracker("UA-10656779-1");
      pageTracker._trackPageview();
      } catch(err) {}</script> <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       
      ga('create', 'UA-76464546-1', 'auto');
      ga('send', 'pageview');
      ga('set', 'anonymizeIp', true);
      ga('require', 'linkid', 'linkid.js');
      
      </script> </div> </body> </html>