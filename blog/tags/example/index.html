<!DOCTYPE html> <html lang="en"> <head> <title>Debezium Blog</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="https://static.jboss.org/theme/css/bootstrap-community/3.2.0.2/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="https://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="https://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="https://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="https://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="https://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="https://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
      @media (min-width: 980px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
      }
      @media (max-width: 979px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
      }
      @media (max-width: 650px) {
        .banner { width: 100%; margin: 0px auto; }
      }
      @media (max-width: 450px) {
        .banner { height: 90px; }
      }
    </style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
      hljs.initHighlightingOnLoad();
    </script> <script src="https://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
      /* adjusting the vertical spacing for when a stickynav is engaged */
      .breadcrumb-fixed > .active {
        color: #8c8f91;
      }
      .breadcrumb-fixed {
        margin: 70px 0 10px;
        padding: 8px 15px;
        margin-bottom: 20px;
        list-style: none;
        background-color: #f5f5f5;
        border-radius: 4px;
      }
      
      .breadcrumb-fixed > li {
        display: inline-block;
      }
    </style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="https://www.jboss.org/projects/about"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> Debezium </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/docs/faq/">FAQ</a></li> <li class=""><a href="/docs/">DOCS</a></li> <li class=""><a href="/community/">COMMUNITY</a></li> <li class="active"><a href="/blog/">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav"> <div class="panel-docnav"> <div class="panel-heading"> <h3 class="panel-title"> Latest posts </h3> </div> <div class="panel-body"> <ul class="list-group"> <li class="list-group-item"> <a href="/blog/2018/11/22/debezium-0-9-0-beta1-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.0.Beta1 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/10/04/debezium-0-9-0-alpha2-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.0.Alpha2 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/" rel="tooltip" title="Click to go to post">Materializing Aggregate Views With Hibernate and Debezium</a> </li> <li class="list-group-item"> <a href="/blog/2018/09/19/debezium-0-8-3-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.8.3.Final Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/08/30/streaming-mysql-data-changes-into-kinesis/" rel="tooltip" title="Click to go to post">Streaming MySQL Data Changes to Amazon Kinesis</a> </li> <li class="list-group-item"> <a href="/blog/2018/08/30/debezium-0-8-2-released/" rel="tooltip" title="Click to go to post">Debezium 0.8.2 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/07/26/debezium-0-9-0-alpha1-released/" rel="tooltip" title="Click to go to post">Debezium 0.9 Alpha1 and 0.8.1 Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/07/19/advantages-of-log-based-change-data-capture/" rel="tooltip" title="Click to go to post">Five Advantages of Log-Based Change Data Capture</a> </li> </ul> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="text-right"> <h3> Subscribe <a class="rss" href="/blog.atom"> <i class="icon-rss"></i> </a> </h3> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/05/24/querying-debezium-change-data-eEvents-with-ksql/">Querying Debezium Change Data Events With KSQL</a> </h1> <div class="byline"> <p> <em> May 24, 2018 by Jiri Pechanec </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/ksql/">ksql</a> <a class="label label-info" href="/blog/tags/example/">example</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p><em>Last updated at Nov 21st 2018 (adjusted to new KSQL Docker images)</em>.</p> </div> <div class="paragraph"> <p>Last year we have seen the inception of a new open-source project in the <a href="https://kafka.apache.org/">Apache Kafka</a> universe, <a href="https://github.com/confluentinc/ksql">KSQL</a>, which is a streaming SQL engine build on top of <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a>. In this post, we are going to try out KSQL querying with data change events generated by Debezium from a MySQL database.</p> </div> <div class="paragraph"> <p>As a source of data we will use the database and setup from our <a href="/docs/tutorial/">tutorial</a>. The result of this exercise should be similar to the recent <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/">post</a> about aggregation of events into <a href="https://martinfowler.com/bliki/DDD_Aggregate.html">domain driven aggregates</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="entity_diagram"><a class="anchor" href="#entity_diagram"></a>Entity diagram</h2> <div class="sectionbody"> <div class="paragraph"> <p>First let&#8217;s look at the entities in the database and the relations between them.</p> </div> <div class="imageblock centered-image"> <div class="content"> <img src="/images/tutorial-erd.svg" alt="Entity diagram"> </div> <div class="title">Figure 1: Entity diagram of the example entities</div> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div class="paragraph"> <p>The picture above shows the full ER diagram for the inventory database in the example MySQL instance. We are going to focus on two entities:</p> </div> <div class="ulist"> <ul> <li> <p><code>customers</code> - the list of customers in the system</p> </li> <li> <p><code>orders</code> - the list of orders in the system</p> </li> </ul> </div> <div class="paragraph"> <p>There is a <code>1:n</code> relation between <code>customers</code> and <code>orders</code>, modelled by the <code>purchaser</code> column in the <code>orders</code> table, which is a foreign key to the <code>customers</code> table.</p> </div> </div> </div> <div class="sect1"> <h2 id="configuration"><a class="anchor" href="#configuration"></a>Configuration</h2> <div class="sectionbody"> <div class="paragraph"> <p>We are going to use a <a href="https://github.com/debezium/debezium-examples/blob/master/ksql/docker-compose.yaml">Docker Compose file</a> for the deployment of the environment. The deployment consists of the following Docker images:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://hub.docker.com/r/debezium/zookeeper/">Apache ZooKeeper</a></p> </li> <li> <p><a href="https://hub.docker.com/r/debezium/kafka/">Apache Kafka</a></p> </li> <li> <p>Kafka Connect including the Debezium connectors <a href="https://hub.docker.com/r/debezium/connect/">image</a></p> </li> <li> <p>A pre-populated MySQL database as used in our <a href="/docs/tutorial/">tutorial</a></p> </li> <li> <p>The <a href="https://hub.docker.com/r/confluentinc/cp-ksql-server/">KSQL server</a> and <a href="https://hub.docker.com/r/confluentinc/cp-ksql-cli/">CLI client</a></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="example"><a class="anchor" href="#example"></a>Example</h2> <div class="sectionbody"> <div class="paragraph"> <p>First we need to start the Debezium and Kafka infrastructure. To do so, clone the <a href="https://github.com/debezium/debezium-examples/">debezium-examples</a> GitHub repository and start the required components using the provided Compose file:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">export DEBEZIUM_VERSION=0.8&#x000A;git clone https://github.com/debezium/debezium-examples.git&#x000A;cd debezium-examples/ksql/&#x000A;docker-compose up</code></pre> </div> </div> <div class="paragraph"> <p>Next we must register an instance of the Debezium MySQL connector to listen to changes in the database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @- &lt;&lt;-EOF&#x000A;{&#x000A;    "name": "inventory-connector",&#x000A;    "config": {&#x000A;        "connector.class": "io.debezium.connector.mysql.MySqlConnector",&#x000A;        "tasks.max": "1",&#x000A;        "database.hostname": "mysql",&#x000A;        "database.port": "3306",&#x000A;        "database.user": "debezium",&#x000A;        "database.password": "dbz",&#x000A;        "database.server.id": "184055",&#x000A;        "database.server.name": "dbserver",&#x000A;        "database.whitelist": "inventory",&#x000A;        "database.history.kafka.bootstrap.servers": "kafka:9092",&#x000A;        "database.history.kafka.topic": "schema-changes.inventory",&#x000A;        "transforms": "unwrap",&#x000A;        "transforms.unwrap.type": "io.debezium.transforms.UnwrapFromEnvelope",&#x000A;        "key.converter": "org.apache.kafka.connect.json.JsonConverter",&#x000A;        "key.converter.schemas.enable": "false",&#x000A;        "value.converter": "org.apache.kafka.connect.json.JsonConverter",&#x000A;        "value.converter.schemas.enable": "false"&#x000A;    }&#x000A;}&#x000A;EOF</code></pre> </div> </div> <div class="paragraph"> <p>Now we should have all components up and running and initial data change events are already streamed into Kafka topics. There are multiple properties that are especially important for our use case:</p> </div> <div class="ulist"> <ul> <li> <p>The <a href="http://debezium.io/docs/configuration/event-flattening/">UnwrapFromEnvelope SMT</a> is used. This allows us to directly map fields from the <code>after</code> part of change records into KSQL statements. Without it, we would need to use <code>EXTRACTJSONFIELD</code> for each field to be extracted from the <code>after</code> part of messages.</p> </li> <li> <p>Schemas are disabled for the JSON converter. The reason is the same as above. With schemas enabled, for JSON the record is encapsulated in a JSON structure that contains the fields <code>schema</code> (with schema information) and <code>payload</code> (with the actual data itself). We would again need to use <code>EXTRACTJSONFIELD</code> to get to the relevant fields. There is no such issue with Avro converter so this option does not need to be set when Avro is used.</p> </li> </ul> </div> <div class="paragraph"> <p>Next we are going to start the KSQL command shell. We will run a local engine in the CLI. Also please note <code>--net</code> parameter. This guarantees that KSQL container runs in the same network as Debezium containers and allows proper DNS resolution.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec ksql-cli ksql http://ksql-server:8088</code></pre> </div> </div> <div class="paragraph"> <p>First we will list all Kafka topics that exist in the broker:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A; connect-status                      | false      | 5          | 1&#x000A; dbserver                            | false      | 1          | 1&#x000A; dbserver.inventory.addresses        | false      | 1          | 1&#x000A; dbserver.inventory.customers        | false      | 1          | 1&#x000A; dbserver.inventory.orders           | false      | 1          | 1&#x000A; dbserver.inventory.products         | false      | 1          | 1&#x000A; dbserver.inventory.products_on_hand | false      | 1          | 1&#x000A; ksql__commands                      | true       | 1          | 1&#x000A; my_connect_configs                  | false      | 1          | 1&#x000A; my_connect_offsets                  | false      | 25         | 1&#x000A; schema-changes.inventory            | false      | 1          | 1</code></pre> </div> </div> <div class="paragraph"> <p>The topics we are interested in are <code>dbserver.inventory.orders</code> and <code>dbserver.inventory.customers</code>.</p> </div> <div class="paragraph"> <p>KSQL processing by default starts with <code>latest</code> offsets. We want to process the events already in the topics so we switch processing from <code>earliest</code> offsets.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SET 'auto.offset.reset' = 'earliest';&#x000A;Successfully changed local property 'auto.offset.reset' from 'null' to 'earliest'</code></pre> </div> </div> <div class="paragraph"> <p>First we need to create streams from the topics containing the Debezium data change events. A <em>stream</em> in KSQL and Kafka Streams terminology is an unbounded incoming data set with no state.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM orders_from_debezium (order_number integer, order_date string, purchaser integer, quantity integer, product_id integer) WITH (KAFKA_TOPIC='dbserver.inventory.orders',VALUE_FORMAT='json');&#x000A;&#x000A; Message&#x000A;----------------&#x000A; Stream created&#x000A;ksql&gt;&#x000A;ksql&gt; CREATE STREAM customers_from_debezium (id integer, first_name string, last_name string, email string) WITH (KAFKA_TOPIC='dbserver.inventory.customers',VALUE_FORMAT='json');&#x000A;&#x000A; Message&#x000A;----------------&#x000A; Stream created</code></pre> </div> </div> <div class="sect2"> <h3 id="partitioning"><a class="anchor" href="#partitioning"></a>Partitioning</h3> <div class="paragraph"> <p>Our deployment uses only one partition per topic. In a production system there will likely be multiple partitions per topic and we need to ensure that all events belonging to our aggregated object end up in the same partition. The natural partioning in our case is per customer id. We are going to repartition the <code>orders_from_debezium</code> stream according to the <code>purchaser</code> field that contains the customer id. The repartitioned data are written into a new topic <code>ORDERS_REPART</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM orders WITH (KAFKA_TOPIC='ORDERS_REPART',VALUE_FORMAT='json',PARTITIONS=1) as SELECT * FROM orders_from_debezium PARTITION BY PURCHASER;&#x000A;&#x000A; Message&#x000A;----------------------------&#x000A; Stream created and running&#x000A;ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A;...&#x000A; ORDERS_REPART                       | true       | 1          | 1&#x000A;...</code></pre> </div> </div> <div class="paragraph"> <p>We are going to execute the same operation for customers too. It is necessary for two reasons:</p> </div> <div class="ulist"> <ul> <li> <p>The current key is a struct that contains a field named <code>id</code> with the customer id. This is different from the repartitioned order topic which contains only the <code>id</code> value as the key, so the partitions would not match.</p> </li> <li> <p>When we will create a JOIN later, there is a limitation that requires the key to have the same value as a key field in the table. The table field contains a plain value but the key contains a struct so they would not match. See <a href="https://github.com/confluentinc/ksql/issues/749">this KSQL issue</a> for more details.</p> </li> </ul> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM customers_stream WITH (KAFKA_TOPIC='CUSTOMERS_REPART',VALUE_FORMAT='json',PARTITIONS=1) as SELECT * FROM customers_from_debezium PARTITION BY ID;&#x000A;&#x000A; Message&#x000A;----------------------------&#x000A; Stream created and running&#x000A;ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A;...&#x000A; CUSTOMERS_REPART                    | true       | 1          | 1&#x000A;...</code></pre> </div> </div> <div class="paragraph"> <p>To verify that records have a new key and are thus repartioned we can issue few statements to compare the results:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SELECT * FROM orders_from_debezium LIMIT 1;&#x000A;1524034842810 | {"order_number":10001} | 10001 | 16816 | 1001 | 1 | 102&#x000A;LIMIT reached for the partition.&#x000A;Query terminated&#x000A;ksql&gt; SELECT * FROM orders LIMIT 1;&#x000A;1524034842810 | 1001 | 10001 | 16816 | 1001 | 1 | 102&#x000A;LIMIT reached for the partition.&#x000A;Query terminated</code></pre> </div> </div> <div class="paragraph"> <p>The second column contains <code>ROWKEY</code> which is the key of the message.</p> </div> <div class="sect3"> <h4 id="customer_order_join"><a class="anchor" href="#customer_order_join"></a>Customer/order join</h4> <div class="paragraph"> <p>So far we were only declaring streams as an unbounded stateless data set. In our use case the <code>order</code> is really an event that comes and goes. But <code>customer</code> is an entity that can be updated and generally is a part of a state fo the system. Such quality is represented in KSQL or Kafka Streams as table. We are going to create a table of customers from the topic containing repartitioned customers.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE TABLE customers (id integer, first_name string, last_name string, email string) WITH (KAFKA_TOPIC='CUSTOMERS_REPART',VALUE_FORMAT='json',KEY='id');&#x000A;&#x000A; Message&#x000A;---------------&#x000A; Table created</code></pre> </div> </div> <div class="paragraph"> <p>Now we have everything in place to make a join between customer and its orders and create a query that will monitor incoming orders and list them with associated customer fields.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SELECT order_number,quantity,customers.first_name,customers.last_name FROM orders left join customers on orders.purchaser=customers.id;&#x000A;10001 | 1 | Sally | Thomas&#x000A;10002 | 2 | George | Bailey&#x000A;10003 | 2 | George | Bailey&#x000A;10004 | 1 | Edward | Walker</code></pre> </div> </div> <div class="paragraph"> <p>Let&#8217;s apply a few changes to the database, which will result in corresponding CDC events being emitted by Debezium:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'&#x000A;&#x000A;mysql&gt; INSERT INTO orders VALUES(default,NOW(), 1003,5,101);&#x000A;Query OK, 1 row affected, 1 warning (0.02 sec)&#x000A;&#x000A;mysql&gt; UPDATE customers SET first_name='Annie' WHERE id=1004;&#x000A;Query OK, 1 row affected (0.02 sec)&#x000A;Rows matched: 1  Changed: 1  Warnings: 0&#x000A;&#x000A;mysql&gt; UPDATE orders SET quantity=20 WHERE order_number=10004;&#x000A;Query OK, 1 row affected (0.02 sec)&#x000A;Rows matched: 1  Changed: 1  Warnings: 0</code></pre> </div> </div> <div class="paragraph"> <p>You may notice that only changes in the <code>orders</code> table have triggered changes in the joined stream. This is a product of the stream/table join. We would need a stream/stream join to trigger changes if any of input streams is modified.</p> </div> <div class="paragraph"> <p>So the final result of the select after the database is modified is</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">10001 | 1 | Sally | Thomas&#x000A;10002 | 2 | George | Bailey&#x000A;10003 | 2 | George | Bailey&#x000A;10004 | 1 | Edward | Walker&#x000A;10005 | 5 | Edward | Walker&#x000A;10004 | 20 | Edward | Walker</code></pre> </div> </div> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>We have successfully started a KSQL instance. We have mapped KSQL streams to Debezium topics filled by Debezium and made a join between them. We have also discussed the problem of repartioning in streaming applications.</p> </div> <div class="paragraph"> <p>If you&#8217;d like to try out this example with Avro encoding and schema registry then you can use our <a href="https://github.com/debezium/debezium-examples/blob/master/tutorial/docker-compose-mysql-avro.yaml">Avro example</a>. Also for further details and more advanced usages just refer to the KSQL <a href="https://github.com/confluentinc/ksql/blob/master/docs/syntax-reference.md">syntax reference</a>.</p> </div> <div class="paragraph"> <p>In case you need help, have feature requests or would like to share your experiences with this example, please let us know in the comments below.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/">Streaming Data Changes from Your Database to Elasticsearch</a> </h1> <div class="byline"> <p> <em> January 17, 2018 by Jiri Pechanec </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/elasticsearch/">elasticsearch</a> <a class="label label-info" href="/blog/tags/smt/">smt</a> <a class="label label-info" href="/blog/tags/example/">example</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>We wish all the best to the Debezium community for 2018!</p> </div> <div class="paragraph"> <p>While we&#8217;re working on the 0.7.2 release, we thought we&#8217;d publish another post describing an end-to-end data streaming use case based on Debezium. We have seen how to set up a change data stream to a downstream database <a href="/blog/2017/09/25/streaming-to-another-database/">a few weeks ago</a>. In this blog post we will follow the same approach to stream the data to an <a href="https://www.elastic.co/">Elasticsearch</a> server to leverage its excellent capabilities for full-text search on our data. But to make the matter a little bit more interesting, we will stream the data to both, a PostgreSQL database and Elasticsearch, so we will optimize access to the data via the SQL query language as well as via full-text search.</p> </div> </div> </div> <div class="sect1"> <h2 id="topology"><a class="anchor" href="#topology"></a>Topology</h2> <div class="sectionbody"> <div class="paragraph"> <p>Here&#8217;s a diagram that shows how the data is flowing through our distributed system. First, the Debezium MySQL connector is continuously capturing the changes from the MySQL database, and sending the changes for each table to separate Kafka topics. Then, the Confluent <a href="https://docs.confluent.io/current/connect/connect-jdbc/docs/sink_connector.html">JDBC sink connector</a> is continuously reading those topics and writing the events into the PostgreSQL database. And, at the same time, the Confluent <a href="https://github.com/confluentinc/kafka-connect-elasticsearch">Elasticsearch connector</a> is continuously reading those same topics and writing the events into Elasticsearch.</p> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div id="img-general" class="imageblock"> <div class="content"> <img src="/images/dbz-to-multiple.svg" alt="Scenario topology"> </div> <div class="title">Figure 1: A general topology</div> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div class="paragraph"> <p>We are going to deploy these components into several different processes. In this example, we&#8217;ll deploy all three connectors to a single Kafka Connect instance that will write to and read from Kafka on behalf of all of the connectors (in production you might need to keep the connectors separated to achieve better performance).</p> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div id="img-general" class="imageblock"> <div class="content"> <img src="/images/dbz-to-multiple-simplified.svg" alt="Scenario topology"> </div> <div class="title">Figure 2: A simplified topology</div> </div> </div> </div> <div class="sect1"> <h2 id="configuration"><a class="anchor" href="#configuration"></a>Configuration</h2> <div class="sectionbody"> <div class="paragraph"> <p>We will use this <a href="https://github.com/debezium/debezium-examples/tree/master/unwrap-smt">Docker Compose file</a> for a fast deployment of the demo. The deployment consists of the following Docker images:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://hub.docker.com/r/debezium/zookeeper/">Apache ZooKeeper</a></p> </li> <li> <p><a href="https://hub.docker.com/r/debezium/kafka/">Apache Kafka</a></p> </li> <li> <p>An <a href="https://github.com/debezium/debezium-examples/tree/master/unwrap-smt/debezium-jdbc">enriched</a> Kafka Connect / Debezium <a href="https://hub.docker.com/r/debezium/connect/">image</a> with a few changes:</p> <div class="ulist"> <ul> <li> <p>PostgreSQL JDBC driver placed into <em>/kafka/libs</em> directory</p> </li> <li> <p>The Confluent JDBC connector placed into <em>/kafka/connect/kafka-connect-jdbc</em> directory</p> </li> </ul> </div> </li> <li> <p>Pre-populated MySQL as used in our <a href="/docs/tutorial/">tutorial</a></p> </li> <li> <p>Empty PostgreSQL</p> </li> <li> <p>Empty Elasticsearch</p> </li> </ul> </div> <div class="paragraph"> <p>The message format is not the same for the Debezium source connector and the JDBC and Elasticsearch connectors as they are developed separately and each focuses on slightly different objectives. Debezium emits a more complex event structure so that it captures all of the information available. In particular, the change events contain the old and the new state of a changed record. Both sink connectors on the other hand expect a simple message that just represents the record state to be written.</p> </div> <div class="paragraph"> <p>Debezium&#8217;s <a href="/docs/configuration/event-flattening/">UnwrapFromEnvelope</a> single message transformation (SMT) collapses the complex change event structure into the same row-based format expected by the two sink connectors and effectively acts as a <a href="http://www.enterpriseintegrationpatterns.com/patterns/messaging/MessageTranslator.html">message translator</a> between the two aforementioned formats.</p> </div> </div> </div> <div class="sect1"> <h2 id="example"><a class="anchor" href="#example"></a>Example</h2> <div class="sectionbody"> <div class="paragraph"> <p>Let&#8217;s move directly to our example as that&#8217;s where the changes are visible. First of all we need to deploy all components:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">export DEBEZIUM_VERSION=0.7&#x000A;docker-compose up</code></pre> </div> </div> <div class="paragraph"> <p>When all components are started we are going to register the Elasticsearch Sink connector writing into the Elasticsearch instance. We want to use the same key (primary id) in the source and both PostgreSQL and Elasticsearch:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" \&#x000A;    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \&#x000A;    -d @es-sink.json</code></pre> </div> </div> <div class="paragraph"> <p>We&#8217;re using this registration request:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;  {&#x000A;    "name": "elastic-sink",&#x000A;    "config": {&#x000A;      "connector.class":&#x000A;          "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",&#x000A;      "tasks.max": "1",&#x000A;      "topics": "customers",&#x000A;      "connection.url": "http://elastic:9200",&#x000A;      "transforms": "unwrap,key",&#x000A;      "transforms.unwrap.type": "io.debezium.transforms.UnwrapFromEnvelope",        (1)&#x000A;      "transforms.key.type": "org.apache.kafka.connect.transforms.ExtractField$Key",(2)&#x000A;      "transforms.key.field": "id",                                                 (2)&#x000A;      "key.ignore": "false",                                                        (3)&#x000A;      "type.name": "customer"                                                       (4)&#x000A;    }&#x000A;  }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>The request configures these options:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>extracting only the new row&#8217;s state from Debezium&#8217;s change data message</p> </li> <li> <p>extracting the <code>id</code> field from the key <code>struct</code>, then the same key is used for the source and both destinations. This is to address the fact that the Elasticsearch connector only supports numeric types and <code>string</code> as keys. If we do not extract the <code>id</code> the messages will be filtered out by the connector because of unknown key type.</p> </li> <li> <p>use key from the event instead of generating a synthetic one</p> </li> <li> <p>type under which the events will be registered in Elasticsearch</p> </li> </ol> </div> <div class="paragraph"> <p>Next we are going to register the JDBC Sink connector writing into PostgreSQL database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" \&#x000A;    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \&#x000A;    -d @jdbc-sink.json</code></pre> </div> </div> <div class="paragraph"> <p>Finally, the source connector must be set up:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" \&#x000A;    -H  "Content-Type:application/json" http://localhost:8083/connectors/ \&#x000A;    -d @source.json</code></pre> </div> </div> <div class="paragraph"> <p>Let&#8217;s check if the databases and the search server are synchronized. All the rows of the <code>customers</code> table should be found in the source database (MySQL) as well as the target database (Postgres) and Elasticsearch:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER  -p$MYSQL_PASSWORD inventory -e "select * from customers"'&#x000A;+------+------------+-----------+-----------------------+&#x000A;| id   | first_name | last_name | email                 |&#x000A;+------+------------+-----------+-----------------------+&#x000A;| 1001 | Sally      | Thomas    | sally.thomas@acme.com |&#x000A;| 1002 | George     | Bailey    | gbailey@foobar.com    |&#x000A;| 1003 | Edward     | Walker    | ed@walker.com         |&#x000A;| 1004 | Anne       | Kretchmar | annek@noanswer.org    |&#x000A;+------+------------+-----------+-----------------------+</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB -c "select * from customers"'&#x000A; last_name |  id  | first_name |         email&#x000A;-----------+------+------------+-----------------------&#x000A; Thomas    | 1001 | Sally      | sally.thomas@acme.com&#x000A; Bailey    | 1002 | George     | gbailey@foobar.com&#x000A; Walker    | 1003 | Edward     | ed@walker.com&#x000A; Kretchmar | 1004 | Anne       | annek@noanswer.org</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl 'http://localhost:9200/customers/_search?pretty'&#x000A;{&#x000A;  "took" : 42,&#x000A;  "timed_out" : false,&#x000A;  "_shards" : {&#x000A;    "total" : 5,&#x000A;    "successful" : 5,&#x000A;    "failed" : 0&#x000A;  },&#x000A;  "hits" : {&#x000A;    "total" : 4,&#x000A;    "max_score" : 1.0,&#x000A;    "hits" : [&#x000A;      {&#x000A;        "_index" : "customers",&#x000A;        "_type" : "customer",&#x000A;        "_id" : "1001",&#x000A;        "_score" : 1.0,&#x000A;        "_source" : {&#x000A;          "id" : 1001,&#x000A;          "first_name" : "Sally",&#x000A;          "last_name" : "Thomas",&#x000A;          "email" : "sally.thomas@acme.com"&#x000A;        }&#x000A;      },&#x000A;      {&#x000A;        "_index" : "customers",&#x000A;        "_type" : "customer",&#x000A;        "_id" : "1004",&#x000A;        "_score" : 1.0,&#x000A;        "_source" : {&#x000A;          "id" : 1004,&#x000A;          "first_name" : "Anne",&#x000A;          "last_name" : "Kretchmar",&#x000A;          "email" : "annek@noanswer.org"&#x000A;        }&#x000A;      },&#x000A;      {&#x000A;        "_index" : "customers",&#x000A;        "_type" : "customer",&#x000A;        "_id" : "1002",&#x000A;        "_score" : 1.0,&#x000A;        "_source" : {&#x000A;          "id" : 1002,&#x000A;          "first_name" : "George",&#x000A;          "last_name" : "Bailey",&#x000A;          "email" : "gbailey@foobar.com"&#x000A;        }&#x000A;      },&#x000A;      {&#x000A;        "_index" : "customers",&#x000A;        "_type" : "customer",&#x000A;        "_id" : "1003",&#x000A;        "_score" : 1.0,&#x000A;        "_source" : {&#x000A;          "id" : 1003,&#x000A;          "first_name" : "Edward",&#x000A;          "last_name" : "Walker",&#x000A;          "email" : "ed@walker.com"&#x000A;        }&#x000A;      }&#x000A;    ]&#x000A;  }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>With the connectors still running, we can add a new row to the MySQL database and then check that it was replicated into both the PostgreSQL database and Elasticsearch:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER  -p$MYSQL_PASSWORD inventory'&#x000A;&#x000A;mysql&gt; insert into customers values(default, 'John', 'Doe', 'john.doe@example.com');&#x000A;Query OK, 1 row affected (0.02 sec)</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec -postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB -c "select * from customers"'&#x000A; last_name |  id  | first_name |         email&#x000A;-----------+------+------------+-----------------------&#x000A;...&#x000A;Doe        | 1005 | John       | john.doe@example.com&#x000A;(5 rows)</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl 'http://localhost:9200/customers/_search?pretty'&#x000A;...&#x000A;{&#x000A;  "_index" : "customers",&#x000A;  "_type" : "customer",&#x000A;  "_id" : "1005",&#x000A;  "_score" : 1.0,&#x000A;  "_source" : {&#x000A;    "id" : 1005,&#x000A;    "first_name" : "John",&#x000A;    "last_name" : "Doe",&#x000A;    "email" : "john.doe@example.com"&#x000A;  }&#x000A;}&#x000A;...</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>We set up a complex streaming data pipeline to synchronize a MySQL database with another database and also with an Elasticsearch instance. We managed to keep the same identifier across all systems which allows us to correlate records across the system as a whole.</p> </div> <div class="paragraph"> <p>Propagating data changes from a primary database in near realtime to a search engine such as Elasticsearch enables many interesting use cases. Besides different applications of fulltext search one could for instance also think about creating dashboards and all kinds of visualizations using <a href="https://www.elastic.co/de/products/kibana">Kibana</a>, to gain further insight into the data.</p> </div> <div class="paragraph"> <p>If you&#8217;d like to try out this set-up yourself, just clone the project from our <a href="https://github.com/debezium/debezium-examples/tree/master/unwrap-smt">examples repo</a>. In case you need help, have feature requests or would like to share your experiences with this pipeline, please let us know in the comments below.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2017/09/25/streaming-to-another-database/">Streaming data to a downstream database</a> </h1> <div class="byline"> <p> <em> September 25, 2017 by Jiri Pechanec </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/smt/">smt</a> <a class="label label-info" href="/blog/tags/example/">example</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>In this blog post we will create a simple streaming data pipeline to continuously capture the changes in a MySQL database and replicate them in near real-time into a PostgreSQL database. We&#8217;ll show how to do this without writing any code, but instead by using and configuring Kafka Connect, the Debezium MySQL source connector, the Confluent JDBC sink connector, and a few single message transforms (SMTs).</p> </div> <div class="paragraph"> <p>This approach of replicating data through Kafka is really useful on its own, but it becomes even more advantageous when we can combine our near real-time streams of data changes with other streams, connectors, and stream processing applications. A recent <a href="https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/">Confluent blog post series</a> shows a similar streaming data pipeline but using different connectors and SMTs. What&#8217;s great about Kafka Connect is that you can mix and match connectors to move data between multiple systems.</p> </div> <div class="paragraph"> <p>We will also demonstrate a new functionality that was released with <a href="2017/09/21/debezium-0-6-0-released/">Debezium 0.6.0</a>: a single message transform for <a href="/docs/configuration/event-flattening/">CDC Event Flattening</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="topology"><a class="anchor" href="#topology"></a>Topology</h2> <div class="sectionbody"> <div class="paragraph"> <p>The general topology for this scenario is displayed on the following picture:</p> </div> <div id="img-general" class="imageblock"> <div class="content"> <img src="/images/dbz-to-jdbc.svg" alt="Scenario topology"> </div> <div class="title">Figure 1: A General topology</div> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div class="paragraph"> <p>To simplify the setup a little bit, we will use only one Kafka Connect instance that will contain all connectors. I.e. this instance will serve as an event producer and an event consumer:</p> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div id="img-general" class="imageblock"> <div class="content"> <img src="/images/dbz-to-jdbc-simplified.svg" alt="Scenario topology"> </div> <div class="title">Figure 2: A Simplified topology</div> </div> </div> </div> <div class="sect1"> <h2 id="configuration"><a class="anchor" href="#configuration"></a>Configuration</h2> <div class="sectionbody"> <div class="paragraph"> <p>We will use this <a href="https://github.com/debezium/debezium-examples/tree/master/unwrap-smt">compose</a> for a fast deployment of the demo. The deployment consists of following Docker images:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://hub.docker.com/r/debezium/zookeeper/">Apache ZooKeeper</a></p> </li> <li> <p><a href="https://hub.docker.com/r/debezium/kafka/">Apache Kafka</a></p> </li> <li> <p>An <a href="https://github.com/debezium/debezium-examples/tree/master/unwrap-smt/debezium-jdbc">enriched</a> Kafka Connect / Debezium <a href="https://hub.docker.com/r/debezium/connect/">image</a> with changes</p> <div class="ulist"> <ul> <li> <p>PostgreSQL JDBC driver placed into <code>/kafka/libs</code> directory</p> </li> <li> <p><a href="https://docs.confluent.io/current/connect/connect-jdbc/docs/index.html">Kafka Connect JDBC Connector</a> (developed by <a href="https://www.confluent.io/">Confluent</a>) placed into <code>/kafka/connect/kafka-connect-jdbc</code> directory</p> </li> </ul> </div> </li> <li> <p>Pre-populated MySQL used in our <a href="docs/tutorial">tutorial</a></p> </li> <li> <p>Empty PostgreSQL</p> </li> </ul> </div> <div class="paragraph"> <p>The Debezium MySQL Connector was designed to specifically capture database changes and provide as much information as possible about those events beyond just the new state of each row. Meanwhile, the Confluent JDBC Sink Connector was designed to simply convert each message into a database insert/upsert based upon the structure of the message. So, the two connectors have different structures for the messages, but they also use different topic naming conventions and behavior of representing deleted records.</p> </div> <div class="paragraph"> <p>These mismatches in structure and behavior will be common when using connectors that were not designed to work together. But this is something that we can easily deal with, and we discuss how in the next few sections.</p> </div> <div class="sect2"> <h3 id="event_format"><a class="anchor" href="#event_format"></a>Event format</h3> <div class="paragraph"> <p>Debezium emits events in a complex format that contains all of the information about the captured data change: the type of operation, source metadata, the timestamp the event was processed by the connector, and state of the row before and after the change was made. Debezium calls this structure an <em>"envelope"</em>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;	"op": "u",&#x000A;	"source": {&#x000A;		...&#x000A;	},&#x000A;	"ts_ms" : "...",&#x000A;	"before" : {&#x000A;		"field1" : "oldvalue1",&#x000A;		"field2" : "oldvalue2"&#x000A;	},&#x000A;	"after" : {&#x000A;		"field1" : "newvalue1",&#x000A;		"field2" : "newvalue2"&#x000A;	}&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Many other Kafka Connect source connectors don&#8217;t have the luxury of knowing this much about the changes, and instead use a simpler model where each message directly represents the after state of the row. This is also what many sink connectors expect, and the Confluent JDBC Sink Connector is not different:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;	"field1" : "newvalue1",&#x000A;	"field2" : "newvalue2"&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>While we think it&#8217;s actually a great thing that Debezium CDC connectors provide as much detail as possible, we also make it easy for you to transform Debezium&#8217;s <em>"envelope"</em> format into the <em>"row"</em> format that is expected by many other connectors. Debezium provides a bridge between those two formats in a form of a <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-66%3A+Single+Message+Transforms+for+Kafka+Connect">single message transform</a>. The <code>UnwrapFromEnvelope</code> transformation automatically extracts a new row record and thus effectively <em>flattens</em> the complex record into a simple one consumable by other connectors.</p> </div> <div class="paragraph"> <p>You can use this SMT on the source connector to transform the message <em>before</em> it is written to Kafka, or you can instead store the source connector&#8217;s richer <em>"envelope"</em> form of the message in Kafka and use this SMT on the sink connector to transform the message <em>after</em> it is read from Kafka and before it is passed to the sink connector. Both options work, and it just depends on whether you find the envelope form of the message useful for other purposes.</p> </div> <div class="paragraph"> <p>In our example we apply the SMT at the sink connector using these configuration properties:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>"transforms": "unwrap",&#x000A;"transforms.unwrap.type": "io.debezium.transforms.UnwrapFromEnvelope",</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="delete_records"><a class="anchor" href="#delete_records"></a>Delete records</h3> <div class="paragraph"> <p>When the Debezium connector detects a row is deleted, it creates two event messages: a <em>delete</em> event and a <em>tombstone</em> message. The <em>delete</em> message has an envelope with the state of the deleted row in the <code>before</code> field, and an <code>after</code> field that is <code>null</code>. The <em>tombstone</em> message contains same key as the <em>delete</em> message, but the entire message value is <code>null</code>, and Kafka&#8217;s log compaction utilizes this to know that it can remove any earlier messages with the same key. A number of sink connectors, including the Confluent&#8217;s JDBC Sink Connector, are not expecting these messages and will instead fail if they see either kind of message. The <code>UnwrapFromEnvelope</code> SMT will by default filter out both <em>delete</em> and <em>tombstone</em> records, though you can change this if you&#8217;re using the SMT and want to keep one or both of these kinds of messages.</p> </div> </div> <div class="sect2"> <h3 id="topic_naming"><a class="anchor" href="#topic_naming"></a>Topic naming</h3> <div class="paragraph"> <p>Last but not least there is a difference in naming of topics. Debezium uses fully qualified naming for target topics representing each table it manages. The naming follows the pattern <code>&lt;logical-name&gt;.&lt;database-name&gt;.&lt;table-name&gt;</code>. Kafka Connect JDBC Connector works with simple names <code>&lt;table-name&gt;</code>.</p> </div> <div class="paragraph"> <p>In more complex scenarios the user may deploy the <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a> framework to establish elaborated routing between source and target routes. In our example we will use a stock <code>RegexRouter</code> SMT that would route records created by Debezium into topics named according to JDBC Connector schema. Again, we could use this SMT in either the source or sink connectors, but for this example we&#8217;re going to use it in the source connector so we can choose the names of the Kafka topics where the records will be written.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>"transforms": "route",&#x000A;"transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",&#x000A;"transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)",&#x000A;"transforms.route.replacement": "$3"</code></pre> </div> </div> </div> </div> </div> <div class="sect1"> <h2 id="example"><a class="anchor" href="#example"></a>Example</h2> <div class="sectionbody"> <div class="paragraph"> <p>Kick the tires and let&#8217;s try our example!</p> </div> <div class="paragraph"> <p>First of all we need to deploy all components.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">export DEBEZIUM_VERSION=0.6&#x000A;docker-compose up</code></pre> </div> </div> <div class="paragraph"> <p>When all components are started we are going to register the JDBC Sink connector writing into PostgreSQL database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @jdbc-sink.json</code></pre> </div> </div> <div class="paragraph"> <p>Using this registration request:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "name": "jdbc-sink",&#x000A;    "config": {&#x000A;        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",&#x000A;        "tasks.max": "1",&#x000A;        "topics": "customers",&#x000A;        "connection.url": "jdbc:postgresql://postgres:5432/inventory?user=postgresuser&amp;password=postgrespw",&#x000A;        "transforms": "unwrap",                                                  (1)&#x000A;        "transforms.unwrap.type": "io.debezium.transforms.UnwrapFromEnvelope",   (1)&#x000A;        "auto.create": "true",                                                   (2)&#x000A;        "insert.mode": "upsert",                                                 (3)&#x000A;        "pk.fields": "id",                                                       (4)&#x000A;        "pk.mode": "record_value"                                                (4)&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>The request configures these options:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>unwrapping Debezium&#8217;s complex format into a simple one</p> </li> <li> <p>automatically create target tables</p> </li> <li> <p>insert a row if it does not exist or update an existing one</p> </li> <li> <p>identify the primary key stored in Kafka&#8217;s record value field</p> </li> </ol> </div> <div class="paragraph"> <p>Then the source connector must be set up:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @source.json</code></pre> </div> </div> <div class="paragraph"> <p>Using this registration request:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "name": "inventory-connector",&#x000A;    "config": {&#x000A;        "connector.class": "io.debezium.connector.mysql.MySqlConnector",&#x000A;        "tasks.max": "1",&#x000A;        "database.hostname": "mysql",&#x000A;        "database.port": "3306",&#x000A;        "database.user": "debezium",&#x000A;        "database.password": "dbz",&#x000A;        "database.server.id": "184054",&#x000A;        "database.server.name": "dbserver1",                                         (1)&#x000A;        "database.whitelist": "inventory",                                           (2)&#x000A;        "database.history.kafka.bootstrap.servers": "kafka:9092",&#x000A;        "database.history.kafka.topic": "schema-changes.inventory",&#x000A;        "transforms": "route",                                                       (3)&#x000A;        "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",  (3)&#x000A;        "transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)",                     (3)&#x000A;        "transforms.route.replacement": "$3"                                         (3)&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>The request configures these options:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>logical name of the database</p> </li> <li> <p>the database we want to monitor</p> </li> <li> <p>an SMT which defines a regular expression matching the topic name <code>&lt;logical-name&gt;.&lt;database-name&gt;.&lt;table-name&gt;</code> and extracts the third part of it as the final topic name</p> </li> </ol> </div> <div class="paragraph"> <p>Let&#8217;s check if the databases are synchronized. All the rows of the <code>customers</code> table should be found in the source database (MySQL) as well as the target database (Postgres):</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER  -p$MYSQL_PASSWORD inventory -e "select * from customers"'&#x000A;+------+------------+-----------+-----------------------+&#x000A;| id   | first_name | last_name | email                 |&#x000A;+------+------------+-----------+-----------------------+&#x000A;| 1001 | Sally      | Thomas    | sally.thomas@acme.com |&#x000A;| 1002 | George     | Bailey    | gbailey@foobar.com    |&#x000A;| 1003 | Edward     | Walker    | ed@walker.com         |&#x000A;| 1004 | Anne       | Kretchmar | annek@noanswer.org    |&#x000A;+------+------------+-----------+-----------------------+&#x000A;&#x000A;docker-compose exec postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB -c "select * from customers"'&#x000A; last_name |  id  | first_name |         email&#x000A;-----------+------+------------+-----------------------&#x000A; Thomas    | 1001 | Sally      | sally.thomas@acme.com&#x000A; Bailey    | 1002 | George     | gbailey@foobar.com&#x000A; Walker    | 1003 | Edward     | ed@walker.com&#x000A; Kretchmar | 1004 | Anne       | annek@noanswer.org</code></pre> </div> </div> <div class="paragraph"> <p>With the connectors still running, we can add a new row to the MySQL database and then check that it was replicated into the PostgreSQL database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER  -p$MYSQL_PASSWORD inventory'&#x000A;mysql&gt; insert into customers values(default, 'John', 'Doe', 'john.doe@example.com');&#x000A;Query OK, 1 row affected (0.02 sec)&#x000A;&#x000A;docker-compose exec -postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB -c "select * from customers"'&#x000A; last_name |  id  | first_name |         email&#x000A;-----------+------+------------+-----------------------&#x000A;...&#x000A;Doe        | 1005 | John       | john.doe@example.com&#x000A;(5 rows)</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>We set up a simple streaming data pipeline to replicate data in near real-time from a MySQL database to a PostgreSQL database. We accomplished this using Kafka Connect, the Debezium MySQL source connector, the Confluent JDBC sink connector, and a few SMTs&#8201;&#8212;&#8201;all without having to write any code. And since it is a streaming system, it will continue to capture all changes made to the MySQL database and replicating them in near real time.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_s_next"><a class="anchor" href="#what_s_next"></a>What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>In a future blog post we will reproduce the same scenario with Elasticsearch as a target for events.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <ul class="pager"> <li class="disabled previous"> <a href="#">&laquo; Older</a> </li> <li class="pages">Page 1 of 1</li> <li class="disabled next"> <a href="#">Newer &raquo;</a> </li> </ul> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2018 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/docs/features/" title="Features">Features</a> </li> <li> <a href="/docs/install/" title="Install">Install</a> </li> <li> <a href="/docs/manage/" title="Manage">Manage</a> </li> <li> <a href="/docs/architecture/" title="Architecture">Architecture</a> </li> <li> <a href="/docs/faq/" title="FAQ">FAQ</a> </li> <li> <a href="/docs/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/dev" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="https://www.redhat.com/"><img src="https://static.jboss.org/theme/images/common/redhat_logo.png"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="https://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.2/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
        var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
        var urlSplit = coreUrl.toLowerCase().split(/\//);
        var urlLast = urlSplit[urlSplit.length-1];
        var pageNameString = "";
        var siteName = "";
        var minorSectionIndex = 3
        if (urlLast == "") {
            urlSplit.splice(-1,1);
        }
        if (urlLast.search(/\./) >= 0) {
            if (urlLast == "index.html") {
                urlSplit.splice(-1,1);
            }
            else {
                urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
            }
        }
        siteName = urlSplit[2].split(".")[1];
        s.prop14 = s.eVar27 = siteName || "";
        s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
        s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
        pageNameString = urlSplit.splice(3).join(" | ");
        s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
        s.server = "jboss";
        s.channel = "jboss | community";
        s.prop4 = s.eVar23 = encodeURI(document.URL);
        s.prop21 = s.eVar18 = coreUrl;
        s.prop2 = s.eVar22 = "en";
        s.prop3 = s.eVar19 = "us";
        //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
        if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
        //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
      document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script> <script type="text/javascript">
      try {
      var pageTracker = _gat._getTracker("UA-10656779-1");
      pageTracker._trackPageview();
      } catch(err) {}</script> <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       
      ga('create', 'UA-76464546-1', 'auto');
      ga('send', 'pageview');
      ga('set', 'anonymizeIp', true);
      ga('require', 'linkid', 'linkid.js');
      
      </script> </div> </body> </html>