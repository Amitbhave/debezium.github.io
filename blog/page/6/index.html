<!DOCTYPE html> <html lang="en"> <head> <title>Debezium Blog</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="https://static.jboss.org/theme/css/bootstrap-community/3.2.0.2/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="https://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="https://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="https://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="https://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="https://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="https://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
      @media (min-width: 980px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
      }
      @media (max-width: 979px) {
        .banner { background-image: url(https://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
      }
      @media (max-width: 650px) {
        .banner { width: 100%; margin: 0px auto; }
      }
      @media (max-width: 450px) {
        .banner { height: 90px; }
      }
    </style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
      hljs.initHighlightingOnLoad();
    </script> <script src="https://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
      /* adjusting the vertical spacing for when a stickynav is engaged */
      .breadcrumb-fixed > .active {
        color: #8c8f91;
      }
      .breadcrumb-fixed {
        margin: 70px 0 10px;
        padding: 8px 15px;
        margin-bottom: 20px;
        list-style: none;
        background-color: #f5f5f5;
        border-radius: 4px;
      }
      
      .breadcrumb-fixed > li {
        display: inline-block;
      }
    </style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="https://www.jboss.org/projects/about"></a> <a class="rhlogo" href="https://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> Debezium </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/docs/faq/">FAQ</a></li> <li class=""><a href="/docs/">DOCS</a></li> <li class=""><a href="/community/">COMMUNITY</a></li> <li class="active"><a href="/blog/">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav"> <div class="panel-docnav"> <div class="panel-heading"> <h3 class="panel-title"> Latest posts </h3> </div> <div class="panel-body"> <ul class="list-group"> <li class="list-group-item"> <a href="/blog/2019/05/29/debezium-0-10-0-alpha1-released/" rel="tooltip" title="Click to go to post">Debezium 0.10.0.Alpha1 "Spring Clean-Up" Edition Released</a> </li> <li class="list-group-item"> <a href="/blog/2019/05/23/tutorial-using-debezium-connectors-with-apache-pulsar/" rel="tooltip" title="Click to go to post">Tutorial for Using Debezium Connectors With Apache Pulsar</a> </li> <li class="list-group-item"> <a href="/blog/2019/05/06/debezium-0-9-5-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.5.Final Released</a> </li> <li class="list-group-item"> <a href="/blog/2019/04/18/hello-debezium/" rel="tooltip" title="Click to go to post">Debezium&#8217;s Team Grows</a> </li> <li class="list-group-item"> <a href="/blog/2019/04/11/debezium-0-9-4-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.4.Final Released</a> </li> <li class="list-group-item"> <a href="/blog/2019/03/26/debezium-0-9-3-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.3.Final Released</a> </li> <li class="list-group-item"> <a href="/blog/2019/03/14/debezium-meets-quarkus/" rel="tooltip" title="Click to go to post">Debezium meets Quarkus</a> </li> <li class="list-group-item"> <a href="/blog/2019/02/25/debezium-0-9-2-final-released/" rel="tooltip" title="Click to go to post">Debezium 0.9.2.Final Released</a> </li> </ul> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="text-right"> <h3> Subscribe <a class="rss" href="/blog.atom"> <i class="icon-rss"></i> </a> </h3> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/06/21/debezium-0-8-0-beta1-released/">Debezium 0.8.0.Beta1 Is Released</a> </h1> <div class="byline"> <p> <em> June 21, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/oracle/">oracle</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>It&#8217;s with great excitement that I&#8217;m announcing the release of Debezium <strong>0.8.0.Beta1</strong>!</p> </div> <div class="paragraph"> <p>This release brings many exciting new features as well as bug fixes, e.g. the first drop of our new Oracle connector, a brand new DDL parser for the MySQL connector, support for MySQL default values and the update to Apache Kafka 1.1.</p> </div> <div class="paragraph"> <p>Due to the big number of changes (the release contains exactly <a href="https://issues.jboss.org/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%200.8.0.Beta1">42 issues</a> overall), we decided to alter our versioning schema a little bit: going forward we may do one or more Beta and CR ("candidate release") releases before doing a final one. This will allow us to get feedback from the community early on, while still completing and polishing specific features. Final (stable) releases will be named like 0.8.0.Final etc.</p> </div> <div class="paragraph"> <p>This release would not have been possible without our outstanding community; a huge "thank you" goes out to the following open source enthusiasts who all contributed to the new version: <a href="https://github.com/echo-xu">Echo Xu</a>, <a href="https://github.com/vuckooo">Ivan Vucina</a>, <a href="https://github.com/glistman">Listman Gamboa</a>, <a href="https://github.com/omarsmak">Omar Al-Safi</a>, <a href="https://github.com/pgoranss">Peter Goransson</a>, <a href="https://github.com/kucharo2">Roman Kuchar</a> (who did a tremendous job with the new DDL parser implementation!), <a href="https://github.com/sagarrao">Sagar Rao</a>, <a href="https://github.com/sauliusvl">Saulius Valatka</a>, <a href="https://github.com/sairam881990">Sairam Polavarapu</a>, <a href="https://github.com/Crim">Stephen Powis</a> and <a href="https://github.com/sweat123">WenZe Hu</a>.</p> </div> <div class="paragraph"> <p>Thank you all very much for your help!</p> </div> <div class="paragraph"> <p>Now let&#8217;s take a closer look at some of the features new in Debezium 0.8.0.Beta1; as always, you can find the complete list of changes of this release in the <a href="/docs/releases/#release-0-8-0-beta-1">change log</a>. Plese take a special look at the breaking changes and the upgrade notes.</p> </div> </div> </div> <div class="sect1"> <h2 id="xstream_based_oracle_connector_tech_preview"><a class="anchor" href="#xstream_based_oracle_connector_tech_preview"></a>XStream-based Oracle Connector (Tech Preview)</h2> <div class="sectionbody"> <div class="paragraph"> <p>Support for a Debezium Oracle connector has been one of the most asked for features for a long time (its original issue number is <a href="https://issues.jboss.org/browse/DBZ-20">DBZ-20</a>!). So we are very happy that we eventually can release a first work-in-progress version of that connector. At this point this code is still very much evolving, so it should be considered as a first tech preview. This means it&#8217;s not feature complete (most notably, there&#8217;s no support for initial snapshots yet), the emitted message format may still change etc. So while we don&#8217;t recommend using it in production quite yet, you should definitely give it a try and report back about your experiences.</p> </div> <div class="paragraph"> <p>One challenge for the Oracle connector is how to get the actual change events out of the database. Unlike with MySQL and Postgres, there&#8217;s unfortunately no free-to-use and easy-to-work-with API which would allow to do the same for Oracle. After some exploration we decided to base this first version of the connector on the <a href="https://docs.oracle.com/database/121/XSTRM/xstrm_intro.htm#XSTRM72647">Oracle XStream</a> API. While this (kinda) checks the box for "easy-to-work-with", it doesn&#8217;t do so for "free-to-use": using this API requires you to have a license for Oracle&#8217;s separate GoldenGate product. We&#8217;re fully aware of this being not ideal, but we decided to still go this route as a first step, allowing us to get some experiences with Oracle and also get a connector into the hands of those with the required license handy. Going forward, we are going to explore alternative approaches. We already have some ideas and discussions around this, so please stay tuned (the issue to track is <a href="https://issues.jboss.org/browse/DBZ-137">DBZ-137</a>).</p> </div> <div class="paragraph"> <p>The Oracle connector is going to evolve within the next 0.8.x releases. To learn more about it, please check its <a href="/docs/connectors/oracle/">connector documentation page</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="antlr_based_mysql_ddl_parser"><a class="anchor" href="#antlr_based_mysql_ddl_parser"></a>Antlr-based MySQL DDL Parser</h2> <div class="sectionbody"> <div class="paragraph"> <p>In order to build up an internal meta-model of the captured database&#8217;s structure, the Debezium MySQL connector needs to parse all issued DDL statements (<code>CREATE TABLE</code> etc.). This used to be done with a hand-written DDL parser which worked reasonably well, but over time it also revealed some shortcomings; as the DDL language is quite extensive, we saw repeatedly bug reports caused by some specific DDL constructs not being parseable.</p> </div> <div class="paragraph"> <p>So we decided to go back to the drawing board and came up with a brand new parser design. Thanks to the great work of Roman Kuchar, we now have a completely new DDL parser which is based on the proven and very mature <a href="http://antlr.org/">Antlr</a> parser generator (luckily, the Antlr project provides a complete MySQL grammar). So we should see much less issue reports related to DDL parsing going forward.</p> </div> <div class="paragraph"> <p>For the time being, the old parser still is in place and remains to be the default parser for Debezium 0.8.x. You are very encouraged though to test the new implementation by setting the connector option <code>ddl.parser.mode</code> to <code>antlr</code> and report back if you run into any issues doing so. We plan to improve and polish the Antlr parser during the 0.8.x release line (specifically we&#8217;re going to measure its performance and optimize as needed) and switch to it by default as of Debezium 0.9. Eventually, the old parser will be removed in a future release after that.</p> </div> </div> </div> <div class="sect1"> <h2 id="further_mysql_connector_changes"><a class="anchor" href="#further_mysql_connector_changes"></a>Further MySQL Connector Changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>The MySQL Connector propagates column default values to corresponding Kafka Connect schemas now (<a href="https://issues.jboss.org/browse/DBZ-191">DBZ-191</a>). That&#8217;s beneficial when using Avro as serialization format and the schema registry with compatibility checking enabled.</p> </div> <div class="paragraph"> <p>By setting the <code>include.query</code> connector option to true, you can add the original query that caused a data change to the corresponding CDC events (<a href="https://issues.jboss.org/browse/DBZ-706">DBZ-706</a>). While disabled by default, this feature can be a useful tool for analyzing and interpreting data changes captured with Debezium.</p> </div> <div class="paragraph"> <p>Some other changes in the MySQL connector include configurability of the heartbeat topic name (<a href="https://issues.jboss.org/browse/DBZ-668">DBZ-668</a>), fixes around timezone handling for <code>TIMESTAMP</code> (<a href="https://issues.jboss.org/browse/DBZ-578">DBZ-578</a>) and <code>DATETIME</code> columns (<a href="https://issues.jboss.org/browse/DBZ-741">DBZ-741</a>) and correct handling of <code>NUMERIC</code> column without an explicit scale value (<a href="https://issues.jboss.org/browse/DBZ-727">DBZ-727</a>).</p> </div> </div> </div> <div class="sect1"> <h2 id="postgres_connector"><a class="anchor" href="#postgres_connector"></a>Postgres Connector</h2> <div class="sectionbody"> <div class="paragraph"> <p>The Debezium Connector for Postgres has seen quite a number of bugfixes, including the following ones:</p> </div> <div class="ulist"> <ul> <li> <p>wal2json can handle transactions now that are bigger than 1Gb (<a href="https://issues.jboss.org/browse/DBZ-638">DBZ-638</a>)</p> </li> <li> <p>the transaction ID is consistently handled as long now (<a href="https://issues.jboss.org/browse/DBZ-673">DBZ-673</a>)</p> </li> <li> <p>multiple fixes related to temporal column types (<a href="https://issues.jboss.org/browse/DBZ-681">DBZ-681</a>, <a href="https://issues.jboss.org/browse/DBZ-696">DBZ-696</a>)</p> </li> <li> <p>OIDs are handled correctly as unsigned int now (<a href="https://issues.jboss.org/browse/DBZ-697">DBZ-697</a>, <a href="https://issues.jboss.org/browse/DBZ-701">DBZ-701</a>)</p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="mongodb_connector"><a class="anchor" href="#mongodb_connector"></a>MongoDB Connector</h2> <div class="sectionbody"> <div class="paragraph"> <p>Also for the MongoDB Connector a number of small feature implementations and bugfixes has been done:</p> </div> <div class="ulist"> <ul> <li> <p>Tested against MongoDB 3.6 (<a href="https://issues.jboss.org/browse/DBZ-529">DBZ-529</a>)</p> </li> <li> <p>Nested documents can be flattened using a provided SMT now (<a href="https://issues.jboss.org/browse/DBZ-561">DBZ-561</a>), which is useful when sinking changes from MongoDB into a relational database</p> </li> <li> <p>The <a href="/docs/configuration/mongodb-event-flattening/">unwrapping SMT</a> can be used together with Avro now (<a href="https://issues.jboss.org/browse/DBZ-650">DBZ-650</a>)</p> </li> <li> <p>The unwrapping SMT can handle arrays with mixed element types (<a href="https://issues.jboss.org/browse/DBZ-649">DBZ-649</a>)</p> </li> <li> <p>When interrupted during snapshotting before completion, the connector will redo the snapshot after restarting (<a href="https://issues.jboss.org/browse/DBZ-712">DBZ-712</a>)</p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="what_s_next"><a class="anchor" href="#what_s_next"></a>What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>As per the new Beta/CR/Final release scheme, we hope to get some feedback by the community (i.e. you :) on this Beta release. Depending on the number of issues reported, we&#8217;ll either release another Beta or go to CR1 with the next version. The 0.8.0.Final version will be released within a few weeks. Note that the Oracle connector will remain a "tech preview" component also in the final version.</p> </div> <div class="paragraph"> <p>After that, we&#8217;ve planned to do a few 0.8.x releases with bug fixes mostly, while work on Debezium 0.9 will commence in parallel. For that we&#8217;ve planned to work on a connector for SQL Server (see <a href="https://issues.jboss.org/browse/DBZ-40">DBZ-40</a>). We&#8217;d also like to explore means of creating consistent materializations of joins from multiple tables' CDC streams, based on the ids of originating transactions. Also there&#8217;s the idea and a first prototype of exposing Debezium change events as a reactive event stream (<a href="https://issues.jboss.org/browse/DBZ-566">DBZ-566</a>), which might be shipped eventually.</p> </div> <div class="paragraph"> <p>Please take a look at the <a href="/docs/roadmap/">roadmap</a> for some more long term ideas and get in touch with us, if you got thoughts around that.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/05/24/querying-debezium-change-data-eEvents-with-ksql/">Querying Debezium Change Data Events With KSQL</a> </h1> <div class="byline"> <p> <em> May 24, 2018 by Jiri Pechanec </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/ksql/">ksql</a> <a class="label label-info" href="/blog/tags/example/">example</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p><em>Last updated at Nov 21st 2018 (adjusted to new KSQL Docker images)</em>.</p> </div> <div class="paragraph"> <p>Last year we have seen the inception of a new open-source project in the <a href="https://kafka.apache.org/">Apache Kafka</a> universe, <a href="https://github.com/confluentinc/ksql">KSQL</a>, which is a streaming SQL engine build on top of <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a>. In this post, we are going to try out KSQL querying with data change events generated by Debezium from a MySQL database.</p> </div> <div class="paragraph"> <p>As a source of data we will use the database and setup from our <a href="/docs/tutorial/">tutorial</a>. The result of this exercise should be similar to the recent <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/">post</a> about aggregation of events into <a href="https://martinfowler.com/bliki/DDD_Aggregate.html">domain driven aggregates</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="entity_diagram"><a class="anchor" href="#entity_diagram"></a>Entity diagram</h2> <div class="sectionbody"> <div class="paragraph"> <p>First let&#8217;s look at the entities in the database and the relations between them.</p> </div> <div class="imageblock centered-image"> <div class="content"> <img src="/images/tutorial-erd.svg" alt="Entity diagram"> </div> <div class="title">Figure 1: Entity diagram of the example entities</div> </div> <div class="paragraph"> <p>&nbsp;<br></p> </div> <div class="paragraph"> <p>The picture above shows the full ER diagram for the inventory database in the example MySQL instance. We are going to focus on two entities:</p> </div> <div class="ulist"> <ul> <li> <p><code>customers</code> - the list of customers in the system</p> </li> <li> <p><code>orders</code> - the list of orders in the system</p> </li> </ul> </div> <div class="paragraph"> <p>There is a <code>1:n</code> relation between <code>customers</code> and <code>orders</code>, modelled by the <code>purchaser</code> column in the <code>orders</code> table, which is a foreign key to the <code>customers</code> table.</p> </div> </div> </div> <div class="sect1"> <h2 id="configuration"><a class="anchor" href="#configuration"></a>Configuration</h2> <div class="sectionbody"> <div class="paragraph"> <p>We are going to use a <a href="https://github.com/debezium/debezium-examples/blob/master/ksql/docker-compose.yaml">Docker Compose file</a> for the deployment of the environment. The deployment consists of the following Docker images:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://hub.docker.com/r/debezium/zookeeper/">Apache ZooKeeper</a></p> </li> <li> <p><a href="https://hub.docker.com/r/debezium/kafka/">Apache Kafka</a></p> </li> <li> <p>Kafka Connect including the Debezium connectors <a href="https://hub.docker.com/r/debezium/connect/">image</a></p> </li> <li> <p>A pre-populated MySQL database as used in our <a href="/docs/tutorial/">tutorial</a></p> </li> <li> <p>The <a href="https://hub.docker.com/r/confluentinc/cp-ksql-server/">KSQL server</a> and <a href="https://hub.docker.com/r/confluentinc/cp-ksql-cli/">CLI client</a></p> </li> </ul> </div> </div> </div> <div class="sect1"> <h2 id="example"><a class="anchor" href="#example"></a>Example</h2> <div class="sectionbody"> <div class="paragraph"> <p>First we need to start the Debezium and Kafka infrastructure. To do so, clone the <a href="https://github.com/debezium/debezium-examples/">debezium-examples</a> GitHub repository and start the required components using the provided Compose file:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">export DEBEZIUM_VERSION=0.8&#x000A;git clone https://github.com/debezium/debezium-examples.git&#x000A;cd debezium-examples/ksql/&#x000A;docker-compose up</code></pre> </div> </div> <div class="paragraph"> <p>Next we must register an instance of the Debezium MySQL connector to listen to changes in the database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @- &lt;&lt;-EOF&#x000A;{&#x000A;    "name": "inventory-connector",&#x000A;    "config": {&#x000A;        "connector.class": "io.debezium.connector.mysql.MySqlConnector",&#x000A;        "tasks.max": "1",&#x000A;        "database.hostname": "mysql",&#x000A;        "database.port": "3306",&#x000A;        "database.user": "debezium",&#x000A;        "database.password": "dbz",&#x000A;        "database.server.id": "184055",&#x000A;        "database.server.name": "dbserver",&#x000A;        "database.whitelist": "inventory",&#x000A;        "database.history.kafka.bootstrap.servers": "kafka:9092",&#x000A;        "database.history.kafka.topic": "schema-changes.inventory",&#x000A;        "transforms": "unwrap",&#x000A;        "transforms.unwrap.type": "io.debezium.transforms.UnwrapFromEnvelope",&#x000A;        "key.converter": "org.apache.kafka.connect.json.JsonConverter",&#x000A;        "key.converter.schemas.enable": "false",&#x000A;        "value.converter": "org.apache.kafka.connect.json.JsonConverter",&#x000A;        "value.converter.schemas.enable": "false"&#x000A;    }&#x000A;}&#x000A;EOF</code></pre> </div> </div> <div class="paragraph"> <p>Now we should have all components up and running and initial data change events are already streamed into Kafka topics. There are multiple properties that are especially important for our use case:</p> </div> <div class="ulist"> <ul> <li> <p>The <a href="http://debezium.io/docs/configuration/event-flattening/">UnwrapFromEnvelope SMT</a> is used. This allows us to directly map fields from the <code>after</code> part of change records into KSQL statements. Without it, we would need to use <code>EXTRACTJSONFIELD</code> for each field to be extracted from the <code>after</code> part of messages.</p> </li> <li> <p>Schemas are disabled for the JSON converter. The reason is the same as above. With schemas enabled, for JSON the record is encapsulated in a JSON structure that contains the fields <code>schema</code> (with schema information) and <code>payload</code> (with the actual data itself). We would again need to use <code>EXTRACTJSONFIELD</code> to get to the relevant fields. There is no such issue with Avro converter so this option does not need to be set when Avro is used.</p> </li> </ul> </div> <div class="paragraph"> <p>Next we are going to start the KSQL command shell. We will run a local engine in the CLI. Also please note <code>--net</code> parameter. This guarantees that KSQL container runs in the same network as Debezium containers and allows proper DNS resolution.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec ksql-cli ksql http://ksql-server:8088</code></pre> </div> </div> <div class="paragraph"> <p>First we will list all Kafka topics that exist in the broker:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A; connect-status                      | false      | 5          | 1&#x000A; dbserver                            | false      | 1          | 1&#x000A; dbserver.inventory.addresses        | false      | 1          | 1&#x000A; dbserver.inventory.customers        | false      | 1          | 1&#x000A; dbserver.inventory.orders           | false      | 1          | 1&#x000A; dbserver.inventory.products         | false      | 1          | 1&#x000A; dbserver.inventory.products_on_hand | false      | 1          | 1&#x000A; ksql__commands                      | true       | 1          | 1&#x000A; my_connect_configs                  | false      | 1          | 1&#x000A; my_connect_offsets                  | false      | 25         | 1&#x000A; schema-changes.inventory            | false      | 1          | 1</code></pre> </div> </div> <div class="paragraph"> <p>The topics we are interested in are <code>dbserver.inventory.orders</code> and <code>dbserver.inventory.customers</code>.</p> </div> <div class="paragraph"> <p>KSQL processing by default starts with <code>latest</code> offsets. We want to process the events already in the topics so we switch processing from <code>earliest</code> offsets.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SET 'auto.offset.reset' = 'earliest';&#x000A;Successfully changed local property 'auto.offset.reset' from 'null' to 'earliest'</code></pre> </div> </div> <div class="paragraph"> <p>First we need to create streams from the topics containing the Debezium data change events. A <em>stream</em> in KSQL and Kafka Streams terminology is an unbounded incoming data set with no state.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM orders_from_debezium (order_number integer, order_date string, purchaser integer, quantity integer, product_id integer) WITH (KAFKA_TOPIC='dbserver.inventory.orders',VALUE_FORMAT='json');&#x000A;&#x000A; Message&#x000A;----------------&#x000A; Stream created&#x000A;ksql&gt;&#x000A;ksql&gt; CREATE STREAM customers_from_debezium (id integer, first_name string, last_name string, email string) WITH (KAFKA_TOPIC='dbserver.inventory.customers',VALUE_FORMAT='json');&#x000A;&#x000A; Message&#x000A;----------------&#x000A; Stream created</code></pre> </div> </div> <div class="sect2"> <h3 id="partitioning"><a class="anchor" href="#partitioning"></a>Partitioning</h3> <div class="paragraph"> <p>Our deployment uses only one partition per topic. In a production system there will likely be multiple partitions per topic and we need to ensure that all events belonging to our aggregated object end up in the same partition. The natural partioning in our case is per customer id. We are going to repartition the <code>orders_from_debezium</code> stream according to the <code>purchaser</code> field that contains the customer id. The repartitioned data are written into a new topic <code>ORDERS_REPART</code>:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM orders WITH (KAFKA_TOPIC='ORDERS_REPART',VALUE_FORMAT='json',PARTITIONS=1) as SELECT * FROM orders_from_debezium PARTITION BY PURCHASER;&#x000A;&#x000A; Message&#x000A;----------------------------&#x000A; Stream created and running&#x000A;ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A;...&#x000A; ORDERS_REPART                       | true       | 1          | 1&#x000A;...</code></pre> </div> </div> <div class="paragraph"> <p>We are going to execute the same operation for customers too. It is necessary for two reasons:</p> </div> <div class="ulist"> <ul> <li> <p>The current key is a struct that contains a field named <code>id</code> with the customer id. This is different from the repartitioned order topic which contains only the <code>id</code> value as the key, so the partitions would not match.</p> </li> <li> <p>When we will create a JOIN later, there is a limitation that requires the key to have the same value as a key field in the table. The table field contains a plain value but the key contains a struct so they would not match. See <a href="https://github.com/confluentinc/ksql/issues/749">this KSQL issue</a> for more details.</p> </li> </ul> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE STREAM customers_stream WITH (KAFKA_TOPIC='CUSTOMERS_REPART',VALUE_FORMAT='json',PARTITIONS=1) as SELECT * FROM customers_from_debezium PARTITION BY ID;&#x000A;&#x000A; Message&#x000A;----------------------------&#x000A; Stream created and running&#x000A;ksql&gt; LIST TOPICS;&#x000A;&#x000A; Kafka Topic                         | Registered | Partitions | Partition Replicas&#x000A;------------------------------------------------------------------------------------&#x000A;...&#x000A; CUSTOMERS_REPART                    | true       | 1          | 1&#x000A;...</code></pre> </div> </div> <div class="paragraph"> <p>To verify that records have a new key and are thus repartioned we can issue few statements to compare the results:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SELECT * FROM orders_from_debezium LIMIT 1;&#x000A;1524034842810 | {"order_number":10001} | 10001 | 16816 | 1001 | 1 | 102&#x000A;LIMIT reached for the partition.&#x000A;Query terminated&#x000A;ksql&gt; SELECT * FROM orders LIMIT 1;&#x000A;1524034842810 | 1001 | 10001 | 16816 | 1001 | 1 | 102&#x000A;LIMIT reached for the partition.&#x000A;Query terminated</code></pre> </div> </div> <div class="paragraph"> <p>The second column contains <code>ROWKEY</code> which is the key of the message.</p> </div> <div class="sect3"> <h4 id="customer_order_join"><a class="anchor" href="#customer_order_join"></a>Customer/order join</h4> <div class="paragraph"> <p>So far we were only declaring streams as an unbounded stateless data set. In our use case the <code>order</code> is really an event that comes and goes. But <code>customer</code> is an entity that can be updated and generally is a part of a state fo the system. Such quality is represented in KSQL or Kafka Streams as table. We are going to create a table of customers from the topic containing repartitioned customers.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; CREATE TABLE customers (id integer, first_name string, last_name string, email string) WITH (KAFKA_TOPIC='CUSTOMERS_REPART',VALUE_FORMAT='json',KEY='id');&#x000A;&#x000A; Message&#x000A;---------------&#x000A; Table created</code></pre> </div> </div> <div class="paragraph"> <p>Now we have everything in place to make a join between customer and its orders and create a query that will monitor incoming orders and list them with associated customer fields.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">ksql&gt; SELECT order_number,quantity,customers.first_name,customers.last_name FROM orders left join customers on orders.purchaser=customers.id;&#x000A;10001 | 1 | Sally | Thomas&#x000A;10002 | 2 | George | Bailey&#x000A;10003 | 2 | George | Bailey&#x000A;10004 | 1 | Edward | Walker</code></pre> </div> </div> <div class="paragraph"> <p>Let&#8217;s apply a few changes to the database, which will result in corresponding CDC events being emitted by Debezium:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'&#x000A;&#x000A;mysql&gt; INSERT INTO orders VALUES(default,NOW(), 1003,5,101);&#x000A;Query OK, 1 row affected, 1 warning (0.02 sec)&#x000A;&#x000A;mysql&gt; UPDATE customers SET first_name='Annie' WHERE id=1004;&#x000A;Query OK, 1 row affected (0.02 sec)&#x000A;Rows matched: 1  Changed: 1  Warnings: 0&#x000A;&#x000A;mysql&gt; UPDATE orders SET quantity=20 WHERE order_number=10004;&#x000A;Query OK, 1 row affected (0.02 sec)&#x000A;Rows matched: 1  Changed: 1  Warnings: 0</code></pre> </div> </div> <div class="paragraph"> <p>You may notice that only changes in the <code>orders</code> table have triggered changes in the joined stream. This is a product of the stream/table join. We would need a stream/stream join to trigger changes if any of input streams is modified.</p> </div> <div class="paragraph"> <p>So the final result of the select after the database is modified is</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-bash" data-lang="bash">10001 | 1 | Sally | Thomas&#x000A;10002 | 2 | George | Bailey&#x000A;10003 | 2 | George | Bailey&#x000A;10004 | 1 | Edward | Walker&#x000A;10005 | 5 | Edward | Walker&#x000A;10004 | 20 | Edward | Walker</code></pre> </div> </div> </div> </div> </div> </div> <div class="sect1"> <h2 id="summary"><a class="anchor" href="#summary"></a>Summary</h2> <div class="sectionbody"> <div class="paragraph"> <p>We have successfully started a KSQL instance. We have mapped KSQL streams to Debezium topics filled by Debezium and made a join between them. We have also discussed the problem of repartioning in streaming applications.</p> </div> <div class="paragraph"> <p>If you&#8217;d like to try out this example with Avro encoding and schema registry then you can use our <a href="https://github.com/debezium/debezium-examples/blob/master/tutorial/docker-compose-mysql-avro.yaml">Avro example</a>. Also for further details and more advanced usages just refer to the KSQL <a href="https://github.com/confluentinc/ksql/blob/master/docs/syntax-reference.md">syntax reference</a>.</p> </div> <div class="paragraph"> <p>In case you need help, have feature requests or would like to share your experiences with this example, please let us know in the comments below.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/03/20/debezium-0-7-5-released/">Debezium 0.7.5 Is Released</a> </h1> <div class="byline"> <p> <em> March 20, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/postgres/">postgres</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>It&#8217;s my pleasure to announce the release of Debezium <strong>0.7.5</strong>!</p> </div> <div class="paragraph"> <p>This is a bugfix release to the 0.7 release line, which we decided to do while working towards Debezium 0.8. Most notably it fixes an unfortunate bug introduced in 0.7.3 (<a href="https://issues.jboss.org/browse/DBZ-663">DBZ-663</a>), where the internal database history topic of the Debezium MySQL connector could be partly deleted under some specific conditions. Please see the <a href="/2018/03/16/note-on-database-history-topic-configuration/">dedicated blog post</a> on this issue to find out whether this affects you and what you should do to prevent this issue.</p> </div> <div class="paragraph"> <p>Together with this, we released a couple of other fixes and improvements. Thanks to <a href="https://github.com/maver1ck">Maciej Brynski</a>, the performance of the <a href="/docs/configuration/topic-routing/">logical table routing SMT</a> has been improved significantly (<a href="https://issues.jboss.org/browse/DBZ-655">DBZ-655</a>). Another fix contributed by Maciej is for <a href="https://issues.jboss.org/browse/DBZ-646">DBZ-646</a> which lets the MySQL connector handle <code>CREATE TABLE</code> statements for the TokuDB storage engine now.</p> </div> <div class="paragraph"> <p>And we got some more bugfixes by our fantastic community: Long-term community member <a href="https://github.com/pgoranss">Peter Goransson</a> fixed an issue about the snapshot JMX metrics of the MySQL connector, which are now also accessible after the snapshot has been completed (<a href="https://issues.jboss.org/browse/DBZ-640">DBZ-640</a>). <a href="https://github.com/atongen">Andrew Tongen</a> spotted and fixed an issue for the Debezium embedded engine (<a href="https://issues.jboss.org/browse/DBZ-665">DBZ-665</a>) which caused offsets to be committed more often than needed. And <a href="https://github.com/matzew">Matthias Wessendorf</a> upgraded the Debezium dependencies and Docker images to Apache Kafka 1.0.1 (<a href="https://issues.jboss.org/browse/DBZ-647">DBZ-647</a>).</p> </div> <div class="paragraph"> <p>Thank you all for your help!</p> </div> <div class="paragraph"> <p>Please refer to the <a href="/docs/releases/#release-0-7-4">change log</a> for the complete list of changes in Debezium 0.7.5.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_s_next"><a class="anchor" href="#what_s_next"></a>What&#8217;s next?</h2> <div class="sectionbody"> <div class="paragraph"> <p>Please see the <a href="/blog/2018/03/07/debezium-0-7-4-released/">previous release announcement</a> for the next planned features. Due to the unplanned 0.7.5 release, though, the schedule of the next one will likely be extended a little bit.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/03/16/note-on-database-history-topic-configuration/">A Note On Database History Topic Configuration</a> </h1> <div class="byline"> <p> <em> March 16, 2018 by Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>A user of the Debezium connector for MySQL informed us about a potential issue with the configuration of the connector&#8217;s internal database history topic, which may cause the deletion of parts of that topic (<a href="https://issues.jboss.org/browse/DBZ-663">DBZ-663</a>). Please continue reading if you&#8217;re using the Debezium MySQL connector in versions 0.7.3 or 0.7.4.</p> </div> </div> </div> <div class="sect1"> <h2 id="what_is_the_issue_about"><a class="anchor" href="#what_is_the_issue_about"></a>What is the issue about?</h2> <div class="sectionbody"> <div class="paragraph"> <p>In Debezium 0.7.3 we rolled out a feature for creating the database history automatically if it doesn&#8217;t exist yet (<a href="https://issues.jboss.org/browse/DBZ-278">DBZ-278</a>). While this feature sets the retention time for the topic to an "infinite" period, it doesn&#8217;t specify the "retention.bytes" option for the history topic. This may cause parts of the history topic to be deleted in case all of the following conditions are met:</p> </div> <div class="ulist"> <ul> <li> <p>You are using versions 0.7.3 or 0.7.4 of the Debezium connector for MySQL</p> </li> <li> <p>The database history topic has been created by the connector (i.e. you haven&#8217;t created it yourself)</p> </li> <li> <p>The broker level option "log.retention.bytes" is set to another value than -1 (note that the default <strong>is</strong> -1, in which case things work as intended)</p> </li> <li> <p>The database history topic grows beyond the threshold configured via "log.retention.bytes"</p> </li> </ul> </div> <div class="paragraph"> <p>If the history topic is incomplete, the connector will fail to recover the database history after a restart of the connector and will not continue with reading the MySQL binlog.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_prevent_the_issue"><a class="anchor" href="#how_to_prevent_the_issue"></a>How to prevent the issue?</h2> <div class="sectionbody"> <div class="paragraph"> <p>You should either create the database history topic yourself with an infinite retention or alternatively override the "retention.bytes" configuration for the history topic created by the connector:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">&lt;KAFKA_DIR&gt;/bin/kafka-configs.sh \&#x000A;  --zookeeper zookeeper:2181 \&#x000A;  --entity-type topics \&#x000A;  --entity-name &lt;DB_HISTORY_TOPIC&gt; \&#x000A;  --alter \&#x000A;  --add-config retention.bytes=-1</code></pre> </div> </div> <div class="paragraph"> <p>In case parts of the history topic were removed already, you can use the snapshot mode <code>schema_only_recovery</code> for re-creating the history topic in case no schema changes have happened since the last committed offset of the connector. Alternatively, a complete new snapshot should be taken, e.g. by setting up a new connector instance.</p> </div> </div> </div> <div class="sect1"> <h2 id="next_steps"><a class="anchor" href="#next_steps"></a>Next steps</h2> <div class="sectionbody"> <div class="paragraph"> <p>We&#8217;ll release Debezium 0.7.5 with a fix for this issue early next week. Note that previously created database history topics should be re-configured as described above. Please don&#8217;t hesitate to get in touch in the comments below, the chat room or the mailing list in case you have any further questions on this issue.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license/">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve ours existing connectors and add even more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/">Creating DDD aggregates with Debezium and Kafka Streams</a> </h1> <div class="byline"> <p> <em> March 08, 2018 by Hans-Peter Grahsl, Gunnar Morling </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/discussion/">discussion</a> <a class="label label-info" href="/blog/tags/examples/">examples</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>Microservice-based architectures can be considered an industry trend and are thus often found in enterprise applications lately. One possible way to keep data synchronized across multiple services and their backing data stores is to make us of an approach called <a href="https://vladmihalcea.com/a-beginners-guide-to-cdc-change-data-capture/">change data capture</a>, or CDC for short.</p> </div> <div class="paragraph"> <p>Essentially CDC allows to listen to any modifications which are occurring at one end of a data flow (i.e. the data source) and communicate them as change events to other interested parties or storing them into a data sink. Instead of doing this in a point-to-point fashion, it&#8217;s advisable to decouple this flow of events between data sources and data sinks. Such a scenario can be implemented based on <a href="http://debezium.io/">Debezium</a> and <a href="https://kafka.apache.org/">Apache Kafka</a> with relative ease and effectively no coding.</p> </div> <div class="paragraph"> <p>As an example, consider the following microservice-based architecture of an order management system:</p> </div> <div class="imageblock centered-image"> <div class="content"> <img src="/images/msa_streaming.png" alt="Microservice-based architecture of an order management system"> </div> </div> <div class="paragraph"> <p>This system comprises three services, <em>Order</em>, <em>Item</em> and <em>Stock</em>. If the <em>Order</em> service receives an order request, it will need information from the other two, such as item definitions or the stock count for specific items. Instead of making synchronous calls to these services to obtain this information, CDC can be used to set up change event streams for the data managed by the <em>Item</em> and <em>Stock</em> services. The <em>Order</em> service can subscribe to these event streams and keep a local copy of the relevant item and stock data in its own database. This approach helps to decouple the services (e.g. no direct impact by service outages) and can also be beneficial for overall performance, as each service can hold optimized views just of those data items owned by other services which it is interested in.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_to_handle_aggregate_objects"><a class="anchor" href="#how_to_handle_aggregate_objects"></a>How to Handle Aggregate Objects?</h2> <div class="sectionbody"> <div class="paragraph"> <p>There are use cases however, where things are a bit more tricky. It is sometimes useful to share information across services and data stores by means of so-called aggregates, which are a concept/pattern defined by domain-driven design (DDD). In general, a <a href="https://martinfowler.com/bliki/DDD_Aggregate.html">DDD aggregate</a> is used to transfer state which can be comprised of multiple different domain objects that are together treated as a single unit of information.</p> </div> <div class="paragraph"> <p>Concrete examples are:</p> </div> <div class="ulist"> <ul> <li> <p><strong>customers and their addresses</strong> which are represented as a customer record <em>aggregate</em> storing a customer and a list of addresses</p> </li> <li> <p><strong>orders and corresponding line items</strong> which are represented as an order record <em>aggregate</em> storing an order and all its line items</p> </li> </ul> </div> <div class="paragraph"> <p>Chances are that the data of the involved domain objects backing these DDD aggregates are stored in separate relations of an RDBMS. When making use of the CDC capabilities currently found in Debezium, all changes to domain objects will be independently captured and by default eventually reflected in separate Kafka topics, one per RDBMS relation. While this behaviour is tremendously helpful for a lot of use cases it can be pretty limiting to others, like the DDD aggregate scenario described above. Therefore, this blog post explores how DDD aggregates can be built based on Debezium CDC events, using the <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams API</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="capturing_change_events_from_a_data_source"><a class="anchor" href="#capturing_change_events_from_a_data_source"></a>Capturing Change Events from a Data Source</h2> <div class="sectionbody"> <div class="paragraph"> <p>The complete source code for this blog post is provided in the Debezium <a href="https://github.com/debezium/debezium-examples/tree/master/kstreams">examples repository</a> on GitHub. Begin by cloning this repository and changing into the <em>kstreams</em> directory:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">git clone https://github.com/debezium/debezium-examples.git&#x000A;cd kstreams</code></pre> </div> </div> <div class="paragraph"> <p>The project provides a Docker Compose file with services for all the components you may already know from the <a href="/docs/tutorial/">Debezium tutorial</a>:</p> </div> <div class="ulist"> <ul> <li> <p><a href="https://zookeeper.apache.org/">Apache ZooKeeper</a></p> </li> <li> <p><a href="https://kafka.apache.org/">Apache Kafka</a></p> </li> <li> <p>A <a href="https://kafka.apache.org/documentation/#connect">Kafka Connect</a> instance with the Debezium CDC connectors</p> </li> <li> <p><a href="http://www.mysql.com/">MySQL</a> (populated with some test data)</p> </li> </ul> </div> <div class="paragraph"> <p>In addition it declares the following services:</p> </div> <div class="ulist"> <ul> <li> <p><a href="http://www.mongodb.com/">MongoDB</a> which will be used as a data sink</p> </li> <li> <p>Another Kafka Connect instance which will host the MongoDB sink connector</p> </li> <li> <p>A service for running the DDD aggregation process we&#8217;re going to build in the following</p> </li> </ul> </div> <div class="paragraph"> <p>We&#8217;ll get to those three in a bit, for now let&#8217;s prepare the source side of our pipeline:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">export DEBEZIUM_VERSION=0.7&#x000A;docker-compose up mysql zookeeper kafka connect_source</code></pre> </div> </div> <div class="paragraph"> <p>Once all services have been started, register an instance of the Debezium MySQL connector by submitting the following JSON document:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "name": "mysql-source",&#x000A;    "config": {&#x000A;        "connector.class": "io.debezium.connector.mysql.MySqlConnector",&#x000A;        "tasks.max": "1",&#x000A;        "database.hostname": "mysql",&#x000A;        "database.port": "3306",&#x000A;        "database.user": "debezium",&#x000A;        "database.password": "dbz",&#x000A;        "database.server.id": "184054",&#x000A;        "database.server.name": "dbserver1",&#x000A;        "table.whitelist": "inventory.customers,inventory.addresses",&#x000A;        "database.history.kafka.bootstrap.servers": "kafka:9092",&#x000A;        "database.history.kafka.topic": "schema-changes.inventory",&#x000A;        "transforms": "unwrap",&#x000A;        "transforms.unwrap.type":"io.debezium.transforms.UnwrapFromEnvelope",&#x000A;        "transforms.unwrap.drop.tombstones":"false"&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>To do so, run the following curl command:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @mysql-source.json</code></pre> </div> </div> <div class="paragraph"> <p>This sets up the connector for the specified database, using the given credentials. For our purposes we&#8217;re only interested in changes to the <code>customers</code> and <code>addresses</code> tables, hence the <code>table.whitelist</code> property is given to just select these two tables. Another noteworthy thing is the "unwrap" transform that is applied. By default, Debezium&#8217;s CDC events would contain the old and new state of changed rows and some additional metadata on the source of the change. By applying the <a href="/docs/configuration/event-flattening/">UnwrapFromEnvelope</a> SMT (single message transformation), only the new state will be propagated into the corresponding Kafka topics.</p> </div> <div class="paragraph"> <p>We can take a look at them once the connector has been deployed and finished its initial snapshot of the two captured tables:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose exec kafka /kafka/bin/kafka-console-consumer.sh \&#x000A;    --bootstrap-server kafka:9092 \&#x000A;    --from-beginning \&#x000A;    --property print.key=true \&#x000A;    --topic dbserver1.inventory.customers # or dbserver1.inventory.addresses</code></pre> </div> </div> <div class="paragraph"> <p>E.g. you should see the following output</p> </div> <div class="paragraph"> <p>(formatted and omitting the schema information for the sake of readability) for the topic with customer changes:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">{&#x000A;    "schema": { ... },&#x000A;    "payload": {&#x000A;        "id": 1001&#x000A;    }&#x000A;}&#x000A;{&#x000A;    "schema": { ... },&#x000A;    "payload": {&#x000A;        "id": 1001,&#x000A;        "first_name": "Sally",&#x000A;        "last_name": "Thomas",&#x000A;        "email": "sally.thomas@acme.com"&#x000A;    }&#x000A;}&#x000A;...</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="building_ddd_aggregates"><a class="anchor" href="#building_ddd_aggregates"></a>Building DDD Aggregates</h2> <div class="sectionbody"> <div class="paragraph"> <p>The KStreams application is going to process data from the two Kafka topics. These topics receive CDC events based on the customers and addresses relations found in MySQL, each of which has its corresponding Jackson-annotated POJO (Customer and Address), enriched by a field holding the CDC event type (i.e. UPSERT/DELETE).</p> </div> <div class="paragraph"> <p>Since the Kafka topic records are in Debezium JSON format with unwrapped envelopes, a special <strong>SerDe</strong> has been written in order to be able to read/write these records using their POJO or Debezium event representation respectively. While the serializer simply converts the POJOs into JSON using Jackson, the deserializer is a "hybrid" one, being able to deserialize from either Debezium CDC events or jsonified POJOs.</p> </div> <div class="paragraph"> <p>With that in place, the KStreams topology to create and maintain DDD aggregates on-the-fly can be built as follows:</p> </div> <div class="sect2"> <h3 id="customers_topic_parent"><a class="anchor" href="#customers_topic_parent"></a>Customers Topic ("parent")</h3> <div class="paragraph"> <p>All the customer records are simply read from the customer topic into a <strong>KTable</strong> which will automatically maintain the latest state per customer according to the record key (i.e. the customer&#8217;s PK)</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">KTable&lt;DefaultId, Customer&gt; customerTable =&#x000A;        builder.table(parentTopic, Consumed.with(defaultIdSerde,customerSerde));</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="addresses_topic_children"><a class="anchor" href="#addresses_topic_children"></a>Addresses Topic ("children")</h3> <div class="paragraph"> <p>For the address records the processing is a bit more involved and needs several steps. First, all the address records are read into a <strong>KStream</strong>.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">KStream&lt;DefaultId, Address&gt; addressStream = builder.stream(childrenTopic,&#x000A;        Consumed.with(defaultIdSerde, addressSerde));</code></pre> </div> </div> <div class="paragraph"> <p>Second, a 'pseudo' grouping of these address records is done based on their keys (the original primary key in the relation), During this step the relationships towards the corresponding customer records are maintained. This effectively allows to keep track which address record belongs to which customer record, even in the light of address record deletions. To achieve this an additional <em>LatestAddress</em> POJO is introduced which allows to store the latest known PK &lt;&#8594; FK relation in addition to the <em>Address</em> record itself.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">KTable&lt;DefaultId,LatestAddress&gt; tempTable = addressStream&#x000A;        .groupByKey(Serialized.with(defaultIdSerde, addressSerde))&#x000A;        .aggregate(&#x000A;                () -&gt; new LatestAddress(),&#x000A;                (DefaultId addressId, Address address, LatestAddress latest) -&gt; {&#x000A;                    latest.update(&#x000A;                        address, addressId, new DefaultId(address.getCustomer_id()));&#x000A;                    return latest;&#x000A;                },&#x000A;                Materialized.&lt;DefaultId,LatestAddress,KeyValueStore&lt;Bytes, byte[]&gt;&gt;&#x000A;                        as(childrenTopic+"_table_temp")&#x000A;                            .withKeySerde(defaultIdSerde)&#x000A;                                .withValueSerde(latestAddressSerde)&#x000A;        );</code></pre> </div> </div> <div class="paragraph"> <p>Third, the intermediate <strong>KTable</strong> is again converted to a <strong>KStream</strong>. The <em>LatestAddress</em> records are transformed to have the customer id (FK relationship) as their new key in order to group them per customer. During the grouping step, customer specific addresses are updated which can result in an address record being added or deleted. For this purpose, another POJO called <em>Addresses</em> is introduced, which holds a map of address records that gets updated accordingly. The result is a <strong>KTable</strong> holding the most recent <em>Addresses</em> per customer id.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">KTable&lt;DefaultId, Addresses&gt; addressTable = tempTable.toStream()&#x000A;        .map((addressId, latestAddress) -&gt;&#x000A;            new KeyValue&lt;&gt;(latestAddress.getCustomerId(),latestAddress))&#x000A;        .groupByKey(Serialized.with(defaultIdSerde,latestAddressSerde))&#x000A;        .aggregate(&#x000A;                () -&gt; new Addresses(),&#x000A;                (customerId, latestAddress, addresses) -&gt; {&#x000A;                    addresses.update(latestAddress);&#x000A;                    return addresses;&#x000A;                },&#x000A;                Materialized.&lt;DefaultId,Addresses,KeyValueStore&lt;Bytes, byte[]&gt;&gt;&#x000A;                        as(childrenTopic+"_table_aggregate")&#x000A;                            .withKeySerde(defaultIdSerde)&#x000A;                                .withValueSerde(addressesSerde)&#x000A;        );</code></pre> </div> </div> </div> <div class="sect2"> <h3 id="combining_customers_with_addresses"><a class="anchor" href="#combining_customers_with_addresses"></a>Combining Customers With Addresses</h3> <div class="paragraph"> <p>Finally, it&#8217;s easy to bring customers and addresses together by <strong>joining the customers KTable with the addresses KTable</strong> and thereby building the DDD aggregates which are represented by the <em>CustomerAddressAggregate</em> POJO. At the end, the KTable changes are written to a KStream, which in turn gets saved into a kafka topic. This allows to make use of the resulting DDD aggregates in manifold ways.</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-java" data-lang="java">KTable&lt;DefaultId,CustomerAddressAggregate&gt; dddAggregate =&#x000A;          customerTable.join(addressTable, (customer, addresses) -&gt;&#x000A;              customer.get_eventType() == EventType.DELETE ?&#x000A;                      null :&#x000A;                      new CustomerAddressAggregate(customer,addresses.getEntries())&#x000A;          );&#x000A;&#x000A;  dddAggregate.toStream().to("final_ddd_aggregates",&#x000A;                              Produced.with(defaultIdSerde,(Serde)aggregateSerde));</code></pre> </div> </div> <div class="admonitionblock note"> <table> <tr> <td class="icon"> <i class="fa icon-note" title="Note"></i> </td> <td class="content"> <div class="paragraph"> <p>Records in the customers KTable might receive a CDC delete event. If so, this can be detected by checking the event type field of the customer POJO and e.g. return 'null' instead of a DDD aggregate. Such a convention can be helpful whenever consuming parties also need to act to deletions accordingly._</p> </div> </td> </tr> </table> </div> </div> </div> </div> <div class="sect1"> <h2 id="running_the_aggregation_pipeline"><a class="anchor" href="#running_the_aggregation_pipeline"></a>Running the Aggregation Pipeline</h2> <div class="sectionbody"> <div class="paragraph"> <p>Having implemented the aggregation pipeline, it&#8217;s time to give it a test run. To do so, build the <em>poc-ddd-aggregates</em> Maven project which contains the complete implementation:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">mvn clean package -f poc-ddd-aggregates/pom.xml</code></pre> </div> </div> <div class="paragraph"> <p>Then run the <code>aggregator</code> service from the Compose file which takes the JAR built by this project and launches it using the <a href="https://hub.docker.com/r/fabric8/java-jboss-openjdk8-jdk/">java-jboss-openjdk8-jdk</a> base image:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose up -d aggregator</code></pre> </div> </div> <div class="paragraph"> <p>Once the aggregation pipeline is running, we can take a look at the aggregated events using the console consumer:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose exec kafka /kafka/bin/kafka-console-consumer.sh \&#x000A;    --bootstrap-server kafka:9092 \&#x000A;    --from-beginning \&#x000A;    --property print.key=true \&#x000A;    --topic final_ddd_aggregates</code></pre> </div> </div> </div> </div> <div class="sect1"> <h2 id="transferring_ddd_aggregates_to_data_sinks"><a class="anchor" href="#transferring_ddd_aggregates_to_data_sinks"></a>Transferring DDD Aggregates to Data Sinks</h2> <div class="sectionbody"> <div class="paragraph"> <p>We originally set out to build these DDD aggregates in order to transfer data and synchronize changes between a data source (MySQL tables in this case) and a convenient data sink. By definition, DDD aggregates are typically complex data structures and therefore it makes perfect sense to write them to data stores which offer flexible ways and means to query and/or index them. Talking about NoSQL databases, a document store seems the most natural choice with <a href="https://www.mongodb.com/">MongoDB</a> being the leading database for such use cases.</p> </div> <div class="paragraph"> <p>Thanks to <a href="https://kafka.apache.org/documentation/#connect">Kafka Connect</a> and numerous turn-key ready <a href="https://www.confluent.io/product/connectors/">connectors</a> it is almost effortless to get this done. Using a <a href="https://github.com/hpgrahsl/kafka-connect-mongodb">MongoDB sink connector</a> from the open-source community, it is easy to have the DDD aggregates written into MongoDB. All it needs is a proper configuration which can be posted to the <a href="https://docs.confluent.io/current/connect/restapi.html">REST API</a> of Kafka Connect in order to run the connector.</p> </div> <div class="paragraph"> <p>So let&#8217;s start MongoDb and another Kafka Connect instance for hosting the sink connector:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose up -d mongodb connect_sink</code></pre> </div> </div> <div class="paragraph"> <p>In case the DDD aggregates should get written unmodified into MongoDB, a configuration may look as simple as follows:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "name": "mongodb-sink",&#x000A;    "config": {&#x000A;        "connector.class": "at.grahsl.kafka.connect.mongodb.MongoDbSinkConnector",&#x000A;        "tasks.max": "1",&#x000A;        "topics": "final_ddd_aggregates",&#x000A;        "mongodb.connection.uri": "mongodb://mongodb:27017/inventory?w=1&amp;journal=true",&#x000A;        "mongodb.collection": "customers_with_addresses",&#x000A;        "mongodb.document.id.strategy": "at.grahsl.kafka.connect.mongodb.processor.id.strategy.FullKeyStrategy",&#x000A;        "mongodb.delete.on.null.values": true&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>As with the source connector, deploy the connector using curl:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8084/connectors/ -d @mongodb-sink.json</code></pre> </div> </div> <div class="paragraph"> <p>This connector will consume messages from the "final_ddd_aggregates" Kafka topic and write them as <strong>MongoDB documents</strong> into the "customers_with_addresses" collection.</p> </div> <div class="paragraph"> <p>You can take a look by firing up a Mongo shell and querying the collection&#8217;s contents:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose exec mongodb bash -c 'mongo inventory'&#x000A;&#x000A;&gt; db.customers_with_addresses.find().pretty()</code></pre> </div> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-json" data-lang="json">{&#x000A;    "_id": {&#x000A;        "id": "1001"&#x000A;    },&#x000A;    "addresses": [&#x000A;        {&#x000A;            "zip": "76036",&#x000A;            "_eventType": "UPSERT",&#x000A;            "city": "Euless",&#x000A;            "street": "3183 Moore Avenue",&#x000A;            "id": "10",&#x000A;            "state": "Texas",&#x000A;            "customer_id": "1001",&#x000A;            "type": "SHIPPING"&#x000A;        },&#x000A;        {&#x000A;            "zip": "17116",&#x000A;            "_eventType": "UPSERT",&#x000A;            "city": "Harrisburg",&#x000A;            "street": "2389 Hidden Valley Road",&#x000A;            "id": "11",&#x000A;            "state": "Pennsylvania",&#x000A;            "customer_id": "1001",&#x000A;            "type": "BILLING"&#x000A;        }&#x000A;    ],&#x000A;    "customer": {&#x000A;        "_eventType": "UPSERT",&#x000A;        "last_name": "Thomas",&#x000A;        "id": "1001",&#x000A;        "first_name": "Sally",&#x000A;        "email": "sally.thomas@acme.com"&#x000A;    }&#x000A;}</code></pre> </div> </div> <div class="paragraph"> <p>Due to the combination of the data in a single document some parts aren&#8217;t needed or redundant. To get rid of any unwanted data (e.g. _eventType, customer_id of each address sub-document) it would also be possible to adapt the configuration in order to blacklist said fields.</p> </div> <div class="paragraph"> <p>Finally, you update some customer or address data in the MySQL source database:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code class="language-shell" data-lang="shell">docker-compose exec mysql bash -c 'mysql -u $MYSQL_USER -p$MYSQL_PASSWORD inventory'&#x000A;&#x000A;mysql&gt; update customers set first_name= "Sarah" where id = 1001;</code></pre> </div> </div> <div class="paragraph"> <p>Shortly thereafter, you should see that the corresponding aggregate document in MongoDB has been updated accordingly.</p> </div> </div> </div> <div class="sect1"> <h2 id="drawbacks_and_limitations"><a class="anchor" href="#drawbacks_and_limitations"></a>Drawbacks and Limitations</h2> <div class="sectionbody"> <div class="paragraph"> <p>While this first version for creating DDD aggregates from table-based CDC events basically works, it is very important to understand its current limitations:</p> </div> <div class="ulist"> <ul> <li> <p>not generically applicable thus needs custom code for POJOs and intermediate types</p> </li> <li> <p>cannot be scaled across multiple instances as is due to missing but necessary data repartitioning prior to processing</p> </li> <li> <p>limited to building aggregates based on a single JOIN between 1:N relationships</p> </li> <li> <p>resulting DDD aggregates are eventually consistent, meaning that it is possible for them to temporarily exhibit intermediate state before converging</p> </li> </ul> </div> <div class="paragraph"> <p>The first few can be addressed with a reasonable amount of work on the KStreams application. The last one, dealing with the eventually consistent nature of resulting DDD aggregates is much harder to correct and will require some efforts at Debezium&#8217;s own CDC mechanism.</p> </div> </div> </div> <div class="sect1"> <h2 id="outlook"><a class="anchor" href="#outlook"></a>Outlook</h2> <div class="sectionbody"> <div class="paragraph"> <p>In this post we described an approach for creating aggregated events from Debezium&#8217;s CDC events. In a follow-up blog post we may dive a bit more into the topic of how to be able to horizontally scale the DDD creation by running multiple KStreams aggregator instances. For that purpose, the data needs proper re-partitioning before running the topology. In addition, it could be interesting to look into a somewhat more generic version which only needs custom classes to the describe the two main POJOs involved.</p> </div> <div class="paragraph"> <p>We also thought about providing a ready-to-use component which would work in a generic way (based on Connect records, i.e. not tied to a specific serialization format such as JSON) and could be set up as a configurable stand-alone process running given aggregations.</p> </div> <div class="paragraph"> <p>Also on the topic of dealing with eventual consistency we got some ideas, but those will need some more exploration and investigation for sure. Stay tuned!</p> </div> <div class="paragraph"> <p>We&#8217;d love to hear about your feedback on the topic of event aggreation. If you got any ideas or thoughts on the subject, please get in touch by posting a comment below or sending a message to our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a>.</p> </div> </div> </div> </div> <hr> <ul class="pager"> <li class="previous"> <a href="/blog/page/7/">&laquo; Older</a> </li> <li class="pages">Page 6 of 14</li> <li class="next"> <a href="/blog/page/5/">Newer &raquo;</a> </li> </ul> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2019 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="https://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="https://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/docs/features/" title="Features">Features</a> </li> <li> <a href="/docs/install/" title="Install">Install</a> </li> <li> <a href="/docs/manage/" title="Manage">Manage</a> </li> <li> <a href="/docs/architecture/" title="Architecture">Architecture</a> </li> <li> <a href="/docs/faq/" title="FAQ">FAQ</a> </li> <li> <a href="/docs/contribute/" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/dev" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="https://www.redhat.com/"><img src="/images/Logo-Red_Hat-Sponsored_By-B-Standard-RGB.svg"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="https://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.2/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='https://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
        var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
        var urlSplit = coreUrl.toLowerCase().split(/\//);
        var urlLast = urlSplit[urlSplit.length-1];
        var pageNameString = "";
        var siteName = "";
        var minorSectionIndex = 3
        if (urlLast == "") {
            urlSplit.splice(-1,1);
        }
        if (urlLast.search(/\./) >= 0) {
            if (urlLast == "index.html") {
                urlSplit.splice(-1,1);
            }
            else {
                urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
            }
        }
        siteName = urlSplit[2].split(".")[1];
        s.prop14 = s.eVar27 = siteName || "";
        s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
        s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
        pageNameString = urlSplit.splice(3).join(" | ");
        s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
        s.server = "jboss";
        s.channel = "jboss | community";
        s.prop4 = s.eVar23 = encodeURI(document.URL);
        s.prop21 = s.eVar18 = coreUrl;
        s.prop2 = s.eVar22 = "en";
        s.prop3 = s.eVar19 = "us";
        //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
        if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
        //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
      document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script> <script type="text/javascript">
      try {
      var pageTracker = _gat._getTracker("UA-10656779-1");
      pageTracker._trackPageview();
      } catch(err) {}</script> <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       
      ga('create', 'UA-76464546-1', 'auto');
      ga('send', 'pageview');
      ga('set', 'anonymizeIp', true);
      ga('require', 'linkid', 'linkid.js');
      
      </script> </div> </body> </html>