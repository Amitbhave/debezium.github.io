<!DOCTYPE html> <html lang="en"> <head> <title>Debezium Blog</title> <meta charset="utf-8"> <meta content="width=device-width, initial-scale=1.0" name="viewport"> <meta content="" name="description"> <meta content="" name="author"> <link href="http://static.jboss.org/theme/css/bootstrap-community/3.2.0.1/bootstrap-community.min.css" media="screen" rel="stylesheet"> <!--[if lt IE 9]><script src="http://static.jboss.org/theme/js/libs/html5/pre3.6/html5.min.js"></script><![endif]--> <link href="http://static.jboss.org/example/images/favicon.ico" rel="shortcut icon"> <link href="http://static.jboss.org/example/images/apple-touch-icon-144x144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144"> <link href="http://static.jboss.org/example/images/apple-touch-icon-114x114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114"> <link href="http://static.jboss.org/example/images/apple-touch-icon-72x72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72"> <link href="http://static.jboss.org/example/images/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed"> <link href="/stylesheets/debezium.css" rel="stylesheet" type="text/css"> <style>
      @media (min-width: 980px) {
        .banner { background-image: url(http://static.jboss.org/example/images/debezium-banner-1180px.png); height: 110px;  }
      }
      @media (max-width: 979px) {
        .banner { background-image: url(http://static.jboss.org/example/images/debezium-logo.png); background-repeat:no-repeat; background-position: center bottom; height: 60px; }
      }
      @media (max-width: 650px) {
        .banner { width: 100%; margin: 0px auto; }
      }
      @media (max-width: 450px) {
        .banner { height: 90px; }
      }
    </style> <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css" rel="stylesheet"> <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script> <script>
      hljs.initHighlightingOnLoad();
    </script> <script src="http://static.jboss.org/theme/js/libs/jquery/jquery-1.9.1.min.js"></script> <style>
      /* adjusting the vertical spacing for when a stickynav is engaged */
      .breadcrumb-fixed > .active {
        color: #8c8f91;
      }
      .breadcrumb-fixed {
        margin: 70px 0 10px;
        padding: 8px 15px;
        margin-bottom: 20px;
        list-style: none;
        background-color: #f5f5f5;
        border-radius: 4px;
      }
      
      .breadcrumb-fixed > li {
        display: inline-block;
      }
    </style> </head> <body> <div id="rhbar"> <a class="jbdevlogo" href="http://www.jboss.org/projects/about"></a> <a class="rhlogo" href="http://www.redhat.com/"></a> </div> <div id=""> <ul class="visuallyhidden" id="top"> <li> <a accesskey="n" href="#nav" title="Skip to navigation">Skip to navigation</a> </li> <li> <a accesskey="c" href="#page" title="Skip to content">Skip to content</a> </li> </ul> <div class="container" id="content"> <div class="navbar navbar-inverse navbar-fix"> <div class="container-fluid"> <div class="navbar-header"> <button class="navbar-toggle collapsed" data-target="#navbar-1" data-toggle="collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/"> Debezium </a> </div> <div class="collapse navbar-collapse" id="navbar-1"> <ul class="nav navbar-nav pull-right"> <li class=""><a href="/docs/faq">FAQ</a></li> <li class=""><a href="/docs">DOCS</a></li> <li class=""><a href="/community">COMMUNITY</a></li> <li class="active"><a href="/blog">BLOG</a></li> </ul> </div> </div> </div> <div id="equalHeightsLayout"> <div class="row post-text-padding row-no-expand"> <div class="hidden-xs col-sm-3 no-right-padding" id="leftdocnav"> <div class="panel-docnav"> <div class="panel-heading"> <h3 class="panel-title"> Latest posts </h3> </div> <div class="panel-body"> <ul class="list-group"> <li class="list-group-item"> <a href="/blog/2018/05/24/querying-debezium-change-data-eEvents-with-ksql/" rel="tooltip" title="Click to go to post">Querying Debezium Change Data Events With KSQL</a> </li> <li class="list-group-item"> <a href="/blog/2018/03/20/debezium-0-7-5-released/" rel="tooltip" title="Click to go to post">Debezium 0.7.5 Is Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/03/16/note-on-database-history-topic-configuration/" rel="tooltip" title="Click to go to post">A Note On Database History Topic Configuration</a> </li> <li class="list-group-item"> <a href="/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/" rel="tooltip" title="Click to go to post">Creating DDD aggregates with Debezium and Kafka Streams</a> </li> <li class="list-group-item"> <a href="/blog/2018/03/07/debezium-0-7-4-released/" rel="tooltip" title="Click to go to post">Debezium 0.7.4 Is Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/02/15/debezium-0-7-3-released/" rel="tooltip" title="Click to go to post">Debezium 0.7.3 Is Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/01/25/debezium-0-7-2-released/" rel="tooltip" title="Click to go to post">Debezium 0.7.2 Is Released</a> </li> <li class="list-group-item"> <a href="/blog/2018/01/17/streaming-to-elasticsearch/" rel="tooltip" title="Click to go to post">Streaming Data Changes from Your Database to Elasticsearch</a> </li> </ul> </div> </div> </div> <div class="col-xs-12 col-sm-9" id="maincol"> <div class="text-right"> <h3> Subscribe <a class="rss" href="/blog.atom"> <i class="icon-rss"></i> </a> </h3> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2016/09/19/Serializing-Debezium-events-with-Avro/">Serializing Debezium events with Avro</a> </h1> <div class="byline"> <p> <em> September 19, 2016 by Randall Hauch </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/kafka/">kafka</a> <a class="label label-info" href="/blog/tags/avro/">avro</a> <a class="label label-info" href="/blog/tags/serialization/">serialization</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>Although Debezium makes it easy to capture database changes and record them in Kafka, one of the more important decisions you have to make is <em>how</em> those change events will be serialized in Kafka. Every message in Kafka has a key and a value, and to Kafka these are opaque byte arrays. But when you set up Kafka Connect, you have to say how the Debezium event keys and values should be serialized to a binary form, and your consumers will also have to deserialize them back into a usable form.</p> </div> <div class="paragraph"> <p>Debezium event keys and values are both structured, so JSON is certainly a reasonable option&#8201;&#8212;&#8201;it&#8217;s flexible, ubiquitous, and language agnostic, but on the other hand it&#8217;s quite verbose. One alternative is Avro, which is also flexible and language agnostic, but also faster and results in smaller binary representations. Using Avro requires a bit more setup effort on your part and some additional software, but the advantages are often worth it.</p> </div> </div> </div> <div class="sect1"> <h2 id="kafka_serializers_and_deserializers"><a class="anchor" href="#kafka_serializers_and_deserializers"></a>Kafka serializers and deserializers</h2> <div class="sectionbody"> <div class="paragraph"> <p>Before we get too far, let&#8217;s back up and review how Kafka producers and consumers normally do this serialization and deserialization. Because the keys and values are simple opaque byte arrays, you can use anything for your keys and values. For example, consider a case where we&#8217;re using simple whole numbers for the keys and strings for the values. Here, a producer of these messages would use a <em>long serializer</em> to convert the <code>long</code> keys to binary form and a <em>string serializer</em> to convert the <code>String</code> values to binary form. Meanwhile, the consumers use a <em>long deserializer</em> to convert the binary keys into usable <code>long</code> values, and a <em>string deserializer</em> to convert the binary values back into <code>String</code> objects.</p> </div> <div class="paragraph"> <p>In cases where the keys and/or values need to be a bit more structured, the producers and consumers can be written to use JSON structures for keys and/or values, and the Kafka-provided <em>JSON serializer and deserializer</em> to do the conversion to and from binary form stored within the Kafka messages. As we said earlier, using JSON for keys and/or values is very flexible and language agnostic, but it is also produces keys and values that are relatively large since the fields and structure of the JSON values need to be encoded as well.</p> </div> </div> </div> <div class="sect1"> <h2 id="avro_serialization"><a class="anchor" href="#avro_serialization"></a>Avro serialization</h2> <div class="sectionbody"> <div class="paragraph"> <p><a href="http://avro.apache.org/">Avro</a> is a data serialization mechanism that uses a <em>schema</em> to define the structure of data. Avro relies upon this schema when writing the data to the binary format, and the schema allows it to encode the fields within the data in a much more compact form. Avro also relies upon the schema when <em>reading</em> the data, too. But interestingly, Avro schemas are designed to evolve, so it is actually possible to use a slightly different schema for reading than what was used for writing. This feature makes Avro a great choice for Kafka serialization and deserialization.</p> </div> <div class="paragraph"> <p><a href="http://confluent.io">Confluent</a> provides a <a href="http://docs.confluent.io/3.0.1/app-development.html">Kafka serializer and deserializer that uses Avro</a> and a separate <a href="http://docs.confluent.io/3.0.1/schema-registry/docs/intro.html">Schema Registry</a>, and it works like this: when a numeric or string object are to be serialized, the <em>Avro serializer</em> will determine the corresponding Avro Schema for the given type, register with the Schema Registry this schema and the topic its used on, get back the unique identifier for the schema, and then encode in the binary form the unique identifier of the schema and the encoded value. The next message is likely to have the same type and thus schema, so the serializer can quickly encode the schema identifier and value for this message without having to talk to the Schema Registry. Only when needing to serialize a schema it hasn&#8217;t already seen does the Avro serializer talk with the Schema Registry. So not only is this fast, but it also produces very compact binary forms and allows for the producer to <em>evolve</em> its key and/or value schemas over time. The Schema Registry can also be configured to allow new versions of schemas to be registered only when they are <em>compatible</em> with the Avro schema evolution rules, ensuring that producers do not produce messages that consumers will not be able to read.</p> </div> <div class="paragraph"> <p>Consumers, meanwhile, use the <em>Avro deserializer</em>, which works in a similar manner, albeit backwards: when it reads the binary form of a key or value, it first looks for the schema identifier and, if it hasn&#8217;t seen it before asks the Schema Registry for the schema, and then uses that schema to decode the remainder of the binary representation into its object form. Again, if the deserializer has previously seen a particular schema identifier, it already has the schema needed to decode the data and doesn&#8217;t have to consult the Schema Registry.</p> </div> </div> </div> <div class="sect1"> <h2 id="kafka_connect_converters"><a class="anchor" href="#kafka_connect_converters"></a>Kafka Connect converters</h2> <div class="sectionbody"> <div class="paragraph"> <p>Kafka Connect is a bit different than many Kafka producers/consumers, since the keys and values will often be structured. And rather than require connectors to work with JSON objects, Kafka Connect defines its own lightweight framework for defining data structures with a schema, making it much easier to write connectors to work with structured data. Kafka Connect defines its own <em>converters</em> that are similar to Kafka (de)serializers, except that Kafka Connect&#8217;s converters know about these structures and schemas and can serialize the keys and values to binary form. Kafka Connect provides a <em>JSON converter</em> that converts the structures into JSON and then uses the normal Kafka JSON serializer, so downstream consumers can just use the normal Kafka JSON deserializer and get a JSON representation of the Kafka Connect structs and schema. This is exactly what the <a href="/docs/tutorial">Debezium tutorial</a> is using, and the <code>watch-topic</code> consumer knows to use the JSON deserializer.</p> </div> <div class="paragraph"> <p>One great feature of Kafka Connect is that the connectors simply provide the structured messages, and Kafka Connect takes care of serializing them using the configured converter. This means that you can use any Kafka Connect <em>converters</em> with any Kafka Connect connector, including all of Debezium&#8217;s connectors.</p> </div> <div class="paragraph"> <p>Kafka Connect&#8217;s schema system was designed specifically with Avro in mind, so there is a one-to-one mapping between Kafka Connect schemas and Avro schemas. Confluent provides an <em>Avro Converter</em> for Kafka Connect that serializes the Kafka Connect structs provided by the connectors into the compact Avro binary representation, again using the Schema Registry just like the Avro serializer. The consumer just uses the normal Avro deserializer as mentioned above.</p> </div> <div class="paragraph"> <p>Using Avro for serialization of Debezium events brings several significant advantages:</p> </div> <div class="olist arabic"> <ol class="arabic"> <li> <p>The encoded binary forms of the Debezium events are <em>significantly</em> smaller than the JSON representations. Not only is the structured data encoded in a more compact form, but the <em>schema</em> associated with that structured data is represented in the binary form as a single integer.</p> </li> <li> <p>Encoding the Debezium events into their Avro binary forms is fast. Only when the converter sees a new schema does it have to consult with the Schema Registry; otherwise, the schema has already been seen and its encoding logic already precomputed.</p> </li> <li> <p>The Avro Converter for Kafka Connect produces messages with Avro-encoded keys and values that can be read by any Kafka consumers using the Avro deserializer.</p> </li> <li> <p>Debezium event structures are based upon the structure of the table from which the changes were captured. When the structure of the source table changes (e.g., because an <code>ALTER</code> statement was applied to it), the structure and schema of the events will also change. If this is done in a manner such that the new Avro schema is <em>compatible with</em> the older Avro schema, then consumers will be able to process the events without disruption, even though the event structures evolve over time.</p> </li> <li> <p>Avro&#8217;s schema mechanism is far more formal and rigorous than the free-form JSON structure, and the changes in the schemas are clearly identified when comparing any two messages.</p> </li> <li> <p>The Avro converter, Avro (de)serializers, and Schema Registry are all open source.</p> </li> </ol> </div> <div class="paragraph"> <p>It is true that using the Avro converter and deserializer requires a running Schema Registry, and that the registry becomes an integral part of your streaming infrastructure. However, this is a small price to pay for the benefits listed above.</p> </div> </div> </div> <div class="sect1"> <h2 id="using_the_avro_converter_with_debezium"><a class="anchor" href="#using_the_avro_converter_with_debezium"></a>Using the Avro Converter with Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>As mentioned above, in the interest of keeping the Debezium tutorial as simple as possible, we avoid using the Schema Registry or the Avro converter in the tutorial. We also don&#8217;t (yet) include the Avro converter in our Docker images, though that <a href="https://issues.jboss.org/browse/DBZ-59">will change soon</a>.</p> </div> <div class="paragraph"> <p>Nevertheless, it is absolutely possible to use the Avro Converter with the Debezium connectors when you are installing the connectors into either the Confluent Platform or into your own installation of Kafka Connect. Simply configure the <a href="http://docs.confluent.io/3.0.1/connect/userguide.html">Kafka Connect workers</a> to use the Avro converter for the keys and values:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>key.converter=io.confluent.connect.avro.AvroConverter&#x000A;value.converter=io.confluent.connect.avro.AvroConverter</code></pre> </div> </div> <div class="paragraph"> <p>And, if you want to use the Avro Converter for Kafka Connect internal messages, then set these as well:</p> </div> <div class="listingblock"> <div class="content"> <pre class="highlight"><code>internal.key.converter=io.confluent.connect.avro.AvroConverter&#x000A;internal.value.converter=io.confluent.connect.avro.AvroConverter</code></pre> </div> </div> <div class="paragraph"> <p>Once again, there is no need to configure the Debezium connectors any differently.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2016/08/30/Debezium-0-3-1-Released/">Debezium 0.3.1 Released</a> </h1> <div class="byline"> <p> <em> August 30, 2016 by Randall Hauch </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>We&#8217;re happy to announce that <strong>Debezium 0.3.1</strong> is now available for use with Kafka Connect 0.10.0.1. This release contains an updated <a href="/docs/connectors/mysql">MySQL connector</a> with a handful of bug fixes and two significant but backward-compatible changes. First, the MySQL connector now supports using secure connections to MySQL, adding to the existing ability to connect securely to Kafka. Second, the MySQL connector is able to capture MySQL string values using the proper character sets so that any values stored in the database can be captured correctly in events. See our <a href="/docs/releases#release-0-3-1">release notes</a> for details of these changes and for upgrading recommendations.</p> </div> <div class="paragraph"> <p>We&#8217;ve also updated the <a href="https://hub.docker.com/r/debezium/">Debezium Docker images</a> labelled <code>0.3</code> and <code>latest</code>, which we use in our <a href="/docs/tutorial">tutorial</a>.</p> </div> <div class="paragraph"> <p>Thanks to Chris, Akshath, barten, and and others for their help with the release, issues, discussions, contributions, and questions!</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve the MySQL connector and add more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2016/08/16/Debezium-0-3-0-Released/">Debezium 0.3.0 Released</a> </h1> <div class="byline"> <p> <em> August 16, 2016 by Randall Hauch </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/mongodb/">mongodb</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>After a few weeks delay, <strong>Debezium 0.3.0 is now available</strong> for use with Kafka Connect 0.10.0.1. This release contains an updated <a href="/docs/connectors/mysql">MySQL connector</a> with quite a few bug fixes, and a new <strong><em><a href="/docs/connectors/mongodb">MongoDB connector</a></em></strong> that captures the changes made to a MongoDB replica set or MongoDB sharded cluster. See the <a href="/docs/connectors">documentation</a> for details about how to configure these connectors and how they work.</p> </div> <div class="paragraph"> <p>We&#8217;ve also updated the <a href="https://hub.docker.com/r/debezium/">Debezium Docker images</a> (with labels <code>0.3</code> and <code>latest</code>) used in our <a href="/docs/tutorial">tutorial</a>.</p> </div> <div class="paragraph"> <p>Thanks to Andrew, Bhupinder, Chris, David, Horia, Konstantin, Tony, and others for their help with the release, issues, discussions, contributions, and questions!</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve the MySQL connector and add more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2016/08/16/Debezium-0-2-4-Released/">Debezium 0.2.4 Released</a> </h1> <div class="byline"> <p> <em> August 16, 2016 by Randall Hauch </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/releases/">releases</a> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> <a class="label label-info" href="/blog/tags/docker/">docker</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>I&#8217;m happy to announce that <strong>Debezium 0.2.4 is now available</strong> for use with Kafka Connect 0.9.0.1. This release adds more verbose logging during MySQL snapshots, enables taking snapshots of very large MySQL databases, and correct a potential exception during graceful shutdown. See our <a href="/docs/releases#release-0-2-4">release notes</a> for details of these changes and for upgrading recommendations.</p> </div> <div class="paragraph"> <p>We&#8217;ve also updated the <a href="https://hub.docker.com/r/debezium/">Debezium Docker images</a> (with label <code>0.2</code> and <code>latest</code>) used in our <a href="/docs/tutorial">tutorial</a>.</p> </div> <div class="paragraph"> <p>Thanks to David and wangshao for their help with the release, issues, discussions, contributions, and questions! Stay tuned for our next release, which will be 0.3 and will have a new MongoDB connector and will support Kafka Connect 0.10.0.1.</p> </div> </div> </div> <div class="sect1"> <h2 id="about_debezium"><a class="anchor" href="#about_debezium"></a>About Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source distributed platform that turns your existing databases into event streams, so applications can see and respond almost instantly to each committed row-level change in the databases. Debezium is built on top of <a href="http://kafka.apache.org/">Kafka</a> and provides <a href="http://kafka.apache.org/documentation.html#connect">Kafka Connect</a> compatible connectors that monitor specific database management systems. Debezium records the history of data changes in Kafka logs, so your application can be stopped and restarted at any time and can easily consume all of the events it missed while it was not running, ensuring that all events are processed correctly and completely. Debezium is <a href="/license">open source</a> under the <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, Version 2.0</a>.</p> </div> </div> </div> <div class="sect1"> <h2 id="get_involved"><a class="anchor" href="#get_involved"></a>Get involved</h2> <div class="sectionbody"> <div class="paragraph"> <p>We hope you find Debezium interesting and useful, and want to give it a try. Follow us on Twitter <a href="https://twitter.com/debezium">@debezium</a>, <a href="https://gitter.im/debezium/user">chat with us on Gitter</a>, or join our <a href="https://groups.google.com/forum/#!forum/debezium">mailing list</a> to talk with the community. All of the code is open source <a href="https://github.com/debezium/">on GitHub</a>, so build the code locally and help us improve the MySQL connector and add more connectors. If you find problems or have ideas how we can improve Debezium, please let us know or <a href="https://issues.jboss.org/projects/DBZ/issues/">log an issue</a>.</p> </div> </div> </div> </div> <hr> <div class="post"> <h1 class="title"> <a href="/blog/2016/08/02/capturing-changes-from-mysql/">Capturing changes from MySQL</a> </h1> <div class="byline"> <p> <em> August 02, 2016 by Randall Hauch </em> <em> under&nbsp; </em> <a class="label label-info" href="/blog/tags/mysql/">mysql</a> </p> </div> <div id="preamble"> <div class="sectionbody"> <div class="paragraph"> <p>Change data capture is a hot topic. Debezium&#8217;s goal is to make change data capture easy for multiple DBMSes, but admittedly we&#8217;re still a young open source project and so far we&#8217;ve only released a <a href="/docs/connectors/mysql">connector for MySQL</a> with a <a href="/docs/connectors/mongodb">connector for MongoDB</a> that&#8217;s just around the corner. So it&#8217;s great to see how others are using and implementing change data capture. In this post, we&#8217;ll review Yelp&#8217;s approach and see how it is strikingly similar to Debezium&#8217;s MySQL connector.</p> </div> </div> </div> <div class="sect1"> <h2 id="streaming_data_at_yelp"><a class="anchor" href="#streaming_data_at_yelp"></a>Streaming data at Yelp</h2> <div class="sectionbody"> <div class="paragraph"> <p>The <a href="http://engineeringblog.yelp.com/">Yelp Engineering Blog</a> recently began a series describing their real-time streaming data infrastructure. The <a href="http://engineeringblog.yelp.com/2016/07/billions-of-messages-a-day-yelps-real-time-data-pipeline.html">first post</a> provides a good introduction and explains how moving from a monolith to a service-oriented architecture increased productivity, but also made it more challenging to work with data spread across the 100 services that own it. It&#8217;s totally worth your time to read it right now.</p> </div> <div class="paragraph"> <p>As Justin writes in the post, several reasons prompted them to create their own real time streaming data pipeline:</p> </div> <div class="ulist"> <ul> <li> <p>Ensuring data always remains consistent across services is always a difficult task, but especially so when things can and do go wrong. Transactions across services may be useful in some situations, but they&#8217;re not straightforward, are expensive, and can lead to request amplification where one service calls another, which coordinates with two others, etc.</p> </li> <li> <p>Services that update data in multiple backend services suffer from the <a href="http://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/">dual write problem</a>, which is where a failure occurs after one backing service was updated but before the other could be updated and that always results in data inconsistencies that are difficult to track down and correct.</p> </li> <li> <p>Combining and integrating data spread across multiple services can also be difficult and expensive, but it is even harder when that data is continously changing. One approach is to use bulk APIs, but these can beprohibitive to create, can result in inconsistencies, and pose real scalability problems when services need to continually receive the never-ending updates to data.</p> </li> </ul> </div> <div class="paragraph"> <p>Yelp&#8217;s Real-Time Data Pipeline records changes to data on totally ordered distributed logs so that downstream consumers can receive and process the same changes in exactly the same order. Services can consume changes made by other services, and can therefore stay in sync without explicit interservice communication. This system uses among other things Kafka for event logs, a homegrown system named <a href="http://engineeringblog.yelp.com/2016/08/streaming-mysql-tables-in-real-time-to-kafka.html">MySQLStreamer</a> to capture committed changes to MySQL tables, <a href="http://avro.apache.org">Avro</a> for message format and schemas, and a custom <a href="http://engineeringblog.yelp.com/2016/07/billions-of-messages-a-day-yelps-real-time-data-pipeline.html#yelps-real-time-data-pipeline">Schematizer</a> service that tracks consumers and enforces the Avro schemas used for messages on every Kafka topic.</p> </div> </div> </div> <div class="sect1"> <h2 id="how_yelp_captures_mysql_changes"><a class="anchor" href="#how_yelp_captures_mysql_changes"></a>How Yelp captures MySQL changes</h2> <div class="sectionbody"> <div class="paragraph"> <p>Perhaps most interesting for Debezium is how Yelp captures the committed changes in their MySQL databases and write them to Kafka topics. Their <a href="http://engineeringblog.yelp.com/2016/08/streaming-mysql-tables-in-real-time-to-kafka.html">second post in the series</a> goes into a lot more detail about their MySQLStreamer process that reads the MySQL binary log and continously processes the DDL statements and DML operations that appear in the log, generating the corresponding <em>insert</em>, <em>update</em>, <em>delete</em>, and <em>refresh</em> events, and writing these event messages to a separate Kafka topic for each MySQL table. We&#8217;ve <a href="/blog/2016-04-15-parsing-ddl">mentioned before</a> that MySQL&#8217;s row-level binlog events that result from the DML operation don&#8217;t include the full definition of the columns, so knowing what the columns mean in each event requires process the DDL statements that also appear in the binlog. Yelp uses a separate MySQL instance it calls the <em>schema tracker database</em>, which behaves like a MySQL slave to which are applied only the DDL statements they read from the binlog. This technique lets Yelp&#8217;s MySQLStreamer system know the state of the database schema and the structure of its tables at the point in the binlog where they are processing events. This is pretty interesting, because it uses the MySQL engine to handle the DDL parsing.</p> </div> <div class="paragraph"> <p>Yelp&#8217;s MySQLStreamer process uses another MySQL database to track internal state describing its position in the binlog, what events have been successfully published to Kafka, and, because the binlog position varies on each replica, replica-independent information about each transaction. This latter information is similar to MySQL GTIDs, although Yelp is using earlier versions of MySQL that do not support GTIDs.</p> </div> <div class="paragraph"> <p>Of course, special consideration has to be taken for databases that have been around for a long time. The MySQL binlogs are capped and will not contain the <em>entire</em> history of the databases, so Yelp&#8217;s MySQLStreamer process bootstraps the change data capture process of old databases by starting another clean MySQL replica, which will use the built-in MySQL replication mechanism with the <a href="http://dev.mysql.com/doc/refman/5.7/en/blackhole-storage-engine.html">MySQL blackhole database engine</a> to obtain a consistent snapshot of the master and so that all activity is logged in the replica&#8217;s binlog while the replica actually stores no data.</p> </div> <div class="paragraph"> <p>Yelp&#8217;s MySQLStreamer mechanism is quite ingenious in its use of MySQL and multiple extra databases to capture changes from MySQL databases and write them to Kafka topics. The downside, of course, is that doing so does increase the operational complexity of the system.</p> </div> </div> </div> <div class="sect1"> <h2 id="similar_purpose_similar_approach"><a class="anchor" href="#similar_purpose_similar_approach"></a>Similar purpose, similar approach</h2> <div class="sectionbody"> <div class="paragraph"> <p>Debezium is an open source project that is building a change data capture for a variety of DBMSes. Like Yelp&#8217;s MySQLStreamer, Debezium&#8217;s <a href="/docs/connectors/mysql">MySQL Connector</a> can continously capture the committed changes to MySQL database rows and record these events in a separate Kafka topic for each table. When first started, Debezium&#8217;s MySQL Connector can perform an initial consistent snapshot and then begin reading the MySQL binlog. It uses both DDL and DML operations that appear in the binlog, directly <a href="/blog/2016-04-15-parsing-ddl">parsing and using the DDL statements</a> to learn the changes to each table&#8217;s structure and the mapping of each insert, update, and delete binlog event. And each resulting change event written to Kafka includes information about the originating MySQL server and its binlog position, as well as the before and/or after states of the affected row.</p> </div> <div class="paragraph"> <p>However, unlike Yelp&#8217;s MySQLStreamer, the Debezium MySQL connector doesn&#8217;t need or use extra MySQL databases to parse DDL or to store the connector&#8217;s state. Instead, Debezium is built on top of Kafka Connect, which is a new Kafka library that provides much of the generic functionality of reliably pulling data from external systems, pushing it into Kafka topics, and tracking what data has already been processed. Kafka Connect stores this state inside Kafka itself, simplifying the operational footprint. Debezium&#8217;s MySQL connector can then focus on the details of performing a consistent snapshot when required, reading the binlog, and converting the binlog events into useful change events.</p> </div> <div class="paragraph"> <p>Yelp&#8217;s real time data pipeline makes use of a custom Avro schema registry, and uses those Avro schemas to encode each event into a compact binary representation while keeping the metadata about the structure of the event. It&#8217;s possible to do this with Debezium, too: simply run <a href="http://docs.confluent.io/3.0.0/schema-registry/docs/index.html">Confluent&#8217;s Schema Registry</a> as a service and then configure the Kafka Connect worker to use the <a href="/docs/faq#avro-converter">Avro Converter</a>. As the converter serializes each event, it looks at the structure defined by the connector and, when that structure changes, generates an updated Avro Schema and registers it with the Schema Registry. That new Avro schema is then used to encode the event (and others with an identical structure) into a compact binary form written to Kafka. And of course, consumers then also use the same Avro converter so that as events are deserialized, the converter coordinates with the Schema Registry whenever it needs an Avro schema it doesn&#8217;t know about. As a result, the events are stored in a compact manner while the events' content and metadata remain available, while Schema Registry captures and maintains the history of the Avro schema for each table as it evolves over time.</p> </div> </div> </div> <div class="sect1"> <h2 id="capturing_changes_from_mysql_with_debezium"><a class="anchor" href="#capturing_changes_from_mysql_with_debezium"></a>Capturing changes from MySQL with Debezium</h2> <div class="sectionbody"> <div class="paragraph"> <p>If you&#8217;re interested in change data capture with MySQL (or any other DBMSes), give Debezium a try by going through <a href="/docs/tutorial">our tutorial</a> that walks you through starting Kafka, Kafka Connect, and Debezium&#8217;s MySQL Connector to see exactly what change data events look like and how they can be used. Best of all, it&#8217;s open source with a growing community of developers that has had the benefit of building on top of recently-created Kafka Connect framework. Our MySQL connector is ready now, but we&#8217;re working on <a href="/docs/connectors/">connectors for other DBMSes</a>. Specifically, our upcoming 0.3 release will include our <a href="/docs/connectors/mongodb">MongoDB Connector</a>, with 0.4 including connectors for PostgreSQL and/or Oracle.</p> </div> <div class="paragraph"> <p><em>Correction: A previous version of this post incorrectly stated that Yelp was using a MySQL version that did support GTIDs, when in fact they are using a version that does <strong>not</strong> support MySQL GTIDs. The post has been corrected, and the author regrets the mistake.</em></p> </div> </div> </div> </div> <hr> <ul class="pager"> <li class="previous"> <a href="/blog/page/8/">&laquo; Older</a> </li> <li class="pages">Page 7 of 9</li> <li class="next"> <a href="/blog/page/6/">Newer &raquo;</a> </li> </ul> </div> </div> </div> </div> <footer class="container"> <div class="row"> <div class="col-md-5 col-md-offset-1"> <h4>Debezium</h4> <p> &#169; 2018 Debezium Community <br> <br> <i class="icon-fire"></i> Mixed with <a href="http://twitter.github.com/bootstrap">Bootstrap</a>, baked by <a href="http://awestruct.org">Awestruct</a>. <br> <i class="icon-flag"></i> Website and docs licensed under <a href="http://creativecommons.org/licenses/by/3.0/">CC BY 3.0</a>. <br> <i class="icon-flag-alt"></i> Code released under <a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache License, v2.0</a>. <br> <i class="icon-file-alt"></i> <a href="http://www.redhat.com/legal/legal_statement.html" title="Terms">Terms</a> | <a href="http://www.redhat.com/legal/privacy_statement.html" title="Privacy Policy">Privacy</a> </p> </div> <div class="col-md-3"> <h4>Documentation</h4> <ul class="list-unstyled"> <li> <a href="/docs/features" title="Features">Features</a> </li> <li> <a href="/docs/install" title="Install">Install</a> </li> <li> <a href="/docs/manage" title="Manage">Manage</a> </li> <li> <a href="/docs/architecture" title="Architecture">Architecture</a> </li> <li> <a href="/docs/faq" title="FAQ">FAQ</a> </li> <li> <a href="/docs/contribute" title="Contribute">Contribute</a> </li> </ul> </div> <div class="col-md-3"> <h4>Connect</h4> <ul class="list-unstyled"> <li> <a href="/blog" title="Blog">Blog</a> </li> <li> <a href="http://twitter.com/debezium" title="Twitter">Twitter</a> </li> <li> <a href="http://github.com/debezium" title="GitHub">GitHub</a> </li> <li> <a href="https://gitter.im/debezium/dev" title="Chat">Chat</a> </li> <li> <a href="https://groups.google.com/forum/#!forum/debezium" title="Google Groups">Google Groups</a> </li> <li> <a href="http://stackoverflow.com/questions/tagged/debezium" title="StackOverflow">StackOverflow</a> </li> </ul> </div> </div> </footer> <div class="container" id="companyfooter"> <div class="redhatlogo"> <div id="logospacer"></div> <a href="http://www.redhat.com/"><img src="http://static.jboss.org/theme/images/common/redhat_logo.png"></a> </div> </div> <span class="backToTop"> <a href="#top">back to top</a> </span> <script src="http://static.jboss.org/theme/js/libs/bootstrap-community/3.2.0.1/bootstrap-community.min.js"></script> <script type='text/javascript' language='JavaScript' src='http://www.redhat.com/j/elqNow/elqCfg.js'></script> <script type='text/javascript' language='JavaScript' src='http://www.redhat.com/j/elqNow/elqImg.js'></script> <div id="oTags"> <script type="text/javascript" src="//www.redhat.com/j/s_code.js"></script> <script type="text/javascript"><!--
        var coreUrl = encodeURI(document.URL.split("?")[0]).replace(/-/g," ");
        var urlSplit = coreUrl.toLowerCase().split(/\//);
        var urlLast = urlSplit[urlSplit.length-1];
        var pageNameString = "";
        var siteName = "";
        var minorSectionIndex = 3
        if (urlLast == "") {
            urlSplit.splice(-1,1);
        }
        if (urlLast.search(/\./) >= 0) {
            if (urlLast == "index.html") {
                urlSplit.splice(-1,1);
            }
            else {
                urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
            }
        }
        siteName = urlSplit[2].split(".")[1];
        s.prop14 = s.eVar27 = siteName || "";
        s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
        s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
        pageNameString = urlSplit.splice(3).join(" | ");
        s.pageName = "jboss | community | " + siteName + " | " + pageNameString;
        s.server = "jboss";
        s.channel = "jboss | community";
        s.prop4 = s.eVar23 = encodeURI(document.URL);
        s.prop21 = s.eVar18 = coreUrl;
        s.prop2 = s.eVar22 = "en";
        s.prop3 = s.eVar19 = "us";
        //--></script> <script type="text/javascript" src="//www.redhat.com/j/rh_omni_footer.js"></script> <script language="JavaScript" type="text/javascript"><!--
        if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
        //--></script> <noscript><a href="http://www.omniture.com" title="Web Analytics"><img src="https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]&cdp=3&[AQE]" height="1" width="1" border="0" alt=""/></a></noscript> </div> <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
      document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script> <script type="text/javascript">
      try {
      var pageTracker = _gat._getTracker("UA-10656779-1");
      pageTracker._trackPageview();
      } catch(err) {}</script> <script>
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       
      ga('create', 'UA-76464546-1', 'auto');
      ga('send', 'pageview');
      ga('set', 'anonymizeIp', true);
      ga('require', 'linkid', 'linkid.js');
      
      </script> </div> </body> </html>